{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Prerequisites\n",
    "This notebook serves as a tutorial on employing the ElasticNet model from QSAR package to a specific dataset. Before you start:\n",
    "- Basic familiarity with Python, Pandas, and Scikit-learn will be beneficial.\n",
    "- The main aim is to understand the flow and not just achieve a high score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo add installation instructions\n",
    "# option1: !python setup.py install\n",
    "# option2: !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. Data Import\n",
    "2. Preprocessing\n",
    "3. Cross-Validation\n",
    "4. Model Without Optimization\n",
    "5. Model With Hyperparameter Optimization\n",
    "6. Model Evaluation\n",
    "7. Prediction and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "from qsar.utils.visualizer import Visualizer\n",
    "from qsar.utils.cross_validator import CrossValidator\n",
    "from qsar.utils.extractor import Extractor\n",
    "from qsar.utils.hyperparameter_optimizer import HyperParameterOptimizer\n",
    "\n",
    "from qsar.models.elasticnet import ElasticnetModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Import\n",
    "Here, we'll load our dataset, explore it briefly, and prepare it for modeling.\n",
    "Define paths for various datasets: full, neutral, and ionizable for both training and testing.\n",
    "Initialize the extractor and split datasets into features (X) and target variable (y) based on \"Log_MP_RATIO\".\n",
    "Also, retrieve the full training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {\n",
    "    \"full_train\": \"../data/full/train/full_train_unfiltered.csv\",\n",
    "    \"full_test\": \"../data/full/test/full_test_unfiltered.csv\",\n",
    "    \"neutral_train\": \"../data/neutral/train/neutral_train_unfiltered.csv\",\n",
    "    \"neutral_test\": \"../data/neutral/test/neutral_test_unfiltered.csv\",\n",
    "    \"ionizable_train\": \"../data/ionizable/train/ionizable_train_unfiltered.csv\",\n",
    "    \"ionizable_test\": \"../data/ionizable/test/ionizable_test_unfiltered.csv\",\n",
    "}\n",
    "\n",
    "extractor = Extractor(data_paths)\n",
    "\n",
    "# todo move the split after the preprocessing\n",
    "x_dfs, y_dfs = extractor.split_x_y(\"Log_MP_RATIO\")\n",
    "df_full_tain = extractor.get_df(\"full_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Preprocessing\n",
    "Scaling the features to have a mean=0 and variance=1 for better convergence during model training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Todo: include and review all the preprocessing steps\n",
    "# Todo: check if we need scaling to make the model converge\n",
    "# scaler = StandardScaler()\n",
    "# x_full_train_scaled = scaler.fit_transform(x_dfs[\"full_train\"])\n",
    "# x_dfs[\"full_train\"] = pd.DataFrame(x_full_train_scaled, index=x_dfs[\"full_train\"].index, columns=x_dfs[\"full_train\"].columns)\n",
    "# x_full_test_scaled = scaler.transform(x_dfs[\"full_test\"])\n",
    "# x_dfs[\"full_test\"] = pd.DataFrame(x_full_test_scaled, index=x_dfs[\"full_test\"].index, columns=x_dfs[\"full_test\"].columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-validation\n",
    "Initialize cross-validation and visualization tools.\n",
    "Create cross-validation folds from the full training dataset and visualize the created folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = CrossValidator(df_full_tain)\n",
    "visualizer = Visualizer()\n",
    "X_list, y_list, df, y, n_folds = cross_validator.create_cv_folds()\n",
    "visualizer.display_cv_folds(df, y, n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model evaluation before hyperparameter optimization\n",
    "Evaluate the performance of the ElasticNet model on the full training dataset and visualize its performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_model = ElasticnetModel()\n",
    "metrics = cross_validator.evaluate_model_performance(elasticnet_model.model,\n",
    "                                                                   x_dfs[\"full_train\"], y_dfs[\"full_train\"],\n",
    "                                                                   x_dfs[\"full_test\"], y_dfs[\"full_test\"])\n",
    "visualizer.display_model_performance(\"ElasticNet\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter optimization\n",
    "Initialize the ElasticnetModel, then use Optuna for hyperparameter optimization.\n",
    "Print the best hyperparameters after optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "elasticnet_model = ElasticnetModel()\n",
    "\n",
    "optimizer = HyperParameterOptimizer(model=elasticnet_model, data=df_full_tain, direction='maximize', trials=100)\n",
    "\n",
    "study = optimizer.optimize()\n",
    "trial = study.best_trial\n",
    "print(trial.value, trial.params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model evaluation after hyperparameter optimization\n",
    "Evaluate the performance of the ElasticNet model with the best hyperparameters on the full training dataset.\n",
    "Then visualize its performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_model.set_hyperparameters(**study.best_params)\n",
    "metrics = cross_validator.evaluate_model_performance(\n",
    "    elasticnet_model.model, x_dfs[\"full_train\"], y_dfs[\"full_train\"], x_dfs[\"full_test\"], y_dfs[\"full_test\"])\n",
    "visualizer.display_model_performance(\"ElasticNet\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the optimization history of the study (hyperparameter optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plot_optimization_history(study))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction and results\n",
    "Predict with the optimized ElasticNet model and visualize the comparison between predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full_train_pred, y_full_test_pred = cross_validator.get_predictions(elasticnet_model.model, x_dfs[\"full_train\"],\n",
    "                                                                      y_dfs[\"full_train\"], x_dfs[\"full_test\"])\n",
    "visualizer.display_true_vs_predicted(\"ElasticNet\", y_dfs[\"full_train\"], y_dfs[\"full_test\"], y_full_train_pred,\n",
    "                                     y_full_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
