{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from feature_selector import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ionizable_train: pd.DataFrame = pd.read_csv(\"../../Data/ionizable_dataset_72_train_divprio.csv\", delimiter=';')\n",
    "df_ionizable_train[\"TYPE\"] = \"TRAIN\"\n",
    "df_ionizable_test: pd.DataFrame = pd.read_csv(\"../../Data/ionizable_dataset_72_test_divprio.csv\", delimiter=';')\n",
    "df_ionizable_test[\"TYPE\"] = \"TEST\"\n",
    "\n",
    "df_ionizable = pd.concat([df_ionizable_train, df_ionizable_test])\n",
    "FS_ionizable: FeatureSelector = FeatureSelector(df_ionizable, cols_to_ignore=[\"TYPE\"])\n",
    "\n",
    "# FS_io_train.scale_data(inplace=True)\n",
    "# FS_io_test.scale_data(inplace=True)\n",
    "\n",
    "\n",
    "df_neutral_train: pd.DataFrame = pd.read_csv(\"../../Data/neutral_dataset_111_train_divprio.csv\", delimiter=';')\n",
    "df_neutral_train[\"TYPE\"] = \"TRAIN\"\n",
    "df_neutral_test: pd.DataFrame = pd.read_csv(\"../../Data/neutral_dataset_111_test_divprio.csv\", delimiter=';')\n",
    "df_neutral_test[\"TYPE\"] = \"TEST\"\n",
    "\n",
    "df_neutral = pd.concat([df_neutral_train, df_neutral_test])\n",
    "FS_neutral: FeatureSelector = FeatureSelector(df_neutral, cols_to_ignore=[\"TYPE\"])\n",
    "\n",
    "# FS_ne_train.scale_data(inplace=True)\n",
    "# FS_ne_test.scale_data(inplace=True)\n",
    "\n",
    "df_full_train: pd.DataFrame = pd.read_csv(\"../../Data/full_dataset_train_divprio.csv\", delimiter=';')\n",
    "df_full_train[\"TYPE\"] = \"TRAIN\"\n",
    "df_full_test: pd.DataFrame = pd.read_csv(\"../../Data/full_dataset_test_divprio.csv\", delimiter=';')\n",
    "df_full_test[\"TYPE\"] = \"TEST\"\n",
    "\n",
    "df_full = pd.concat([df_full_train, df_full_test])\n",
    "FS_full: FeatureSelector = FeatureSelector(df_full, cols_to_ignore=[\"TYPE\"])\n",
    "\n",
    "\n",
    "# FS_full_train: FeatureSelector = FeatureSelector(df_full_train)\n",
    "# FS_full_test: FeatureSelector = FeatureSelector(df_full_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FS_full.df[[\"vsurf_W8\", \"vsurf_HB8\"]]\n",
    "# dropped = FS_full.remove_highly_correlated(verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test de normalitÃ©\n",
    "from scipy.stats import normaltest\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "data = df_full_test.iloc[:,14]\n",
    "\n",
    "stat, p = normaltest(data)\n",
    "\n",
    "print(\"Stats= \", stat, \"\\np= \", p)\n",
    "alpha = 0.05\n",
    "\n",
    "\n",
    "if p > alpha:\n",
    "    print(\"Gaussian\")\n",
    "else:\n",
    "    print(\"Not gaussian\")\n",
    "\n",
    "\n",
    "pyplot.hist(data)\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Low variance features\n",
    "We try to detect every feature that has a variance below the threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IONIZABLE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Before low variance removal: \", df_ionizable.shape)\n",
    "df_ionizable_lv, col_ionizable_lv = FS_ionizable.remove_low_variance(variance_threshold=0, cols_to_ignore=[\"TYPE\"], inplace=True)\n",
    "print(col_ionizable_lv)\n",
    "print(\"length of the feature with low variance that are common for train and test: \", len(col_ionizable_lv))\n",
    "\n",
    "df_ionizable = df_ionizable.drop(list(col_ionizable_lv), axis=1)\n",
    "print(\"After low variance removal: \", df_ionizable.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NEUTRAL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Before low variance removal: \", df_neutral.shape)\n",
    "df_neutral_lv, col_neutral_lv = FS_neutral.remove_low_variance(variance_threshold=0, cols_to_ignore=[\"TYPE\"], inplace=True)\n",
    "print(col_neutral_lv)\n",
    "print(\"length of the feature with low variance that are common for train and test: \", len(col_neutral_lv))\n",
    "\n",
    "df_neutral = df_neutral.drop(list(col_neutral_lv), axis=1)\n",
    "print(\"After low variance removal: \", df_neutral.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FULL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Before low variance removal: \", df_full.shape)\n",
    "df_full_lv, col_full_lv = FS_full.remove_low_variance(variance_threshold=0, cols_to_ignore=[\"TYPE\"], inplace=True)\n",
    "print(col_full_lv)\n",
    "print(\"length of the feature with low variance that are common for train and test: \", len(col_full_lv))\n",
    "df_full = df_full.drop(list(col_full_lv), axis=1)\n",
    "print(\"After low variance removal: \", df_full.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detect binary data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "dfs: dict = {\n",
    "    \"ionizable\": df_ionizable.loc[:, df_ionizable.isin([0,1]).all()],\n",
    "    \"neutral\": df_neutral.loc[:, df_neutral.isin([0,1]).all()],\n",
    "    \"full\": df_full.loc[:, df_full.isin([0,1]).all()]\n",
    "}\n",
    "\n",
    "\n",
    "for key, value in dfs.items():\n",
    "    suspect_cols = []\n",
    "    for i in range(value.shape[1]):\n",
    "        aled = value[value.columns[i]].value_counts()\n",
    "        percentage = aled.min() / aled.sum() * 100\n",
    "        if (percentage < 1).any():\n",
    "            suspect_cols.append(aled)\n",
    "    print(\"===== \", key, \" =====\")\n",
    "    print(suspect_cols)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# High correlation feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IONIZABLE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_io_corr = FS_ionizable.get_correlation()\n",
    "corr_feat_mtx = df_io_corr.to_numpy()\n",
    "\n",
    "\n",
    "# Determine optimun number of clusters for kmeans\n",
    "wcss = []\n",
    "max_num_clusters = 15\n",
    "for i in range(1, max_num_clusters):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(corr_feat_mtx)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, max_num_clusters), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_data_cluster(df_corr=df_io_corr, n_clusters=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Before high correlation removal: \", df_ionizable.shape)\n",
    "df_ionizable_correlation_removed = FS_ionizable.remove_highly_correlated(graph=True)\n",
    "print(\"After high correlation removal: \", df_ionizable_correlation_removed.shape)\n",
    "df_ionizable[df_ionizable.columns.difference(df_ionizable_correlation_removed.columns)].columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_io_corr = FS_ionizable.get_correlation(df_ionizable_correlation_removed)\n",
    "\n",
    "display_elbow(df_io_corr)\n",
    "display_data_cluster(df_corr=df_io_corr, n_clusters=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neutral"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ne_corr = FS_neutral.get_correlation()\n",
    "display_elbow(df_ne_corr)\n",
    "display_data_cluster(df_corr=df_ne_corr, n_clusters=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Before high correlation removal: \", df_neutral.shape)\n",
    "df_neutral_correlation_removed = FS_neutral.remove_highly_correlated(graph=True)\n",
    "print(\"After high correlation removal: \", df_neutral_correlation_removed.shape)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_seq_items', None):  # more options can be specified also\n",
    "    display(df_neutral[df_neutral.columns.difference(df_neutral_correlation_removed.columns)].columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ne_corr = FS_neutral.get_correlation(df_neutral_correlation_removed)\n",
    "\n",
    "display_elbow(df_ne_corr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_data_cluster(df_corr=df_io_corr, n_clusters=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Full"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_full_corr = FS_full.get_correlation()\n",
    "display_elbow(df_full_corr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_data_cluster(df_corr=df_full_corr, n_clusters=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Before high correlation removal: \", df_full.shape)\n",
    "df_full_correlation_removed = FS_full.remove_highly_correlated(graph=True)\n",
    "print(\"After high correlation removal: \", df_full_correlation_removed.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_full[df_full.columns.difference(df_full_correlation_removed.columns)].columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_full_corr = FS_full.get_correlation(df_full_correlation_removed)\n",
    "display_elbow(df_full_corr)\n",
    "display_data_cluster(df_corr=df_io_corr, n_clusters=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Proof of concept of the **transform** method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading the data and putting it in a FeatureSelector object\n",
    "df_full_train: pd.DataFrame = pd.read_csv(\"../../Data/full_dataset_train_divprio.csv\", delimiter=';')\n",
    "df_full_train[\"TYPE\"] = \"TRAIN\"\n",
    "df_full_test: pd.DataFrame = pd.read_csv(\"../../Data/full_dataset_test_divprio.csv\", delimiter=';')\n",
    "df_full_test[\"TYPE\"] = \"TEST\"\n",
    "\n",
    "df_full = pd.concat([df_full_train, df_full_test])\n",
    "FS_full: FeatureSelector = FeatureSelector(df_full, cols_to_ignore=[\"TYPE\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calling the automatic selection function\n",
    "final_df: pd.DataFrame = FS_full.transform()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df.equals(df_full_correlation_removed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the CSV files of the cleaned features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ionizable_train: pd.DataFrame = pd.read_csv(\"../../Data/ionizable_dataset_72_train_divprio.csv\", delimiter=';')\n",
    "df_ionizable_train[\"TYPE\"] = \"TRAIN\"\n",
    "df_ionizable_test: pd.DataFrame = pd.read_csv(\"../../Data/ionizable_dataset_72_test_divprio.csv\", delimiter=';')\n",
    "df_ionizable_test[\"TYPE\"] = \"TEST\"\n",
    "\n",
    "df_ionizable = pd.concat([df_ionizable_train, df_ionizable_test])\n",
    "FS_ionizable: FeatureSelector = FeatureSelector(df_ionizable, cols_to_ignore=[\"TYPE\"])\n",
    "\n",
    "\n",
    "\n",
    "df_neutral_train: pd.DataFrame = pd.read_csv(\"../../Data/neutral_dataset_111_train_divprio.csv\", delimiter=';')\n",
    "df_neutral_train[\"TYPE\"] = \"TRAIN\"\n",
    "df_neutral_test: pd.DataFrame = pd.read_csv(\"../../Data/neutral_dataset_111_test_divprio.csv\", delimiter=';')\n",
    "df_neutral_test[\"TYPE\"] = \"TEST\"\n",
    "\n",
    "df_neutral = pd.concat([df_neutral_train, df_neutral_test])\n",
    "FS_neutral: FeatureSelector = FeatureSelector(df_neutral, cols_to_ignore=[\"TYPE\"])\n",
    "\n",
    "\n",
    "df_full_train: pd.DataFrame = pd.read_csv(\"../../Data/full_dataset_train_divprio.csv\", delimiter=';')\n",
    "df_full_train[\"TYPE\"] = \"TRAIN\"\n",
    "df_full_test: pd.DataFrame = pd.read_csv(\"../../Data/full_dataset_test_divprio.csv\", delimiter=';')\n",
    "df_full_test[\"TYPE\"] = \"TEST\"\n",
    "\n",
    "df_full = pd.concat([df_full_train, df_full_test])\n",
    "FS_full: FeatureSelector = FeatureSelector(df_full, cols_to_ignore=[\"TYPE\"])\n",
    "\n",
    "\n",
    "save_path: str = \"../../Data/Filtered/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ionizable_df: pd.DataFrame = FS_ionizable.transform()\n",
    "neutral_df: pd.DataFrame = FS_neutral.transform()\n",
    "full_df: pd.DataFrame = FS_full.transform()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_train_test(df: pd.DataFrame, separator: str = \"TYPE\", y: str = \"Log_MP_RATIO\") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df_train = df.loc[df[separator] == \"TRAIN\"]\n",
    "    df_test = df.loc[df[separator] == \"TEST\"]\n",
    "\n",
    "    train_MP = df_train[\"Log_MP_RATIO\"]\n",
    "    test_MP = df_test[\"Log_MP_RATIO\"]\n",
    "\n",
    "    df_train = df_train.drop(columns=[separator, y])\n",
    "    df_test = df_test.drop(columns=[separator, y])\n",
    "\n",
    "    df_train.insert(0, y, train_MP)\n",
    "    df_test.insert(0, y, test_MP)\n",
    "\n",
    "    print(\"Train: \", df_train.shape, \"\\nTest: \", df_test.shape)\n",
    "    return df_train, df_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ionizable_train, ionizable_test = split_train_test(ionizable_df)\n",
    "ionizable_train.to_csv(save_path + \"ionizable_train.csv\", index=False, encoding='utf-8', sep=\";\")\n",
    "ionizable_test.to_csv(save_path + \"ionizable_test.csv\", index=False, encoding='utf-8', sep=\";\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neutral_train, neutral_test = split_train_test(neutral_df)\n",
    "neutral_train.to_csv(save_path + \"neutral_train.csv\", index=False, encoding=\"utf-8\", sep=\";\")\n",
    "neutral_test.to_csv(save_path + \"neutral_test.csv\", index=False, encoding=\"utf-8\", sep=\";\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_train, full_test = split_train_test(full_df)\n",
    "full_train.to_csv(save_path + \"full_train.csv\", index=False, encoding=\"utf-8\", sep=\";\")\n",
    "full_test.to_csv(save_path + \"full_test.csv\", index=False, encoding=\"utf-8\", sep=\";\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GRAPHS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "FS_full = FeatureSelector(df_full, cols_to_ignore=[\"TYPE\"])\n",
    "y_corr = FS_full.get_correlation_to_y(method=\"pearson\")\n",
    "# y_corr = y_corr.abs()\n",
    "y_corr = y_corr[y_corr.abs() > 0.5]\n",
    "full_corr = df_full.corr(method=\"pearson\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_full_correlated_y = df_full[y_corr.index]\n",
    "df_full_correlated_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_display = 1 - full_corr.loc[y_corr.index, y_corr.index]\n",
    "# linkage = hierarchy.linkage(distance.squareform(df_display), method=\"average\")\n",
    "# print(linkage)\n",
    "g = sns.clustermap(df_full_correlated_y.corr())\n",
    "\n",
    "# mask = np.tril(np.ones_like(df_display))\n",
    "# values = g.ax_heatmap.collections[0].get_array().reshape(df_display.shape)\n",
    "# new_values = np.ma.array(values, mask=mask)\n",
    "# g.ax_heatmap.collections[0].set_array(new_values)\n",
    "# display(g)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def corr_matrix_plot(df):\n",
    "    f, ax = plt.subplots(figsize=(12, 10))\n",
    "    corr = df.corr()\n",
    "    sns.heatmap(corr, mask=np.zeros_like(corr),\n",
    "                cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "                square=True, ax=ax)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
