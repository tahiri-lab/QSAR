{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code.wrapper import utils\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Normalization** increases the speed of calculation and reduces the alpha value while also increasing the score\n",
    "https://stats.stackexchange.com/a/189179"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "# https://stackoverflow.com/a/23835410\n",
    "\n",
    "excel_sheet = pd.read_excel(\"../Data/New/unfiltered_data.xlsx\", sheet_name=[\"full_train\", \"full_test\",\n",
    "                                                                               \"ionizable_train\", \"ionizable_test\",\n",
    "                                                                               \"neutral_train\", \"neutral_test\"])\n",
    "\n",
    "\n",
    "full_train: pd.DataFrame = excel_sheet[\"full_train\"]\n",
    "full_test: pd.DataFrame = excel_sheet[\"full_test\"]\n",
    "\n",
    "neutral_train: pd.DataFrame = excel_sheet[\"neutral_train\"]\n",
    "neutral_test: pd.DataFrame = excel_sheet[\"neutral_test\"]\n",
    "\n",
    "ionizable_train: pd.DataFrame = excel_sheet[\"ionizable_train\"]\n",
    "ionizable_test: pd.DataFrame = excel_sheet[\"ionizable_test\"]\n",
    "\n",
    "Scaler = RobustScaler()\n",
    "Norm = Normalizer()\n",
    "# TRAIN\n",
    "X_full_train = full_train.loc[:, full_train.columns != \"Log_MP_RATIO\"]\n",
    "y_full_train = full_train[\"Log_MP_RATIO\"]\n",
    "\n",
    "\n",
    "X_neutral_train = neutral_train.loc[:, neutral_train.columns != \"Log_MP_RATIO\"]\n",
    "y_neutral_train = neutral_train[\"Log_MP_RATIO\"]\n",
    "\n",
    "X_ionizable_train = ionizable_train.loc[:, ionizable_train.columns != \"Log_MP_RATIO\"]\n",
    "y_ionizable_train = ionizable_train[\"Log_MP_RATIO\"]\n",
    "# Scaler.fit(X_full_train)\n",
    "# X_full_train = pd.DataFrame(Scaler.transform(X_full_train), columns = X_full_train.columns)\n",
    "#\n",
    "# Norm.fit(X_full_train)\n",
    "# X_full_train = pd.DataFrame(Norm.transform(X_full_train), columns=X_full_train.columns)\n",
    "\n",
    "# TEST\n",
    "X_full_test = full_test.loc[:, full_test.columns != \"Log_MP_RATIO\"]\n",
    "y_full_test = full_test[\"Log_MP_RATIO\"]\n",
    "\n",
    "X_neutral_test = neutral_test.loc[:, neutral_test.columns != \"Log_MP_RATIO\"]\n",
    "y_neutral_test = neutral_test[\"Log_MP_RATIO\"]\n",
    "\n",
    "X_ionizable_test = ionizable_test.loc[:, ionizable_test.columns != \"Log_MP_RATIO\"]\n",
    "y_ionizable_test = ionizable_test[\"Log_MP_RATIO\"]\n",
    "#\n",
    "# Scaler.fit(X_full_test)\n",
    "# X_full_test = pd.DataFrame(Scaler.transform(X_full_test), columns = X_full_test.columns)\n",
    "#\n",
    "# Norm.fit(X_full_test)\n",
    "# X_full_test = pd.DataFrame(Norm.transform(X_full_test), columns=X_full_test.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_utils = utils.Utils(full_train)\n",
    "test_utils.create_cv_folds(display=True)\n",
    "test_utils.display_score(Ridge(), X_full_train, y_full_train, X_full_test, y_full_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1e10, log=True)\n",
    "\n",
    "    solver = trial.suggest_categorical('solver', [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"])\n",
    "\n",
    "    clf = Ridge(max_iter=100000, alpha=alpha, solver=solver)\n",
    "\n",
    "    # n_ft = trial.suggest_int('n_ft', 1, 10, log=True)\n",
    "    # clf = RFE(Ridge(max_iter=100000, alpha=alpha, solver=solver), n_features_to_select=n_ft)\n",
    "\n",
    "    estimator = utils.Utils(full_train)\n",
    "    # return cross_val_score(clf, X_full_train, y_full_train, cv=5, n_jobs=-1).mean()\n",
    "    return estimator.cross_value_score(clf)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "trial = study.best_trial\n",
    "print(trial.value, trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_utils.display_score(Ridge(**{'alpha': 117191.74850379501, 'solver': 'lsqr'}), X_full_train, y_full_train, X_full_test, y_full_test)\n",
    "# display(plot_optimization_history(study))\n",
    "\n",
    "rr = Ridge(**{'alpha': 117191.74850379501, 'solver': 'lsqr'}).fit(X_full_train, y_full_train)\n",
    "y_full_train_pred = rr.predict(X_full_train)\n",
    "y_full_test_pred = rr.predict(X_full_test)\n",
    "\n",
    "test_utils.display_graph(rr, X_full_train, X_full_test, y_full_train, y_full_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rr = Ridge(max_iter=100000, **({'alpha': 117191.74850379501, 'solver': 'lsqr'}))\n",
    "rr.fit(X_full_train, y_full_train)\n",
    "\n",
    "\n",
    "hyper_params = [{\"n_features_to_select\": list(range(1,len(X_full_train.columns)))}]\n",
    "\n",
    "rfe = RFE(rr, step=1)\n",
    "\n",
    "model_cv = GridSearchCV(estimator=rfe,\n",
    "                        param_grid=hyper_params,\n",
    "                        scoring=\"r2\",\n",
    "                        cv=3,\n",
    "                        verbose=2,\n",
    "                        return_train_score=True,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "\n",
    "model_cv.fit(X_full_train, y_full_train)\n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "best_rfe = model_cv.best_estimator_\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel(\"number of features\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.title(\"Optimal number of features\")\n",
    "plt.legend([\"test score\", \"train score\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_utils.display_score(best_rfe,\n",
    "                         X_full_train, y_full_train,\n",
    "                         X_full_test, y_full_test)\n",
    "\n",
    "print(\"Selected features:\", best_rfe.get_feature_names_out())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_utils.display_score(best_rfe, X_full_train, y_full_train, X_full_test, y_full_test)\n",
    "# display(plot_optimization_history(study))\n",
    "\n",
    "rr = best_rfe.fit(X_full_train, y_full_train)\n",
    "y_full_train_pred = rr.predict(X_full_train)\n",
    "y_full_test_pred = rr.predict(X_full_test)\n",
    "\n",
    "test_utils.display_graph(rr, X_full_train, X_full_test, y_full_train, y_full_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ionizable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_utils = utils.Utils(ionizable_train)\n",
    "test_utils.create_cv_folds(display=True)\n",
    "test_utils.display_score(Ridge(), X_ionizable_train, y_ionizable_train, X_ionizable_test, y_ionizable_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1e10, log=True)\n",
    "\n",
    "    solver = trial.suggest_categorical('solver', [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"])\n",
    "\n",
    "    clf = Ridge(max_iter=100000, alpha=alpha, solver=solver)\n",
    "\n",
    "    # n_ft = trial.suggest_int('n_ft', 1, 10, log=True)\n",
    "    # clf = RFE(Ridge(max_iter=100000, alpha=alpha, solver=solver), n_features_to_select=n_ft)\n",
    "\n",
    "    estimator = utils.Utils(ionizable_train)\n",
    "    # return cross_val_score(clf, X_ionizable_train, y_ionizable_train, cv=5, n_jobs=-1).mean()\n",
    "    return estimator.cross_value_score(clf)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "trial = study.best_trial\n",
    "print(trial.value, trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rr = Ridge(max_iter=100000, **({'alpha': 23051583.217470333, 'solver': 'sparse_cg'}))\n",
    "rr.fit(X_ionizable_train, y_ionizable_train)\n",
    "\n",
    "\n",
    "hyper_params = [{\"n_features_to_select\": list(range(1,len(X_ionizable_train.columns)))}]\n",
    "\n",
    "rfe = RFE(rr, step=1)\n",
    "\n",
    "model_cv = GridSearchCV(estimator=rfe,\n",
    "                        param_grid=hyper_params,\n",
    "                        scoring=\"r2\",\n",
    "                        cv=3,\n",
    "                        verbose=2,\n",
    "                        return_train_score=True,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "\n",
    "model_cv.fit(X_ionizable_train, y_ionizable_train)\n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "best_rfe = model_cv.best_estimator_\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel(\"number of features\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.title(\"Optimal number of features\")\n",
    "plt.legend([\"test score\", \"train score\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_utils.display_score(best_rfe,\n",
    "                         X_ionizable_train, y_ionizable_train,\n",
    "                         X_ionizable_test, y_ionizable_test)\n",
    "\n",
    "print(\"Selected features:\", best_rfe.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# display(plot_optimization_history(study))\n",
    "\n",
    "rr = Ridge(**({'alpha': 23051583.217470333, 'solver': 'sparse_cg'})).fit(X_ionizable_train, y_ionizable_train)\n",
    "y_ionizable_train_pred = rr.predict(X_ionizable_train)\n",
    "y_ionizable_test_pred = rr.predict(X_ionizable_test)\n",
    "\n",
    "test_utils.display_graph(rr, X_ionizable_train, X_ionizable_test, y_ionizable_train, y_ionizable_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neutral"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_utils = utils.Utils(neutral_train)\n",
    "test_utils.create_cv_folds(display=True)\n",
    "test_utils.display_score(Ridge(), X_neutral_train, y_neutral_train, X_neutral_test, y_neutral_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1e10, log=True)\n",
    "\n",
    "    solver = trial.suggest_categorical('solver', [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"])\n",
    "\n",
    "    clf = Ridge(max_iter=100000, alpha=alpha, solver=solver)\n",
    "\n",
    "    # n_ft = trial.suggest_int('n_ft', 1, 10, log=True)\n",
    "    # clf = RFE(Ridge(max_iter=100000, alpha=alpha, solver=solver), n_features_to_select=n_ft)\n",
    "\n",
    "    estimator = utils.Utils(neutral_train)\n",
    "    # return cross_val_score(clf, X_neutral_train, y_neutral_train, cv=5, n_jobs=-1).mean()\n",
    "    return estimator.cross_value_score(clf)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "trial = study.best_trial\n",
    "print(trial.value, trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rr = Ridge(max_iter=100000, **{'alpha': 19553992.061135184, 'solver': 'lsqr'})\n",
    "rr.fit(X_neutral_train, y_neutral_train)\n",
    "\n",
    "\n",
    "hyper_params = [{\"n_features_to_select\": list(range(1,len(X_neutral_train.columns)))}]\n",
    "\n",
    "rfe = RFE(rr, step=1)\n",
    "\n",
    "model_cv = GridSearchCV(estimator=rfe,\n",
    "                        param_grid=hyper_params,\n",
    "                        scoring=\"r2\",\n",
    "                        cv=3,\n",
    "                        verbose=2,\n",
    "                        return_train_score=True,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "\n",
    "model_cv.fit(X_neutral_train, y_neutral_train)\n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "best_rfe = model_cv.best_estimator_\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel(\"number of features\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.title(\"Optimal number of features\")\n",
    "plt.legend([\"cross-value score\", \"train score\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_utils.display_score(best_rfe,\n",
    "                         X_neutral_train, y_neutral_train,\n",
    "                         X_neutral_test, y_neutral_test)\n",
    "\n",
    "\n",
    "print(\"Selected features:\", best_rfe.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# display(plot_optimization_history(study))\n",
    "\n",
    "rr = Ridge(**{'alpha': 19553992.061135184, 'solver': 'lsqr'}).fit(X_full_train, y_full_train)\n",
    "y_full_train_pred = rr.predict(X_full_train)\n",
    "y_full_test_pred = rr.predict(X_full_test)\n",
    "\n",
    "test_utils.display_graph(rr, X_full_train, X_full_test, y_full_train, y_full_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Demo of good R2 Q2 but bad cross val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, ShuffleSplit, StratifiedShuffleSplit\n",
    "\n",
    "# THIS IS AN EXEMPLE OF A \"GOOD\" R2 and Q2 but it won't be found because the cross val is low\n",
    "\n",
    "\n",
    "\n",
    "rr = Ridge()\n",
    "rr.fit(X_full_train, y_full_train)\n",
    "\n",
    "rfe = RFE(rr, n_features_to_select=20)\n",
    "rfe = rfe.fit(X_full_train, y_full_train)\n",
    "\n",
    "\n",
    "print(rfe.score(X_full_train, y_full_train))\n",
    "print(rfe.score(X_full_test, y_full_test))\n",
    "print(cross_val_score(rfe, X_full_train, y_full_train, scoring=\"r2\", cv=ShuffleSplit(n_splits=4,test_size=0.1,random_state=0)).mean())\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
