{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-16T19:31:52.132696876Z",
     "start_time": "2023-06-16T19:31:52.122002745Z"
    }
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_intermediate_values\n",
    "\n",
    "\n",
    "# def warn(*args, **kwargs):\n",
    "#     pass\n",
    "# import warnings\n",
    "# warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from code.wrapper import utils\n",
    "\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer\n",
    "# https://stackoverflow.com/a/23835410\n",
    "\n",
    "excel_sheet = pd.read_excel(\"../Data/New/unfiltered_data.xlsx\", sheet_name=[\"full_train\", \"full_test\",\n",
    "                                                                            \"ionizable_train\", \"ionizable_test\",\n",
    "                                                                            \"neutral_train\", \"neutral_test\"])\n",
    "\n",
    "\n",
    "full_train: pd.DataFrame = excel_sheet[\"full_train\"]\n",
    "full_test: pd.DataFrame = excel_sheet[\"full_test\"]\n",
    "\n",
    "neutral_train: pd.DataFrame = excel_sheet[\"neutral_train\"]\n",
    "neutral_test: pd.DataFrame = excel_sheet[\"neutral_test\"]\n",
    "\n",
    "ionizable_train: pd.DataFrame = excel_sheet[\"ionizable_train\"]\n",
    "ionizable_test: pd.DataFrame = excel_sheet[\"ionizable_test\"]\n",
    "\n",
    "Scaler = RobustScaler()\n",
    "Norm = Normalizer()\n",
    "# TRAIN\n",
    "X_full_train = full_train.loc[:, full_train.columns != \"Log_MP_RATIO\"]\n",
    "y_full_train = full_train[\"Log_MP_RATIO\"]\n",
    "\n",
    "\n",
    "X_neutral_train = neutral_train.loc[:, neutral_train.columns != \"Log_MP_RATIO\"]\n",
    "y_neutral_train = neutral_train[\"Log_MP_RATIO\"]\n",
    "\n",
    "X_ionizable_train = ionizable_train.loc[:, ionizable_train.columns != \"Log_MP_RATIO\"]\n",
    "y_ionizable_train = ionizable_train[\"Log_MP_RATIO\"]\n",
    "# Scaler.fit(X_full_train)\n",
    "# X_full_train = pd.DataFrame(Scaler.transform(X_full_train), columns = X_full_train.columns)\n",
    "#\n",
    "# Norm.fit(X_full_train)\n",
    "# X_full_train = pd.DataFrame(Norm.transform(X_full_train), columns=X_full_train.columns)\n",
    "\n",
    "# TEST\n",
    "X_full_test = full_test.loc[:, full_test.columns != \"Log_MP_RATIO\"]\n",
    "y_full_test = full_test[\"Log_MP_RATIO\"]\n",
    "\n",
    "X_neutral_test = neutral_test.loc[:, neutral_test.columns != \"Log_MP_RATIO\"]\n",
    "y_neutral_test = neutral_test[\"Log_MP_RATIO\"]\n",
    "\n",
    "X_ionizable_test = ionizable_test.loc[:, ionizable_test.columns != \"Log_MP_RATIO\"]\n",
    "y_ionizable_test = ionizable_test[\"Log_MP_RATIO\"]\n",
    "#\n",
    "# Scaler.fit(X_full_test)\n",
    "# X_full_test = pd.DataFrame(Scaler.transform(X_full_test), columns = X_full_test.columns)\n",
    "#\n",
    "# Norm.fit(X_full_test)\n",
    "# X_full_test = pd.DataFrame(Norm.transform(X_full_test), columns=X_full_test.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T18:16:13.863169112Z",
     "start_time": "2023-06-16T18:16:11.872548075Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 3 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      "\tR2\t\t\t\t:\t 0.6336190473666746 \n",
      "\tCV train\t\t:\t 0.2719491331954161 \n",
      "\tCustom CV train\t:\t 0.3327321627630588 \n",
      "\tQ2\t\t\t\t:\t 0.1990222236299406\n"
     ]
    }
   ],
   "source": [
    "test_utils = utils.Utils(full_train)\n",
    "test_utils.create_cv_folds(display=True)\n",
    "test_utils.display_score(ElasticNet(max_iter=100000, random_state=0), X_full_train, y_full_train, X_full_test, y_full_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T18:28:14.517872395Z",
     "start_time": "2023-06-16T18:28:00.462475107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:23:48,059] A new study created in memory with name: no-name-bceeb9fe-a904-4986-a873-2e8a9ba4730b\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd380e7b0aa54a60a46b492606644a3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:23:49,131] Trial 2 finished with value: -1.4544204143926058 and parameters: {'alpha': 3.240037611199972e-08, 'l1_ratio': 0.15666170846706146}. Best is trial 2 with value: -1.4544204143926058.\n",
      "[I 2023-06-16 16:23:49,201] Trial 0 finished with value: -1.4588566440063353 and parameters: {'alpha': 2.0906372214204996e-09, 'l1_ratio': 1.7612578807631209e-09}. Best is trial 2 with value: -1.4544204143926058.\n",
      "[I 2023-06-16 16:23:49,510] Trial 4 finished with value: -1.4592894203414815 and parameters: {'alpha': 1.5156846606170913e-10, 'l1_ratio': 0.0009347701229623113}. Best is trial 2 with value: -1.4544204143926058.\n",
      "[I 2023-06-16 16:23:49,551] Trial 9 finished with value: -0.015530983180227128 and parameters: {'alpha': 181791367.33304393, 'l1_ratio': 0.00859573421719675}. Best is trial 9 with value: -0.015530983180227128.\n",
      "[I 2023-06-16 16:23:49,770] Trial 10 finished with value: -0.015500695097565983 and parameters: {'alpha': 1050413596.2293283, 'l1_ratio': 1.2713136546403835e-09}. Best is trial 10 with value: -0.015500695097565983.\n",
      "[I 2023-06-16 16:23:50,032] Trial 12 finished with value: 0.18025439973100474 and parameters: {'alpha': 1383038.3986101274, 'l1_ratio': 6.493920160581272e-10}. Best is trial 12 with value: 0.18025439973100474.\n",
      "[I 2023-06-16 16:23:51,049] Trial 13 finished with value: -1.4608882846383286 and parameters: {'alpha': 3.972157142820058e-07, 'l1_ratio': 0.0004928843329633952}. Best is trial 12 with value: 0.18025439973100474.\n",
      "[I 2023-06-16 16:23:51,414] Trial 1 finished with value: -1.4186238795506367 and parameters: {'alpha': 7.096016710463027e-07, 'l1_ratio': 1.0412932459747858e-10}. Best is trial 12 with value: 0.18025439973100474.\n",
      "[I 2023-06-16 16:23:51,625] Trial 7 finished with value: -1.2659143003247595 and parameters: {'alpha': 7.730573249069138e-06, 'l1_ratio': 2.9886507873276206e-09}. Best is trial 12 with value: 0.18025439973100474.\n",
      "[I 2023-06-16 16:23:52,291] Trial 11 finished with value: 0.3572658715830546 and parameters: {'alpha': 22.224330787661, 'l1_ratio': 0.0718639783203082}. Best is trial 11 with value: 0.3572658715830546.\n",
      "[I 2023-06-16 16:23:52,653] Trial 17 finished with value: 0.32058660350081286 and parameters: {'alpha': 49.79906709299318, 'l1_ratio': 0.4046104028825755}. Best is trial 11 with value: 0.3572658715830546.\n",
      "[I 2023-06-16 16:23:52,856] Trial 18 finished with value: 0.10710902288645618 and parameters: {'alpha': 134.40785555772723, 'l1_ratio': 0.6630694520703359}. Best is trial 11 with value: 0.3572658715830546.\n",
      "[I 2023-06-16 16:23:54,602] Trial 19 finished with value: 0.35549691245468323 and parameters: {'alpha': 2.017016899578117, 'l1_ratio': 0.8819281291372241}. Best is trial 11 with value: 0.3572658715830546.\n",
      "[I 2023-06-16 16:23:54,781] Trial 5 finished with value: -1.2851724293152476 and parameters: {'alpha': 5.25665128903121e-05, 'l1_ratio': 4.711249491244871e-09}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.172e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.763e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.466e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.285e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.524e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.817e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.937e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.125e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.438e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.094e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:24:41,050] Trial 16 finished with value: -1.618533230604383 and parameters: {'alpha': 0.03763760388109042, 'l1_ratio': 0.30322441973937053}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.439e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:24:42,440] Trial 3 finished with value: 0.34216137737701824 and parameters: {'alpha': 768.7800474161819, 'l1_ratio': 1.3831188648108083e-06}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:24:52,314] Trial 20 finished with value: -3.292956266082208 and parameters: {'alpha': 0.018653716122563155, 'l1_ratio': 0.01073362150335118}. Best is trial 11 with value: 0.3572658715830546.\n",
      "[I 2023-06-16 16:24:52,532] Trial 24 finished with value: -0.015530983180227128 and parameters: {'alpha': 25731.586497119886, 'l1_ratio': 0.03145551005119586}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:24:53,595] Trial 15 finished with value: -0.9927486221172465 and parameters: {'alpha': 0.9968277966153822, 'l1_ratio': 6.169433856588499e-05}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:24:55,482] Trial 6 finished with value: -1.0181034118687586 and parameters: {'alpha': 0.9274021412343176, 'l1_ratio': 0.00048517049065362465}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.750e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:24:59,076] Trial 14 finished with value: -1.8180348210106962 and parameters: {'alpha': 0.0006225962049571979, 'l1_ratio': 5.837428438220421e-08}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.042e+00, tolerance: 4.591e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:24:59,859] Trial 8 finished with value: 0.023625995974864034 and parameters: {'alpha': 16.82959333318621, 'l1_ratio': 7.117405538860166e-06}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.696e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.218e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:02,511] Trial 21 finished with value: -3.0454415634994234 and parameters: {'alpha': 0.010125455824745274, 'l1_ratio': 2.143575333772087e-05}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.940e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:15,111] Trial 30 finished with value: 0.33491988500858355 and parameters: {'alpha': 5388.094266260341, 'l1_ratio': 7.058931766235261e-07}. Best is trial 11 with value: 0.3572658715830546.\n",
      "[I 2023-06-16 16:25:15,413] Trial 31 finished with value: 0.26951701759981045 and parameters: {'alpha': 795.8837790599543, 'l1_ratio': 0.06408591099135431}. Best is trial 11 with value: 0.3572658715830546.\n",
      "[I 2023-06-16 16:25:15,719] Trial 32 finished with value: -0.015530983180227128 and parameters: {'alpha': 61855.648261603295, 'l1_ratio': 0.6054381442332205}. Best is trial 11 with value: 0.3572658715830546.\n",
      "[I 2023-06-16 16:25:15,920] Trial 29 finished with value: 0.33983561911351234 and parameters: {'alpha': 2712.4040396868663, 'l1_ratio': 1.6655406519919888e-06}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.454e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.456e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:26,903] Trial 33 finished with value: 0.22035503036760481 and parameters: {'alpha': 16.65259767131658, 'l1_ratio': 0.007307321498576213}. Best is trial 11 with value: 0.3572658715830546.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.533e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:31,668] Trial 35 finished with value: 0.35866430895057694 and parameters: {'alpha': 1.084483226919104, 'l1_ratio': 0.9284222397089379}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:32,605] Trial 22 finished with value: -3.318535151838067 and parameters: {'alpha': 0.01807772943695826, 'l1_ratio': 0.014656026495230031}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:33,172] Trial 34 finished with value: 0.2978541917178748 and parameters: {'alpha': 7.631496310598561, 'l1_ratio': 0.03953605631421224}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.996e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:34,219] Trial 23 finished with value: -2.438316439548156 and parameters: {'alpha': 0.07388835912047288, 'l1_ratio': 0.01470164846581545}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:34,455] Trial 39 finished with value: -0.015530983180227128 and parameters: {'alpha': 394.8679444063131, 'l1_ratio': 0.9669619847838972}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:42,239] Trial 27 finished with value: -4.113433421282801 and parameters: {'alpha': 0.0009346200746853411, 'l1_ratio': 0.8303850947326461}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:42,457] Trial 37 finished with value: 0.12932749082335837 and parameters: {'alpha': 1.092838202221985, 'l1_ratio': 0.10269224224321304}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:42,725] Trial 26 finished with value: -3.3868368865403897 and parameters: {'alpha': 0.00044006589213291036, 'l1_ratio': 0.8710652939562434}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:42,936] Trial 42 finished with value: 0.31749073414887985 and parameters: {'alpha': 100.05848280905303, 'l1_ratio': 0.22954841336410034}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:43,256] Trial 43 finished with value: 0.3175486877282333 and parameters: {'alpha': 172.5407605371581, 'l1_ratio': 0.14520381721487471}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:46,152] Trial 40 finished with value: -0.0014153394919703688 and parameters: {'alpha': 1.3110600808109893, 'l1_ratio': 0.054869088110398506}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:47,209] Trial 36 finished with value: 0.31373835674571315 and parameters: {'alpha': 0.4438269267700925, 'l1_ratio': 0.8697045848599596}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:51,075] Trial 41 finished with value: 0.05550761445672888 and parameters: {'alpha': 1.3334511523790589, 'l1_ratio': 0.06259694534124138}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.275e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:53,091] Trial 38 finished with value: 0.2425865490743435 and parameters: {'alpha': 0.257337217652338, 'l1_ratio': 0.8017018816740606}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:55,367] Trial 25 finished with value: -1.3989318076014794 and parameters: {'alpha': 0.47950371130886754, 'l1_ratio': 0.0003294360132345671}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.199e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:25:55,911] Trial 28 finished with value: 0.3340060028910736 and parameters: {'alpha': 399.8437526463856, 'l1_ratio': 1.9944520034414585e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:25:57,471] Trial 47 finished with value: 0.058950514407528666 and parameters: {'alpha': 12.796630465245395, 'l1_ratio': 0.0021794351476732334}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.174e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.704e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:26:04,942] Trial 48 finished with value: 0.33701257267914336 and parameters: {'alpha': 3945.887326709132, 'l1_ratio': 1.4824071257246999e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:26:05,118] Trial 53 finished with value: -0.015530983180227128 and parameters: {'alpha': 448621.1950014823, 'l1_ratio': 0.1649605872717571}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:26:08,785] Trial 51 finished with value: 0.06594382135104937 and parameters: {'alpha': 11.17346068218987, 'l1_ratio': 0.0033777413818564398}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.554e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.450e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:26:21,127] Trial 52 finished with value: 0.3370592974448212 and parameters: {'alpha': 3880.4780394689574, 'l1_ratio': 3.0392138227095755e-07}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:26:21,607] Trial 56 finished with value: 0.3166631619834335 and parameters: {'alpha': 42.634885332735, 'l1_ratio': 0.18627199243975626}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.566e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:26:26,861] Trial 46 finished with value: -0.5628248380931161 and parameters: {'alpha': 0.23894308013064758, 'l1_ratio': 0.1446398601860931}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:26:27,286] Trial 50 finished with value: 0.3411702716182422 and parameters: {'alpha': 2238.710976118063, 'l1_ratio': 1.2569316470968414e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:26:37,704] Trial 54 finished with value: 0.34086502615278663 and parameters: {'alpha': 2329.9170956852195, 'l1_ratio': 4.010624610609998e-07}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:26:38,558] Trial 44 finished with value: -1.1737488389175899 and parameters: {'alpha': 0.6457816035097171, 'l1_ratio': 0.002238905303578539}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:26:40,120] Trial 55 finished with value: 0.3399125025660407 and parameters: {'alpha': 2656.3634616964728, 'l1_ratio': 8.520305932747903e-08}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:26:41,798] Trial 61 finished with value: 0.3398038819718452 and parameters: {'alpha': 35323.75120124294, 'l1_ratio': 7.635495107385818e-08}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:26:47,311] Trial 45 finished with value: -1.3870978362141995 and parameters: {'alpha': 0.445427549753611, 'l1_ratio': 0.002258753106176581}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:26:53,658] Trial 59 finished with value: 0.3428946303035355 and parameters: {'alpha': 1748.3579858835583, 'l1_ratio': 8.044248696397792e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:27:00,572] Trial 57 finished with value: 0.3426261530747236 and parameters: {'alpha': 813.2647886552081, 'l1_ratio': 6.028288262387034e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.006e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.191e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:27:10,932] Trial 49 finished with value: -0.1089600358672342 and parameters: {'alpha': 9.972969618977498, 'l1_ratio': 1.1717220306987056e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.376e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:27:22,579] Trial 58 finished with value: 0.3430656613920456 and parameters: {'alpha': 1555.5721884866975, 'l1_ratio': 2.057637857217884e-07}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.349e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.440e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.294e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.582e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.472e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:27:43,883] Trial 67 finished with value: 0.2351915885891488 and parameters: {'alpha': 55.243936143010664, 'l1_ratio': 0.00018772862427401564}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.871e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.291e+00, tolerance: 4.591e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.067e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:27:57,477] Trial 63 finished with value: 0.24269347388740617 and parameters: {'alpha': 63.92595687716711, 'l1_ratio': 1.0659801271799658e-05}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:27:57,655] Trial 60 finished with value: -0.28906591989821184 and parameters: {'alpha': 5.493079513339144, 'l1_ratio': 1.0696227305410547e-07}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.948e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:27:59,338] Trial 62 finished with value: -0.28947352898421286 and parameters: {'alpha': 5.480081423110035, 'l1_ratio': 8.984711873262441e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.263e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:28:03,528] Trial 64 finished with value: 0.22539670765738998 and parameters: {'alpha': 54.64166663302754, 'l1_ratio': 6.122698653829969e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:28:07,887] Trial 69 finished with value: 0.34328843016891925 and parameters: {'alpha': 911.6322843491316, 'l1_ratio': 1.012890240535931e-05}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.879e+00, tolerance: 4.591e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.847e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:28:11,347] Trial 65 finished with value: -0.3246935341885149 and parameters: {'alpha': 4.929783654901841, 'l1_ratio': 7.173868674662597e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.827e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:28:13,224] Trial 66 finished with value: -0.32852952940247465 and parameters: {'alpha': 4.872974968431883, 'l1_ratio': 8.977706666342493e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:28:13,406] Trial 75 finished with value: -0.015530983180227128 and parameters: {'alpha': 22529.705124822838, 'l1_ratio': 0.3020149607252176}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.142e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.653e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:28:25,439] Trial 76 finished with value: 0.3395437399406364 and parameters: {'alpha': 475.9853287575421, 'l1_ratio': 0.00010449869586925186}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:28:30,180] Trial 77 finished with value: 0.3421545316798636 and parameters: {'alpha': 693.5233942905022, 'l1_ratio': 4.771325675585541e-05}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:28:31,416] Trial 72 finished with value: 0.33545896210178877 and parameters: {'alpha': 413.5440558481504, 'l1_ratio': 3.4676937095914516e-05}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.598e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:28:35,758] Trial 68 finished with value: 0.2566912048915019 and parameters: {'alpha': 74.16304218442494, 'l1_ratio': 5.1349734044103125e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:28:35,984] Trial 81 finished with value: -0.015530983180227128 and parameters: {'alpha': 9543.257234419858, 'l1_ratio': 0.42565945130326704}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:28:36,570] Trial 82 finished with value: 0.3364179500414026 and parameters: {'alpha': 108672.10782931189, 'l1_ratio': 1.898955151224188e-05}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:28:38,569] Trial 74 finished with value: 0.33553891230776783 and parameters: {'alpha': 414.35774045407607, 'l1_ratio': 3.6312769374795136e-05}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:28:39,067] Trial 73 finished with value: 0.3227062378834569 and parameters: {'alpha': 236.34416509811987, 'l1_ratio': 5.809899221073838e-05}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.489e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.685e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:28:55,088] Trial 70 finished with value: 0.3306977645905042 and parameters: {'alpha': 338.1678701732456, 'l1_ratio': 4.738211397035273e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.106e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.576e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:00,818] Trial 71 finished with value: 0.3222144998955559 and parameters: {'alpha': 243.02322582841066, 'l1_ratio': 5.44142804981681e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.161e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.707e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:12,017] Trial 87 finished with value: 0.332995077061896 and parameters: {'alpha': 9945.194620027702, 'l1_ratio': 1.9857401941118034e-08}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.074e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:19,051] Trial 85 finished with value: 0.34352993099701296 and parameters: {'alpha': 1371.6836114098335, 'l1_ratio': 2.9210344919982588e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.821e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.900e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:22,472] Trial 79 finished with value: 0.32008851483832546 and parameters: {'alpha': 223.747800519993, 'l1_ratio': 2.4732332298932338e-05}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.330e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.740e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:24,198] Trial 78 finished with value: 0.3356873471001011 and parameters: {'alpha': 438.80233910877877, 'l1_ratio': 3.4488672217910933e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:37,541] Trial 86 finished with value: 0.34363297658866526 and parameters: {'alpha': 1239.1156306578464, 'l1_ratio': 2.7949317758333427e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.511e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:43,357] Trial 80 finished with value: 0.311591958383739 and parameters: {'alpha': 179.276092265419, 'l1_ratio': 3.5120588126691373e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.564e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.992e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:46,966] Trial 83 finished with value: 0.31990929657122014 and parameters: {'alpha': 226.5975325235457, 'l1_ratio': 2.0936731945364196e-08}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:29:47,096] Trial 94 finished with value: 0.30289869328226565 and parameters: {'alpha': 1467.7100442760716, 'l1_ratio': 0.026009418997159833}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:49,598] Trial 84 finished with value: -2.552278580876953 and parameters: {'alpha': 0.06622064706704071, 'l1_ratio': 2.5415201670828777e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:29:50,843] Trial 88 finished with value: 0.3432552668825773 and parameters: {'alpha': 947.3206382014207, 'l1_ratio': 2.5976432224132896e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:29:53,274] Trial 95 finished with value: 0.3330673912108459 and parameters: {'alpha': 10982.78253638735, 'l1_ratio': 7.509632043642259e-07}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:29:54,766] Trial 89 finished with value: 0.3433832338164791 and parameters: {'alpha': 986.1607463977743, 'l1_ratio': 2.867143630246812e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:29:55,395] Trial 90 finished with value: 0.3431160500204338 and parameters: {'alpha': 1576.337382144327, 'l1_ratio': 2.5990245545659454e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.523e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:29:58,759] Trial 97 finished with value: 0.3333014167749549 and parameters: {'alpha': 8004.788879555039, 'l1_ratio': 8.43583346444554e-07}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.834e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.627e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.846e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.486e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.283e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.612e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.456e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:30:29,409] Trial 91 finished with value: 0.08458993578110534 and parameters: {'alpha': 22.3872870543745, 'l1_ratio': 6.66530362202587e-07}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:30:32,505] Trial 96 finished with value: 0.34356435978747873 and parameters: {'alpha': 1262.7571605623066, 'l1_ratio': 8.59732178262214e-07}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.129e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.517e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:30:40,731] Trial 92 finished with value: 0.10621048729256448 and parameters: {'alpha': 24.984375544897894, 'l1_ratio': 3.363418346683845e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:30:40,917] Trial 99 finished with value: 0.34362671451946114 and parameters: {'alpha': 1172.1441044591322, 'l1_ratio': 2.1588599156809198e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:30:41,196] Trial 105 finished with value: -0.015530983180227128 and parameters: {'alpha': 64485.911612599164, 'l1_ratio': 0.4522425403603847}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.829e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.937e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.756e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.868e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.574e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:30:57,239] Trial 93 finished with value: 0.11362359788401366 and parameters: {'alpha': 25.99447051004856, 'l1_ratio': 2.601692877434117e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.736e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:03,942] Trial 98 finished with value: 0.14007708989977863 and parameters: {'alpha': 30.140209731020633, 'l1_ratio': 2.319187172193272e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.363e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.444e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:08,014] Trial 100 finished with value: 0.08795102420329966 and parameters: {'alpha': 22.756756521063426, 'l1_ratio': 2.1268862390987074e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.549e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:09,598] Trial 101 finished with value: 0.10764145966097678 and parameters: {'alpha': 25.182446407470625, 'l1_ratio': 2.2238972889339105e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.128e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:23,367] Trial 109 finished with value: 0.33538735142924614 and parameters: {'alpha': 5016.016914757978, 'l1_ratio': 1.3849093304966858e-06}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:23,837] Trial 111 finished with value: 0.0676674772685731 and parameters: {'alpha': 1139.3171614839673, 'l1_ratio': 0.09018588642229312}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.045e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:29,349] Trial 110 finished with value: 0.34396407806549234 and parameters: {'alpha': 1191.6176597090514, 'l1_ratio': 1.4392457132704187e-05}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:30,127] Trial 104 finished with value: 0.3436294319533494 and parameters: {'alpha': 1178.530860021423, 'l1_ratio': 2.232088094538831e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.799e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:33,191] Trial 108 finished with value: 0.3432729458915366 and parameters: {'alpha': 883.4564408355255, 'l1_ratio': 1.4855895220951925e-05}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:33,220] Trial 113 finished with value: 0.35559305952517556 and parameters: {'alpha': 2.002615119862817, 'l1_ratio': 0.6225275746936918}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:35,182] Trial 115 finished with value: 0.35449940302888366 and parameters: {'alpha': 3.0265191278623114, 'l1_ratio': 0.6181115650096641}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:35,444] Trial 116 finished with value: 0.353275923454508 and parameters: {'alpha': 2.14946277556599, 'l1_ratio': 0.9010547370184071}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:38,067] Trial 118 finished with value: 0.3584358498271417 and parameters: {'alpha': 2.6393707267635, 'l1_ratio': 0.5622837849404161}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:38,275] Trial 117 finished with value: 0.3556806905288994 and parameters: {'alpha': 2.5961371128142994, 'l1_ratio': 0.47003735675323294}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:41,842] Trial 119 finished with value: 0.3556802369386711 and parameters: {'alpha': 2.2344938585516574, 'l1_ratio': 0.5526538301719753}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:44,901] Trial 121 finished with value: 0.3552871489429807 and parameters: {'alpha': 2.009034883697931, 'l1_ratio': 0.5731587594727826}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:45,434] Trial 120 finished with value: 0.35823191211381694 and parameters: {'alpha': 1.3658379748888778, 'l1_ratio': 0.6453024231809769}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:46,685] Trial 102 finished with value: 0.12525507384321607 and parameters: {'alpha': 27.705923960278085, 'l1_ratio': 1.9733075326579075e-06}. Best is trial 35 with value: 0.35866430895057694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.160e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:48,634] Trial 124 finished with value: 0.34775853994064815 and parameters: {'alpha': 2.4491184915427247, 'l1_ratio': 0.9806290047271404}. Best is trial 35 with value: 0.35866430895057694.\n",
      "[I 2023-06-16 16:31:48,760] Trial 123 finished with value: 0.3589629641662819 and parameters: {'alpha': 2.298510253607165, 'l1_ratio': 0.6061476450312111}. Best is trial 123 with value: 0.3589629641662819.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.735e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:49,785] Trial 103 finished with value: 0.13810773271791368 and parameters: {'alpha': 29.802466279269076, 'l1_ratio': 1.780835882983013e-06}. Best is trial 123 with value: 0.3589629641662819.\n",
      "[I 2023-06-16 16:31:54,209] Trial 125 finished with value: 0.35767131413199565 and parameters: {'alpha': 1.0491678355315666, 'l1_ratio': 0.9969448010015778}. Best is trial 123 with value: 0.3589629641662819.\n",
      "[I 2023-06-16 16:31:55,158] Trial 126 finished with value: 0.3577516548496169 and parameters: {'alpha': 1.551528165408014, 'l1_ratio': 0.5339208085740278}. Best is trial 123 with value: 0.3589629641662819.\n",
      "[I 2023-06-16 16:31:55,814] Trial 122 finished with value: 0.3475912627734778 and parameters: {'alpha': 0.952305985339784, 'l1_ratio': 0.6667723562421951}. Best is trial 123 with value: 0.3589629641662819.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.527e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:31:56,368] Trial 106 finished with value: -0.4976968424495506 and parameters: {'alpha': 3.043235176150612, 'l1_ratio': 1.6515021306339164e-06}. Best is trial 123 with value: 0.3589629641662819.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.322e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:32:00,080] Trial 128 finished with value: 0.3590101021316477 and parameters: {'alpha': 1.644323744842163, 'l1_ratio': 0.5651966026772418}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:03,596] Trial 127 finished with value: 0.3346303442322133 and parameters: {'alpha': 1.7757779770387965, 'l1_ratio': 0.28669151971609114}. Best is trial 128 with value: 0.3590101021316477.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:32:07,976] Trial 107 finished with value: -0.4938522708286848 and parameters: {'alpha': 3.069876559992963, 'l1_ratio': 1.4503501013399005e-05}. Best is trial 128 with value: 0.3590101021316477.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.473e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.533e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.775e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:32:17,958] Trial 129 finished with value: 0.19165048934513376 and parameters: {'alpha': 0.30891020434760463, 'l1_ratio': 0.5289073213871309}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:21,324] Trial 133 finished with value: -0.022476813628028114 and parameters: {'alpha': 0.17614881720168601, 'l1_ratio': 0.4447469932262171}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:22,063] Trial 131 finished with value: -0.2143361149375758 and parameters: {'alpha': 0.18998166502750288, 'l1_ratio': 0.28834710682769343}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:24,699] Trial 130 finished with value: -0.4425521405306269 and parameters: {'alpha': 0.1600004494974021, 'l1_ratio': 0.262761459348795}. Best is trial 128 with value: 0.3590101021316477.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.866e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.613e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:32:29,298] Trial 112 finished with value: 0.28957983884197064 and parameters: {'alpha': 114.43160400129673, 'l1_ratio': 1.512711735607313e-05}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:30,387] Trial 134 finished with value: -0.14034568065295225 and parameters: {'alpha': 0.1747575635411224, 'l1_ratio': 0.36258521714236863}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:36,717] Trial 132 finished with value: -0.5632198581246426 and parameters: {'alpha': 0.14099529757607035, 'l1_ratio': 0.2604585427313206}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:39,483] Trial 138 finished with value: 0.32086628728045785 and parameters: {'alpha': 0.7337203546757607, 'l1_ratio': 0.5745432061687057}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:40,961] Trial 136 finished with value: 0.1651233144846966 and parameters: {'alpha': 0.5569775110665226, 'l1_ratio': 0.2472110582710893}. Best is trial 128 with value: 0.3590101021316477.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.626e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:32:42,251] Trial 114 finished with value: 0.28536753462302833 and parameters: {'alpha': 107.10514738332942, 'l1_ratio': 1.3682573087386972e-05}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:42,327] Trial 142 finished with value: 0.3574362412163299 and parameters: {'alpha': 8.663220201376458, 'l1_ratio': 0.15419220925438676}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:43,526] Trial 139 finished with value: 0.32565535777254434 and parameters: {'alpha': 0.7744827833979129, 'l1_ratio': 0.5797680153084188}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:43,991] Trial 137 finished with value: 0.17870736875553297 and parameters: {'alpha': 0.7065443690497855, 'l1_ratio': 0.20994592885610022}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:45,542] Trial 143 finished with value: 0.35838071582056313 and parameters: {'alpha': 7.079819546856549, 'l1_ratio': 0.140433875511221}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:45,737] Trial 144 finished with value: 0.35542519269214107 and parameters: {'alpha': 7.421900692201734, 'l1_ratio': 0.1545470666537958}. Best is trial 128 with value: 0.3590101021316477.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:32:46,343] Trial 146 finished with value: 0.35625965438162227 and parameters: {'alpha': 8.339733535990586, 'l1_ratio': 0.15320082843376934}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:46,451] Trial 145 finished with value: 0.3579673609234114 and parameters: {'alpha': 8.19000098218525, 'l1_ratio': 0.12464338642352578}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:47,922] Trial 140 finished with value: 0.17142630796836122 and parameters: {'alpha': 0.7523623233807152, 'l1_ratio': 0.18845798155225382}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:48,037] Trial 147 finished with value: 0.3554621066345563 and parameters: {'alpha': 8.504339945563487, 'l1_ratio': 0.1349862280696274}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:48,610] Trial 148 finished with value: 0.3562383860556151 and parameters: {'alpha': 10.508522200868086, 'l1_ratio': 0.12095483492834083}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:50,840] Trial 151 finished with value: 0.3560802708808445 and parameters: {'alpha': 10.361142580097823, 'l1_ratio': 0.12182136494117235}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:52,523] Trial 150 finished with value: 0.35857044104617514 and parameters: {'alpha': 8.066851853605737, 'l1_ratio': 0.1189766144397544}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:53,168] Trial 154 finished with value: 0.355639104055644 and parameters: {'alpha': 11.005349676223748, 'l1_ratio': 0.10534472943428723}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:54,226] Trial 152 finished with value: 0.35849394056187145 and parameters: {'alpha': 9.262937727511707, 'l1_ratio': 0.103903257855903}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:54,324] Trial 141 finished with value: 0.3154372650158423 and parameters: {'alpha': 0.7157225694204717, 'l1_ratio': 0.5488695149117363}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:55,167] Trial 149 finished with value: 0.35529740603277793 and parameters: {'alpha': 8.41615238925995, 'l1_ratio': 0.088330453471283}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:57,772] Trial 155 finished with value: 0.3569469677120692 and parameters: {'alpha': 9.007392064083218, 'l1_ratio': 0.09090022970542305}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:32:58,857] Trial 153 finished with value: 0.3487610648407854 and parameters: {'alpha': 7.1369107845819695, 'l1_ratio': 0.08911828530296355}. Best is trial 128 with value: 0.3590101021316477.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:33:04,220] Trial 135 finished with value: -0.6248525888870063 and parameters: {'alpha': 0.13722380677433085, 'l1_ratio': 0.24407103220064677}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:33:04,764] Trial 156 finished with value: 0.34215713652774393 and parameters: {'alpha': 7.836480947340992, 'l1_ratio': 0.06922014331726478}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:33:05,132] Trial 158 finished with value: 0.34609535690051557 and parameters: {'alpha': 7.899992924791051, 'l1_ratio': 0.07242713022505035}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:33:05,220] Trial 157 finished with value: 0.3437652860156858 and parameters: {'alpha': 7.719755675637385, 'l1_ratio': 0.0717042091644323}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:33:05,807] Trial 163 finished with value: 0.34644828885223344 and parameters: {'alpha': 57.18592288664059, 'l1_ratio': 0.042660416178057305}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:33:06,739] Trial 164 finished with value: 0.3510282485296207 and parameters: {'alpha': 57.79956634462816, 'l1_ratio': 0.03507424623508824}. Best is trial 128 with value: 0.3590101021316477.\n",
      "[I 2023-06-16 16:33:07,962] Trial 166 finished with value: 0.35905311002504064 and parameters: {'alpha': 37.56874458881551, 'l1_ratio': 0.039031576622456904}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:08,312] Trial 168 finished with value: 0.3485484939160866 and parameters: {'alpha': 13.688099399906871, 'l1_ratio': 0.16878562051513782}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:09,239] Trial 159 finished with value: 0.3243768327923027 and parameters: {'alpha': 7.767258993684323, 'l1_ratio': 0.053897987553781036}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:09,308] Trial 169 finished with value: 0.34947941784485514 and parameters: {'alpha': 15.20361446230839, 'l1_ratio': 0.1444746038729292}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:13,379] Trial 160 finished with value: 0.30877608897240466 and parameters: {'alpha': 6.731677313597141, 'l1_ratio': 0.050897532044362294}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:13,527] Trial 161 finished with value: 0.3089930429691231 and parameters: {'alpha': 6.422793147036954, 'l1_ratio': 0.053676321506851615}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:18,532] Trial 170 finished with value: 0.10370870280683926 and parameters: {'alpha': 3.888962497573385, 'l1_ratio': 0.02128415752233523}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:19,671] Trial 171 finished with value: 0.11582147497170252 and parameters: {'alpha': 3.914123256362101, 'l1_ratio': 0.02221615699329023}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:21,072] Trial 167 finished with value: 0.34012341942322943 and parameters: {'alpha': 18.19043557287485, 'l1_ratio': 0.02730451902452118}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.246e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:33:22,850] Trial 162 finished with value: 0.26704037028675254 and parameters: {'alpha': 4.412008141299202, 'l1_ratio': 0.05249892628173616}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:23,815] Trial 177 finished with value: 0.3556432364883561 and parameters: {'alpha': 1.3183268804397674, 'l1_ratio': 0.9555678927288119}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:25,190] Trial 179 finished with value: 0.323256356080263 and parameters: {'alpha': 43.60123897482891, 'l1_ratio': 0.10666004687245777}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:25,735] Trial 180 finished with value: 0.3153598607041081 and parameters: {'alpha': 80.84427882111773, 'l1_ratio': 0.367895441040962}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.666e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:33:29,667] Trial 165 finished with value: 0.2154714599802278 and parameters: {'alpha': 4.26345810951327, 'l1_ratio': 0.04007786068700219}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.317e-03, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:33:32,672] Trial 173 finished with value: 0.31390624425061125 and parameters: {'alpha': 1.3310430617167825, 'l1_ratio': 0.2880646787629727}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:34,032] Trial 175 finished with value: 0.32690155719100483 and parameters: {'alpha': 1.3983810598681201, 'l1_ratio': 0.3263523366430239}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:40,577] Trial 176 finished with value: -0.4927017233056891 and parameters: {'alpha': 0.044974999696495016, 'l1_ratio': 0.9464686629033711}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.124e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:33:45,067] Trial 178 finished with value: 0.23748912871306463 and parameters: {'alpha': 1.6874743218241526, 'l1_ratio': 0.11890762768509015}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:33:46,357] Trial 183 finished with value: -0.049614966641591596 and parameters: {'alpha': 0.438413337980227, 'l1_ratio': 0.164161244504615}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.807e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:33:47,599] Trial 187 finished with value: 0.32642101451467614 and parameters: {'alpha': 20.22104831118227, 'l1_ratio': 0.19249856436955115}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:51,661] Trial 181 finished with value: -0.22176279702005544 and parameters: {'alpha': 0.3543440344801002, 'l1_ratio': 0.1476065845440262}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:53,907] Trial 182 finished with value: -0.23945852036809487 and parameters: {'alpha': 0.3784909338804193, 'l1_ratio': 0.13340400534733093}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:54,255] Trial 185 finished with value: -0.10719945576620149 and parameters: {'alpha': 0.46397075585827546, 'l1_ratio': 0.13664113937301828}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:54,621] Trial 190 finished with value: 0.3115455170461861 and parameters: {'alpha': 19.16859698381255, 'l1_ratio': 0.36724270509547396}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:56,610] Trial 189 finished with value: 0.3583395099603423 and parameters: {'alpha': 2.6422685196957603, 'l1_ratio': 0.3860580664220999}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:56,974] Trial 193 finished with value: 0.32067234758972546 and parameters: {'alpha': 51.81761669952174, 'l1_ratio': 0.38654212185067954}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:58,523] Trial 192 finished with value: 0.35557156087560937 and parameters: {'alpha': 2.9542263822164943, 'l1_ratio': 0.40184202015855225}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:58,911] Trial 195 finished with value: 0.31996610285925775 and parameters: {'alpha': 134.2537927091675, 'l1_ratio': 0.07717962209561224}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:33:59,363] Trial 184 finished with value: -0.2950643614828246 and parameters: {'alpha': 0.3497139978205444, 'l1_ratio': 0.13314479506816929}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:00,528] Trial 186 finished with value: -0.07994009213256308 and parameters: {'alpha': 0.39290388178963065, 'l1_ratio': 0.1735156229139904}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:00,700] Trial 197 finished with value: 0.31153935292078166 and parameters: {'alpha': 26.823731910286806, 'l1_ratio': 0.24712741611292707}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:01,209] Trial 191 finished with value: 0.3588350989716463 and parameters: {'alpha': 2.5284132017583087, 'l1_ratio': 0.3882057114257279}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:34:02,009] Trial 174 finished with value: -1.3806280496304346 and parameters: {'alpha': 0.039013559351048305, 'l1_ratio': 0.3606663177217783}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:04,154] Trial 200 finished with value: 0.35742331338950745 and parameters: {'alpha': 1.6507081339279628, 'l1_ratio': 0.9684446838855929}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:04,708] Trial 201 finished with value: 0.3584192220349806 and parameters: {'alpha': 1.6285357815056498, 'l1_ratio': 0.912127740894783}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:34:06,238] Trial 172 finished with value: -1.6444983307045624 and parameters: {'alpha': 0.03450387626297002, 'l1_ratio': 0.3329587648246955}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:06,743] Trial 198 finished with value: 0.35884432405815353 and parameters: {'alpha': 1.3450385556608397, 'l1_ratio': 0.6800396395604138}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:08,045] Trial 202 finished with value: 0.35640425501286704 and parameters: {'alpha': 1.7291212431707994, 'l1_ratio': 0.9850875669672076}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:08,051] Trial 194 finished with value: 0.35262644138693827 and parameters: {'alpha': 2.7004246920921733, 'l1_ratio': 0.2572808817266274}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:09,909] Trial 204 finished with value: 0.3579958754257995 and parameters: {'alpha': 1.920615459802693, 'l1_ratio': 0.7068020525248606}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:10,290] Trial 205 finished with value: 0.35515744247846576 and parameters: {'alpha': 1.2577717060695388, 'l1_ratio': 0.9065293364050337}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:10,802] Trial 203 finished with value: 0.35879220830896286 and parameters: {'alpha': 1.1297061735782394, 'l1_ratio': 0.8058426831865927}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:11,203] Trial 188 finished with value: 0.18103193214229688 and parameters: {'alpha': 0.4106344560529772, 'l1_ratio': 0.36704719345679804}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:11,430] Trial 199 finished with value: 0.3522741400435548 and parameters: {'alpha': 1.0038592034427873, 'l1_ratio': 0.6906382549625223}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:13,977] Trial 206 finished with value: 0.35787433921658846 and parameters: {'alpha': 1.0774055114318124, 'l1_ratio': 0.7926251130748497}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:17,666] Trial 207 finished with value: 0.35264448755504135 and parameters: {'alpha': 0.9940621428894468, 'l1_ratio': 0.7026197523098673}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:18,826] Trial 208 finished with value: 0.35285039225925646 and parameters: {'alpha': 1.1869447610877348, 'l1_ratio': 0.5905481937664221}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:19,006] Trial 211 finished with value: 0.3559611854839141 and parameters: {'alpha': 1.1184088623845927, 'l1_ratio': 0.6745606625732515}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:20,182] Trial 212 finished with value: 0.3493149002385352 and parameters: {'alpha': 1.0195690720191792, 'l1_ratio': 0.648216598696597}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:20,494] Trial 196 finished with value: 0.28392867020650037 and parameters: {'alpha': 1.2964538246144233, 'l1_ratio': 0.21759039017460857}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:21,817] Trial 214 finished with value: 0.35556855893360867 and parameters: {'alpha': 1.790816436143981, 'l1_ratio': 0.6158341942162535}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:21,989] Trial 216 finished with value: 0.3573679359980803 and parameters: {'alpha': 3.180311824562158, 'l1_ratio': 0.5029571742847947}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:21,995] Trial 209 finished with value: 0.3357513389040881 and parameters: {'alpha': 0.8408423257491701, 'l1_ratio': 0.6198099603828284}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:23,569] Trial 210 finished with value: 0.33345496567479244 and parameters: {'alpha': 0.856844256671552, 'l1_ratio': 0.5898609253219191}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:24,562] Trial 221 finished with value: 0.3518024711046048 and parameters: {'alpha': 2.1716150905468248, 'l1_ratio': 0.9336467957472713}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:25,050] Trial 218 finished with value: 0.35892927938510694 and parameters: {'alpha': 3.195655702676652, 'l1_ratio': 0.4538558440492656}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:25,322] Trial 222 finished with value: 0.33473910846148713 and parameters: {'alpha': 3.3111282946947544, 'l1_ratio': 0.9692981212238252}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:25,855] Trial 223 finished with value: 0.3442385549313532 and parameters: {'alpha': 2.828830094532656, 'l1_ratio': 0.9530041135495575}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:26,102] Trial 224 finished with value: 0.32631069680731545 and parameters: {'alpha': 4.176099854829504, 'l1_ratio': 0.995078103439142}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:32,708] Trial 217 finished with value: 0.10908787265381932 and parameters: {'alpha': 0.11559483773597118, 'l1_ratio': 0.9212451087156238}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:32,978] Trial 213 finished with value: -0.08923461982228624 and parameters: {'alpha': 0.112823400518761, 'l1_ratio': 0.6235525077202432}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:34,592] Trial 228 finished with value: 0.3557450871356086 and parameters: {'alpha': 4.15258359147298, 'l1_ratio': 0.42304107335721264}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:35,129] Trial 229 finished with value: 0.35139176040671194 and parameters: {'alpha': 4.978271732661682, 'l1_ratio': 0.4116243189087176}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:36,428] Trial 220 finished with value: 0.10875264898829029 and parameters: {'alpha': 0.11895249092111165, 'l1_ratio': 0.8937886492240369}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.246e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:34:39,294] Trial 225 finished with value: 0.0771552251210323 and parameters: {'alpha': 0.19659476633310666, 'l1_ratio': 0.48830431196329344}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:41,395] Trial 215 finished with value: -0.15820177871676164 and parameters: {'alpha': 0.09769656616421873, 'l1_ratio': 0.6393619468474081}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:42,580] Trial 226 finished with value: 0.1583577688628215 and parameters: {'alpha': 0.3123039893730791, 'l1_ratio': 0.42866266755527244}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:34:43,724] Trial 235 finished with value: 0.326119867509815 and parameters: {'alpha': 12.335506049365117, 'l1_ratio': 0.3074603771888265}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:46,917] Trial 219 finished with value: -0.11814645137514253 and parameters: {'alpha': 0.07603843007133154, 'l1_ratio': 0.88528563150596}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:50,930] Trial 232 finished with value: 0.1454187846058805 and parameters: {'alpha': 0.3114908286372215, 'l1_ratio': 0.406741255250941}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:51,155] Trial 231 finished with value: -0.010748006623309289 and parameters: {'alpha': 0.1977886612016916, 'l1_ratio': 0.4034209114027792}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:51,466] Trial 236 finished with value: 0.35641826878216215 and parameters: {'alpha': 3.370311533774825, 'l1_ratio': 0.22623626437637184}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.153e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:34:52,376] Trial 240 finished with value: 0.3231006491235032 and parameters: {'alpha': 19.17279676363264, 'l1_ratio': 0.2428474316171259}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:52,629] Trial 233 finished with value: 0.14465612142220094 and parameters: {'alpha': 0.4452599228075216, 'l1_ratio': 0.28238421408656533}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:53,394] Trial 237 finished with value: 0.35775727013691144 and parameters: {'alpha': 2.6038544245100463, 'l1_ratio': 0.3307471581292322}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:55,376] Trial 243 finished with value: 0.3510712442615813 and parameters: {'alpha': 4.548614453425793, 'l1_ratio': 0.45458438705624443}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:55,836] Trial 239 finished with value: 0.35891917928167605 and parameters: {'alpha': 3.8218428661593267, 'l1_ratio': 0.24570976412865275}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:55,911] Trial 238 finished with value: 0.3585731346168109 and parameters: {'alpha': 3.878081760109068, 'l1_ratio': 0.256885103648444}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.685e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:34:57,027] Trial 230 finished with value: 0.187407148917166 and parameters: {'alpha': 0.3952651531913673, 'l1_ratio': 0.39993171350261936}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:57,374] Trial 245 finished with value: 0.3379185646005755 and parameters: {'alpha': 13.339352381847181, 'l1_ratio': 0.22770178390849694}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:57,828] Trial 246 finished with value: 0.3443113633113733 and parameters: {'alpha': 12.358388379054622, 'l1_ratio': 0.21669214835623818}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:34:58,907] Trial 244 finished with value: 0.3556739375191189 and parameters: {'alpha': 2.454118517653155, 'l1_ratio': 0.4970953255517495}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:00,722] Trial 227 finished with value: -0.6459511846433815 and parameters: {'alpha': 0.0842707325880348, 'l1_ratio': 0.40249318972179}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:01,265] Trial 234 finished with value: 0.16667109977434158 and parameters: {'alpha': 0.4090803703708747, 'l1_ratio': 0.3408524647522838}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:03,210] Trial 247 finished with value: 0.13738822317302932 and parameters: {'alpha': 13.548061308259994, 'l1_ratio': 0.0042483835516742875}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:04,088] Trial 242 finished with value: 0.013636084687276543 and parameters: {'alpha': 4.603284847003036, 'l1_ratio': 0.01187060442280093}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:08,507] Trial 249 finished with value: 0.3477152669173245 and parameters: {'alpha': 2.002715366983059, 'l1_ratio': 0.2998788692394597}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:08,680] Trial 241 finished with value: -0.11381228325339994 and parameters: {'alpha': 4.4637093525496905, 'l1_ratio': 0.006727042067342645}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:11,585] Trial 248 finished with value: 0.3217881445098996 and parameters: {'alpha': 1.9689911858428697, 'l1_ratio': 0.2147816832318575}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.388e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.859e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:35:18,624] Trial 253 finished with value: 0.3112915288088999 and parameters: {'alpha': 1.5222435841743707, 'l1_ratio': 0.2441005854859932}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.778e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:35:23,328] Trial 257 finished with value: 0.33479264608706344 and parameters: {'alpha': 0.8317256670680453, 'l1_ratio': 0.6186555971876092}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:24,168] Trial 259 finished with value: -1.4581299187241386 and parameters: {'alpha': 8.60517936579712e-09, 'l1_ratio': 0.6013485530132231}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:25,695] Trial 260 finished with value: 0.32985425594588347 and parameters: {'alpha': 37.40885917174199, 'l1_ratio': 0.09099017369947522}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:27,161] Trial 261 finished with value: 0.3266386973062517 and parameters: {'alpha': 6.390361348481446, 'l1_ratio': 0.6325465682958648}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:35:29,220] Trial 258 finished with value: 0.3301770313869203 and parameters: {'alpha': 0.7105339893997542, 'l1_ratio': 0.682488068090753}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.238e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:35:42,786] Trial 262 finished with value: 0.15714248753659377 and parameters: {'alpha': 0.7526747786302113, 'l1_ratio': 0.17441946846205128}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:45,067] Trial 264 finished with value: 0.35506109021892235 and parameters: {'alpha': 1.8431761234389832, 'l1_ratio': 0.9916869723142979}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:45,247] Trial 265 finished with value: -0.015530983180227128 and parameters: {'alpha': 3131596779.099636, 'l1_ratio': 0.34724642575675496}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.187e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:35:47,133] Trial 250 finished with value: -0.579929781497432 and parameters: {'alpha': 1.309638106074325, 'l1_ratio': 0.009170163290376284}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:35:47,445] Trial 251 finished with value: -0.6312305535032702 and parameters: {'alpha': 1.6639726558736287, 'l1_ratio': 0.0033515450772516014}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:35:48,770] Trial 268 finished with value: -1.4474188455224184 and parameters: {'alpha': 4.538206872980713e-07, 'l1_ratio': 0.0010088837112051867}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.203e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:35:51,480] Trial 269 finished with value: -1.2186626142315062 and parameters: {'alpha': 1.263730347794349e-05, 'l1_ratio': 6.827324026070622e-05}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:35:54,394] Trial 266 finished with value: 0.350659289563602 and parameters: {'alpha': 7.02173235908879, 'l1_ratio': 0.09482696259667178}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:01,051] Trial 271 finished with value: 0.35784343733491525 and parameters: {'alpha': 4.939537559426036, 'l1_ratio': 0.17721420037577468}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:01,058] Trial 252 finished with value: -0.6665962646133711 and parameters: {'alpha': 1.9229823204233207, 'l1_ratio': 0.0004392219119564195}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:02,296] Trial 272 finished with value: 0.32374614266479945 and parameters: {'alpha': 26.459351267294075, 'l1_ratio': 0.1731342114100947}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:02,415] Trial 273 finished with value: 0.3228668773910273 and parameters: {'alpha': 30.91003527070721, 'l1_ratio': 0.15726544820100838}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:03,310] Trial 275 finished with value: -1.459282765511732 and parameters: {'alpha': 2.0157312045392627e-10, 'l1_ratio': 0.07368597704996363}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:06,160] Trial 276 finished with value: 0.35681147381100004 and parameters: {'alpha': 6.167759836567966, 'l1_ratio': 0.269382136502096}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:06,598] Trial 254 finished with value: -0.799392569560221 and parameters: {'alpha': 1.451455540032428, 'l1_ratio': 0.00026433130883262145}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:06,793] Trial 267 finished with value: -0.10532896547230493 and parameters: {'alpha': 8.149134951417654, 'l1_ratio': 0.0013468243870195821}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:12,112] Trial 255 finished with value: -0.9884734330291947 and parameters: {'alpha': 0.9901583401947913, 'l1_ratio': 0.0003101391300360855}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:14,235] Trial 280 finished with value: 0.349531794611252 and parameters: {'alpha': 4.393643531998262, 'l1_ratio': 0.5022601484029957}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:14,351] Trial 274 finished with value: 0.33360694402947116 and parameters: {'alpha': 7.480530699949198, 'l1_ratio': 0.0645648528844949}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:15,395] Trial 282 finished with value: 0.3489002420208785 and parameters: {'alpha': 17.933185124615957, 'l1_ratio': 0.12632748203193844}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.020e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:15,663] Trial 256 finished with value: -0.8633357900213132 and parameters: {'alpha': 1.2855614030645457, 'l1_ratio': 8.735805654320987e-05}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:15,974] Trial 284 finished with value: 0.3207160472169541 and parameters: {'alpha': 45.72622746605665, 'l1_ratio': 0.354097320365704}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:16,955] Trial 285 finished with value: 0.3265463936586212 and parameters: {'alpha': 98.21755802285716, 'l1_ratio': 0.04127765384972196}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:21,894] Trial 277 finished with value: 0.319676377553934 and parameters: {'alpha': 8.579757431908833, 'l1_ratio': 0.04499826962548574}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:23,073] Trial 270 finished with value: -0.2509122726884796 and parameters: {'alpha': 5.290256554806105, 'l1_ratio': 0.001182396960156063}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:23,448] Trial 288 finished with value: -0.015530983180227128 and parameters: {'alpha': 3383651.8755171364, 'l1_ratio': 0.22057191559447262}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:36:27,382] Trial 286 finished with value: 0.10146932695958837 and parameters: {'alpha': 0.4863068623310315, 'l1_ratio': 0.2089182552089899}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.624e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.866e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:34,938] Trial 281 finished with value: 0.2616054601382115 and parameters: {'alpha': 11.918943132247675, 'l1_ratio': 0.016716166813329315}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.986e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:35,802] Trial 263 finished with value: -0.7542689492597158 and parameters: {'alpha': 1.6020156389796423, 'l1_ratio': 0.0002520734792777955}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.915e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:36,989] Trial 292 finished with value: 0.35535121816891374 and parameters: {'alpha': 3.5470326327283836, 'l1_ratio': 0.5069586999065763}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.310e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.973e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.921e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:54,064] Trial 279 finished with value: -0.0012424596238384729 and parameters: {'alpha': 14.754346900913301, 'l1_ratio': 0.00012374197276970725}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:36:55,924] Trial 278 finished with value: -0.0333862488790185 and parameters: {'alpha': 12.95003493480967, 'l1_ratio': 0.0001295665984119184}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.042e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:37:03,895] Trial 283 finished with value: -3.3942958905710605 and parameters: {'alpha': 0.009573288640901269, 'l1_ratio': 0.3047513960863534}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:06,117] Trial 296 finished with value: 0.3507808698874323 and parameters: {'alpha': 3.4242779884713865, 'l1_ratio': 0.6107069410039746}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:11,755] Trial 294 finished with value: 0.3008718993883735 and parameters: {'alpha': 0.568917587429643, 'l1_ratio': 0.5952593841559563}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.785e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:37:14,249] Trial 287 finished with value: -4.179199352777676 and parameters: {'alpha': 0.003856456542393659, 'l1_ratio': 0.23526573008072468}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.781e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.462e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:37:20,736] Trial 297 finished with value: 0.3441369158278777 and parameters: {'alpha': 0.5724944407224427, 'l1_ratio': 0.9994248553946805}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.915e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:37:23,048] Trial 295 finished with value: 0.20463377817227782 and parameters: {'alpha': 0.5544805984008764, 'l1_ratio': 0.3171303079813372}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:28,755] Trial 298 finished with value: -0.12192646391065864 and parameters: {'alpha': 0.6007727603842729, 'l1_ratio': 0.09943433454848583}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.044e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:37:32,935] Trial 291 finished with value: -2.6363264195465734 and parameters: {'alpha': 0.011793948956731954, 'l1_ratio': 0.5029927858274263}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:39,950] Trial 300 finished with value: 0.3054755423653524 and parameters: {'alpha': 3.654491852069652, 'l1_ratio': 0.09369950676455853}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:40,415] Trial 301 finished with value: 0.31703469125452416 and parameters: {'alpha': 3.358298774848868, 'l1_ratio': 0.1164867560063967}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:41,063] Trial 305 finished with value: 0.32129606789500914 and parameters: {'alpha': 48.525770272680695, 'l1_ratio': 0.360922516166821}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.966e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:37:41,866] Trial 290 finished with value: -3.102323190893002 and parameters: {'alpha': 0.011651953754856332, 'l1_ratio': 7.419118903971296e-10}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:37:45,576] Trial 289 finished with value: -1.347034682280125 and parameters: {'alpha': 0.5293991017819636, 'l1_ratio': 1.239146127150826e-10}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:37:50,990] Trial 293 finished with value: -1.3195634165693984 and parameters: {'alpha': 0.5511356746783862, 'l1_ratio': 0.00015363507529581372}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:51,520] Trial 299 finished with value: -0.48336143625031686 and parameters: {'alpha': 0.3350717607415882, 'l1_ratio': 0.10863818346763209}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:53,114] Trial 310 finished with value: 0.3424848875982817 and parameters: {'alpha': 2.8381788459099213, 'l1_ratio': 0.9913181199474366}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:53,714] Trial 311 finished with value: -1.4527132885932348 and parameters: {'alpha': 4.399714883556872e-08, 'l1_ratio': 0.03271067007645255}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:54,736] Trial 312 finished with value: 0.3211436181019196 and parameters: {'alpha': 31.70762204941146, 'l1_ratio': 0.16886857526361684}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:37:54,992] Trial 313 finished with value: 0.28874869026131533 and parameters: {'alpha': 107.76182942625654, 'l1_ratio': 0.4143141306915106}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.678e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.129e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:03,541] Trial 302 finished with value: -0.6816296103098017 and parameters: {'alpha': 0.21975268511335744, 'l1_ratio': 0.1240935430845626}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.932e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:04,202] Trial 315 finished with value: 0.3198534893675102 and parameters: {'alpha': 15.57034582663218, 'l1_ratio': 0.7230739179277309}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:05,966] Trial 309 finished with value: 0.3380399824366615 and parameters: {'alpha': 19.623933623405282, 'l1_ratio': 0.024055375198324274}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:06,974] Trial 314 finished with value: 0.102895844197045 and parameters: {'alpha': 0.16352568827101033, 'l1_ratio': 0.6339050598299549}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e-03, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:09,223] Trial 316 finished with value: 0.3559026409491577 and parameters: {'alpha': 2.2941657450848525, 'l1_ratio': 0.4766898630827011}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:09,377] Trial 317 finished with value: 0.3561372329700137 and parameters: {'alpha': 2.780452713806143, 'l1_ratio': 0.46221672130051494}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.453e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:12,145] Trial 318 finished with value: -1.335982214810917 and parameters: {'alpha': 1.779740853152563e-06, 'l1_ratio': 1.2675913651037906e-07}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:12,148] Trial 303 finished with value: -0.6984491784464092 and parameters: {'alpha': 0.20807106952456386, 'l1_ratio': 0.12747532765892322}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:12,208] Trial 319 finished with value: 0.3558390170110048 and parameters: {'alpha': 6.312366699815112, 'l1_ratio': 0.27681805571682466}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:15,167] Trial 322 finished with value: 0.3482835006833344 and parameters: {'alpha': 9.017391602305848, 'l1_ratio': 0.25990506524327134}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:15,277] Trial 321 finished with value: 0.35248011327402623 and parameters: {'alpha': 7.258018988316631, 'l1_ratio': 0.2726722724974805}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.602e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:18,228] Trial 324 finished with value: 0.35529346564166436 and parameters: {'alpha': 1.1619031655509968, 'l1_ratio': 0.9945050498420221}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:24,045] Trial 304 finished with value: -0.561662838986741 and parameters: {'alpha': 0.20572421391268275, 'l1_ratio': 0.1719333213515096}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:27,621] Trial 326 finished with value: 0.35412333708478216 and parameters: {'alpha': 1.1223778097615975, 'l1_ratio': 0.6433780259383559}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:27,899] Trial 328 finished with value: -0.015530983180227128 and parameters: {'alpha': 594494106.2461306, 'l1_ratio': 0.3861475889389854}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:28,624] Trial 325 finished with value: 0.021089969737206078 and parameters: {'alpha': 1.3429747543913264, 'l1_ratio': 0.05659189496749993}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.600e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.449e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:32,879] Trial 306 finished with value: -1.3314918935177145 and parameters: {'alpha': 0.25257131388884496, 'l1_ratio': 0.024083686920194622}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.365e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:35,788] Trial 323 finished with value: 0.27502723504919774 and parameters: {'alpha': 1.165711758108136, 'l1_ratio': 0.21611891491437843}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:38,499] Trial 327 finished with value: 0.036562496108139074 and parameters: {'alpha': 1.31657384122447, 'l1_ratio': 0.06023141352039404}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:40,488] Trial 333 finished with value: 0.346478698066261 and parameters: {'alpha': 3.842793617123977, 'l1_ratio': 0.6545208926911218}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:44,254] Trial 334 finished with value: 0.35769741116789106 and parameters: {'alpha': 4.183471346633355, 'l1_ratio': 0.37284703356321053}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:48,599] Trial 335 finished with value: 0.35894922190117373 and parameters: {'alpha': 3.2218121852045405, 'l1_ratio': 0.4321038220670151}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:38:49,557] Trial 336 finished with value: 0.32048269253517847 and parameters: {'alpha': 33.03706136074976, 'l1_ratio': 0.38984228114328373}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.309e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.498e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:53,811] Trial 308 finished with value: -0.6123112186063538 and parameters: {'alpha': 2.2691617101058035, 'l1_ratio': 3.5638610909216626e-05}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.464e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:56,798] Trial 307 finished with value: -1.7725634270981712 and parameters: {'alpha': 0.2703228702207453, 'l1_ratio': 0.0004953034711097626}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:38:59,595] Trial 339 finished with value: 0.3575559488449212 and parameters: {'alpha': 4.6429516610524235, 'l1_ratio': 0.3390642367117666}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:39:00,410] Trial 340 finished with value: 0.31580800231750034 and parameters: {'alpha': 11.75701427622063, 'l1_ratio': 0.5162033734059842}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:39:00,701] Trial 341 finished with value: -0.015530983180227128 and parameters: {'alpha': 13085630.545994643, 'l1_ratio': 0.2071250362025139}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.593e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.986e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.204e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.962e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.203e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.262e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:39:31,063] Trial 320 finished with value: -0.22183003775507992 and parameters: {'alpha': 6.784935684242058, 'l1_ratio': 1.8440166044159062e-07}. Best is trial 166 with value: 0.35905311002504064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:39:33,096] Trial 332 finished with value: -3.6600910998854816 and parameters: {'alpha': 0.0007212402298318349, 'l1_ratio': 0.6691821276262655}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:39:33,490] Trial 344 finished with value: 0.21037786751230458 and parameters: {'alpha': 196.27084011558458, 'l1_ratio': 0.3359317397396465}. Best is trial 166 with value: 0.35905311002504064.\n",
      "[I 2023-06-16 16:39:34,719] Trial 343 finished with value: 0.3603214034046899 and parameters: {'alpha': 118.43682332925782, 'l1_ratio': 0.01089724282209381}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:39:35,556] Trial 346 finished with value: 0.31668871842392793 and parameters: {'alpha': 247.203008268278, 'l1_ratio': 0.03177817262658021}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.015e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:39:38,326] Trial 330 finished with value: 0.174490656215424 and parameters: {'alpha': 37.3430583363863, 'l1_ratio': 2.027080592169785e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:39:38,997] Trial 348 finished with value: 0.31177336760749125 and parameters: {'alpha': 111.82516804564663, 'l1_ratio': 0.06277132822200154}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.244e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:39:43,121] Trial 345 finished with value: 0.3516787210976737 and parameters: {'alpha': 81.7916228566738, 'l1_ratio': 0.0076722183966419}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:39:43,813] Trial 349 finished with value: 0.35602028215560605 and parameters: {'alpha': 72.28781483817026, 'l1_ratio': 0.013994521352720895}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.588e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:39:44,427] Trial 329 finished with value: -0.47663256403224047 and parameters: {'alpha': 3.21810648346337, 'l1_ratio': 4.0475496397259714e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:39:44,901] Trial 352 finished with value: 0.31751538386488976 and parameters: {'alpha': 23.814640680923723, 'l1_ratio': 0.9883191599715496}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:39:47,680] Trial 347 finished with value: 0.3492435831402289 and parameters: {'alpha': 69.03357452376801, 'l1_ratio': 0.007781868688042326}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.751e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+00, tolerance: 4.591e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.938e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:39:49,620] Trial 331 finished with value: -0.4315309250671305 and parameters: {'alpha': 3.6360554268239267, 'l1_ratio': 2.748630429897904e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:39:49,674] Trial 337 finished with value: -2.6158720724761952 and parameters: {'alpha': 4.0514357427576264e-05, 'l1_ratio': 0.45575389817178236}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:39:54,388] Trial 355 finished with value: 0.16689944992487393 and parameters: {'alpha': 20.792959345532257, 'l1_ratio': 0.002359986847163001}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:39:55,065] Trial 350 finished with value: 0.24427447613474965 and parameters: {'alpha': 26.85912613195525, 'l1_ratio': 0.004409865710336549}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.869e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:02,740] Trial 338 finished with value: 0.31623366886675214 and parameters: {'alpha': 203.2127637915162, 'l1_ratio': 7.532496428839743e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:40:04,814] Trial 358 finished with value: 0.1309520358236441 and parameters: {'alpha': 0.686816328048978, 'l1_ratio': 0.16910221392875932}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.266e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.019e-03, tolerance: 4.591e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:06,639] Trial 354 finished with value: 0.29546816414174276 and parameters: {'alpha': 14.676468592950245, 'l1_ratio': 0.018440324211985774}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.550e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:11,200] Trial 360 finished with value: 0.3574592978371764 and parameters: {'alpha': 12.06889171461188, 'l1_ratio': 0.07315723418477958}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:40:11,655] Trial 362 finished with value: 0.32216096431444846 and parameters: {'alpha': 212205.00407819918, 'l1_ratio': 5.16563429721285e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.611e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.334e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:12,322] Trial 342 finished with value: 0.2947544802095244 and parameters: {'alpha': 126.069763666647, 'l1_ratio': 4.5763694955945265e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.099e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.518e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:25,152] Trial 363 finished with value: 0.3339996382023081 and parameters: {'alpha': 2.116024776505333, 'l1_ratio': 0.23786379824689868}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.299e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.976e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.992e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.781e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.716e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.472e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.436e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:39,932] Trial 365 finished with value: 0.3256123187233857 and parameters: {'alpha': 0.6665395105314698, 'l1_ratio': 0.6736396875881006}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.530e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:43,522] Trial 356 finished with value: -2.091249557798951 and parameters: {'alpha': 0.040195114936746504, 'l1_ratio': 0.16636114795995888}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.357e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:44,907] Trial 357 finished with value: -2.064419654972361 and parameters: {'alpha': 0.041221389654139816, 'l1_ratio': 0.16658292561310964}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:47,912] Trial 367 finished with value: 0.355923982836866 and parameters: {'alpha': 2.07397119942243, 'l1_ratio': 0.527129852368853}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.409e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:54,469] Trial 353 finished with value: 0.03379042906960539 and parameters: {'alpha': 17.448524422831923, 'l1_ratio': 4.4552653314966846e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.385e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:56,179] Trial 351 finished with value: 0.08917838968842924 and parameters: {'alpha': 22.87541239706658, 'l1_ratio': 5.430865989750755e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.820e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:57,851] Trial 359 finished with value: -1.8644662372140417 and parameters: {'alpha': 0.04347813040450841, 'l1_ratio': 0.2005877935164756}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:40:59,418] Trial 361 finished with value: -1.8630823820148064 and parameters: {'alpha': 0.07516620900855005, 'l1_ratio': 0.08574711510280432}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:02,732] Trial 373 finished with value: 0.35843994774725363 and parameters: {'alpha': 4.924983804483052, 'l1_ratio': 0.3020738947408501}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.984e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:03,583] Trial 364 finished with value: -1.8607245061478899 and parameters: {'alpha': 0.05244113530233749, 'l1_ratio': 0.153246746717345}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:04,229] Trial 366 finished with value: -0.27195260026519646 and parameters: {'alpha': 2.1858886854369373, 'l1_ratio': 0.012099618261833889}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:05,704] Trial 370 finished with value: 0.34842702376776635 and parameters: {'alpha': 6.509575389079292, 'l1_ratio': 0.09712606271669143}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:05,836] Trial 375 finished with value: 0.35692783008651174 and parameters: {'alpha': 4.190600720558036, 'l1_ratio': 0.31681360491748706}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:07,914] Trial 371 finished with value: 0.3452648844291753 and parameters: {'alpha': 5.898195122064737, 'l1_ratio': 0.09648642154090625}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:08,758] Trial 372 finished with value: 0.3478606276201634 and parameters: {'alpha': 5.683868494514357, 'l1_ratio': 0.104732547516239}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.992e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:12,510] Trial 368 finished with value: 0.22831156756388551 and parameters: {'alpha': 2.211586960489709, 'l1_ratio': 0.08610461273991792}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:13,269] Trial 381 finished with value: 0.3205494509913016 and parameters: {'alpha': 430.8578978841573, 'l1_ratio': 0.03223333465039055}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:22,430] Trial 380 finished with value: 0.34136822970543096 and parameters: {'alpha': 0.8109251389703105, 'l1_ratio': 0.6842239379775037}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:23,805] Trial 376 finished with value: 0.30554291419607416 and parameters: {'alpha': 7.462675517458579, 'l1_ratio': 0.04392635038678436}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:28,219] Trial 378 finished with value: -0.40574744615689207 and parameters: {'alpha': 0.7981237088174319, 'l1_ratio': 0.039666295425765725}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:32,149] Trial 379 finished with value: -0.2679718814609029 and parameters: {'alpha': 0.8671487266020353, 'l1_ratio': 0.04814723270823016}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:32,970] Trial 385 finished with value: 0.25114625909675425 and parameters: {'alpha': 46.09506023252694, 'l1_ratio': 0.00153362229873768}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:33,614] Trial 374 finished with value: -0.18724976247032424 and parameters: {'alpha': 6.1006176168876785, 'l1_ratio': 0.0015620366961167102}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.372e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:41,054] Trial 382 finished with value: -0.49765888458377594 and parameters: {'alpha': 0.6678116362109839, 'l1_ratio': 0.042158135660172624}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:44,545] Trial 388 finished with value: 0.3453186802497291 and parameters: {'alpha': 1.9402328409909113, 'l1_ratio': 0.2974646546406578}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.643e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:45,517] Trial 390 finished with value: 0.32654497568528595 and parameters: {'alpha': 11.083352079021827, 'l1_ratio': 0.3691706153815081}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:45,738] Trial 391 finished with value: -0.015530983180227128 and parameters: {'alpha': 19340870.39221029, 'l1_ratio': 0.7016755576435647}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:46,303] Trial 387 finished with value: 0.11502151895902864 and parameters: {'alpha': 0.37465042018042277, 'l1_ratio': 0.2884112814617706}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.296e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:48,397] Trial 393 finished with value: 0.3339170272411143 and parameters: {'alpha': 12694.753184119976, 'l1_ratio': 2.0329943324789936e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:48,519] Trial 383 finished with value: 0.24827278085196447 and parameters: {'alpha': 0.7652515730332636, 'l1_ratio': 0.2784505274951537}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:49,549] Trial 389 finished with value: 0.356046210075102 and parameters: {'alpha': 2.2072537614715944, 'l1_ratio': 0.34203442854787086}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:41:53,509] Trial 394 finished with value: 0.35534227110870276 and parameters: {'alpha': 2.481615690367469, 'l1_ratio': 0.46584025144831165}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:41:56,665] Trial 396 finished with value: 0.21893668452624773 and parameters: {'alpha': 41.96762536358092, 'l1_ratio': 0.0006544674625060709}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:02,468] Trial 398 finished with value: -1.264487029697481 and parameters: {'alpha': 2.6831587168593066e-06, 'l1_ratio': 0.7232019356407489}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:03,091] Trial 399 finished with value: 0.3202112787439207 and parameters: {'alpha': 12.729738849033877, 'l1_ratio': 0.9458221795951972}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:03,546] Trial 369 finished with value: -0.2430285964127928 and parameters: {'alpha': 6.324247559304702, 'l1_ratio': 1.8062709610551137e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:04,955] Trial 401 finished with value: -1.5134361550753421 and parameters: {'alpha': 1.5091188208326389e-07, 'l1_ratio': 0.1988744682194188}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.854e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:09,963] Trial 377 finished with value: -2.67070363670904 and parameters: {'alpha': 0.00012795645521340512, 'l1_ratio': 0.30133585662432866}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.854e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:16,452] Trial 397 finished with value: 0.19644780755835234 and parameters: {'alpha': 0.2171472888410813, 'l1_ratio': 0.776222073217323}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:17,121] Trial 404 finished with value: -1.459106552959043 and parameters: {'alpha': 4.753488982980867e-10, 'l1_ratio': 0.4459201500246091}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.978e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:22,322] Trial 384 finished with value: -4.177634302903346 and parameters: {'alpha': 0.003023746026745519, 'l1_ratio': 0.3207549328008527}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:24,645] Trial 406 finished with value: 0.3496716917010649 and parameters: {'alpha': 15.433593279751788, 'l1_ratio': 0.1404222898633696}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:24,915] Trial 407 finished with value: 0.2944678536482575 and parameters: {'alpha': 45048.00516005837, 'l1_ratio': 0.0007665956489560509}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:25,476] Trial 405 finished with value: 0.085528337801892 and parameters: {'alpha': 18.164464286199024, 'l1_ratio': 0.0008691529167960324}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:26,433] Trial 409 finished with value: -1.4586713810436456 and parameters: {'alpha': 3.338643664653926e-09, 'l1_ratio': 0.00021595222465736373}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:26,689] Trial 410 finished with value: -0.015530983180227128 and parameters: {'alpha': 288122946.27350265, 'l1_ratio': 0.004476911411686544}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:27,140] Trial 386 finished with value: -2.65891362123988 and parameters: {'alpha': 7.724841785098519e-05, 'l1_ratio': 0.28754084092207083}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:28,680] Trial 392 finished with value: -1.5315663508411754 and parameters: {'alpha': 0.00022034734780892166, 'l1_ratio': 1.2179978411676297e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.093e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:34,062] Trial 412 finished with value: 0.3578128020253674 and parameters: {'alpha': 1.7416840400507794, 'l1_ratio': 0.4959494967774702}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:34,456] Trial 414 finished with value: 0.29559171726388894 and parameters: {'alpha': 2807.740556693483, 'l1_ratio': 0.01476260074593115}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:35,162] Trial 408 finished with value: 0.3467481302066269 and parameters: {'alpha': 1.2881978325528822, 'l1_ratio': 0.45798603712441843}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.318e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:50,733] Trial 411 finished with value: -0.23117528226447157 and parameters: {'alpha': 1.8730282653178936, 'l1_ratio': 0.018168291704463276}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:51,838] Trial 416 finished with value: -0.06005171663412815 and parameters: {'alpha': 0.12409806143372086, 'l1_ratio': 0.5960788433029727}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.525e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.284e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:55,327] Trial 415 finished with value: 0.2794560009966162 and parameters: {'alpha': 0.2711587259915724, 'l1_ratio': 0.992043696174969}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:42:57,009] Trial 395 finished with value: -0.6313760931421741 and parameters: {'alpha': 2.174125813811312, 'l1_ratio': 5.833597547322189e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:57,145] Trial 420 finished with value: -0.015530983180227128 and parameters: {'alpha': 19642.44076972295, 'l1_ratio': 0.1932973727848104}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:57,323] Trial 419 finished with value: 0.3480812739315084 and parameters: {'alpha': 4.409934731890792, 'l1_ratio': 0.5372282031622526}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:42:57,620] Trial 422 finished with value: -0.015530983180227128 and parameters: {'alpha': 540.9805964710483, 'l1_ratio': 0.9963934126706622}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.323e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:00,322] Trial 400 finished with value: -1.8351786016940215 and parameters: {'alpha': 0.21160567858989784, 'l1_ratio': 0.0054518408303230155}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:00,865] Trial 424 finished with value: 0.3175799951302369 and parameters: {'alpha': 48.798220609224735, 'l1_ratio': 0.5073597259810421}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:07,355] Trial 418 finished with value: 0.32816605472294685 and parameters: {'alpha': 0.48111201014409577, 'l1_ratio': 0.9755694996190306}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:07,908] Trial 426 finished with value: -1.4592954096167965 and parameters: {'alpha': 1.1609772433504937e-10, 'l1_ratio': 0.1406123413856944}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:13,053] Trial 413 finished with value: 0.3401368502092517 and parameters: {'alpha': 2575.933955724217, 'l1_ratio': 4.550563332703453e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:13,287] Trial 402 finished with value: -2.2720082803825026 and parameters: {'alpha': 0.002207665928418979, 'l1_ratio': 6.76419832945949e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:14,609] Trial 425 finished with value: 0.05329001899922936 and parameters: {'alpha': 0.5669125218447699, 'l1_ratio': 0.15588977610012497}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:14,803] Trial 430 finished with value: -0.015530983180227128 and parameters: {'alpha': 443821.99282122153, 'l1_ratio': 0.0094068433856347}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.658e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.302e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:20,712] Trial 427 finished with value: 0.01283582291706605 and parameters: {'alpha': 10.387452868147006, 'l1_ratio': 0.0023889032864374427}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.569e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:21,158] Trial 403 finished with value: -2.0074292483467904 and parameters: {'alpha': 0.18370928860314284, 'l1_ratio': 0.0005112491408970883}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:24,924] Trial 431 finished with value: 0.33728565297216 and parameters: {'alpha': 6.667030686829142, 'l1_ratio': 0.07638911847055062}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.985e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:33,685] Trial 434 finished with value: 0.3474372284556131 and parameters: {'alpha': 1.2188670499423016, 'l1_ratio': 0.5128310337845232}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.691e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:40,811] Trial 435 finished with value: 0.3581160246105819 and parameters: {'alpha': 3.7856112754835785, 'l1_ratio': 0.23334734114695366}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:41,315] Trial 436 finished with value: 0.31757421665635166 and parameters: {'alpha': 110.56056686932837, 'l1_ratio': 0.2185896752717215}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.229e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:41,933] Trial 432 finished with value: 0.2795618206553193 and parameters: {'alpha': 4.244081474559618, 'l1_ratio': 0.06047813573256122}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.068e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:43,336] Trial 437 finished with value: 0.33682649212269117 and parameters: {'alpha': 26.848401477382335, 'l1_ratio': 0.1146845878098228}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:43,511] Trial 438 finished with value: 0.325344128336722 and parameters: {'alpha': 39.64120658673528, 'l1_ratio': 0.10983585675281408}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:45,755] Trial 439 finished with value: 0.3546562344166067 and parameters: {'alpha': 9.43339695041662, 'l1_ratio': 0.19651004784430828}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:48,776] Trial 440 finished with value: 0.3584273177075202 and parameters: {'alpha': 4.640865177019877, 'l1_ratio': 0.21630722271382347}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:49,117] Trial 442 finished with value: -0.015530983180227128 and parameters: {'alpha': 900733812.9238061, 'l1_ratio': 0.02309087403375789}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:43:51,697] Trial 443 finished with value: 0.14360904634536809 and parameters: {'alpha': 305.69503281894345, 'l1_ratio': 0.26720753986737283}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.930e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:43:55,280] Trial 444 finished with value: 0.3584507771804764 and parameters: {'alpha': 3.433988776201552, 'l1_ratio': 0.4317131675441634}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:00,127] Trial 445 finished with value: 0.35487412511246247 and parameters: {'alpha': 4.153194125098798, 'l1_ratio': 0.4433952745757214}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.363e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:07,087] Trial 421 finished with value: 0.21664656672368152 and parameters: {'alpha': 49.23309745951484, 'l1_ratio': 7.740595621930497e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:07,486] Trial 417 finished with value: -2.1781679562009257 and parameters: {'alpha': 0.13391385946071413, 'l1_ratio': 3.2435963625700174e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:44:07,807] Trial 448 finished with value: -0.015530983180227128 and parameters: {'alpha': 59458408.5555488, 'l1_ratio': 0.23431099656374405}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.623e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:13,015] Trial 449 finished with value: 0.35772746694155305 and parameters: {'alpha': 15.592981706325741, 'l1_ratio': 0.06469107277952649}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.528e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:19,020] Trial 423 finished with value: 0.23774034844378575 and parameters: {'alpha': 61.247296565614874, 'l1_ratio': 7.518378520078529e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.430e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:19,844] Trial 429 finished with value: -0.24570510294741574 and parameters: {'alpha': 6.238500913742631, 'l1_ratio': 5.695927593836953e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.372e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:22,910] Trial 428 finished with value: -0.34420804318204073 and parameters: {'alpha': 4.552795471690781, 'l1_ratio': 0.0001914908127326082}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.002e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.994e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.472e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:37,576] Trial 433 finished with value: -0.351661529658744 and parameters: {'alpha': 4.50282873305854, 'l1_ratio': 0.00010227535987752606}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:44:37,916] Trial 454 finished with value: -0.015530983180227128 and parameters: {'alpha': 83865.41171556269, 'l1_ratio': 0.3360709968536609}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:40,169] Trial 453 finished with value: 0.31811912576974893 and parameters: {'alpha': 1.0907862399809785, 'l1_ratio': 0.37142115928814523}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:44:41,107] Trial 456 finished with value: -1.5120171381314516 and parameters: {'alpha': 1.6427014175866924e-07, 'l1_ratio': 0.12987490519960299}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.649e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.310e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.328e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:44:59,863] Trial 450 finished with value: -0.3485847147437076 and parameters: {'alpha': 3.522482016013072, 'l1_ratio': 0.0023480161936271617}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.708e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:02,448] Trial 441 finished with value: -0.384034081123584 and parameters: {'alpha': 4.148256671921737, 'l1_ratio': 8.917567903121835e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.552e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:08,935] Trial 446 finished with value: -0.0234943738564715 and parameters: {'alpha': 13.826001310464278, 'l1_ratio': 1.6041967342510803e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:45:09,376] Trial 460 finished with value: 0.18648868337852595 and parameters: {'alpha': 1299737.1102656776, 'l1_ratio': 8.772550428457937e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:45:10,830] Trial 458 finished with value: 0.059222216092806756 and parameters: {'alpha': 11.223037491926291, 'l1_ratio': 0.003137709883700547}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:45:11,588] Trial 461 finished with value: -1.2870022917608257 and parameters: {'alpha': 5.97820897749913e-06, 'l1_ratio': 2.4489209604860137e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.531e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:18,481] Trial 463 finished with value: 0.3553138776992857 and parameters: {'alpha': 1.2255025711659047, 'l1_ratio': 0.6070460837620796}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.978e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:22,182] Trial 447 finished with value: -0.018104848896938048 and parameters: {'alpha': 14.130900372478882, 'l1_ratio': 6.409594816496265e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:45:22,769] Trial 464 finished with value: -1.2496700077227336 and parameters: {'alpha': 2.221349618112527e-05, 'l1_ratio': 0.0059619899374727565}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.076e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.027e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:30,398] Trial 452 finished with value: -0.3941703510715586 and parameters: {'alpha': 3.9320085352332224, 'l1_ratio': 0.0002304146354699289}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.877e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:31,137] Trial 451 finished with value: -0.40670478607532834 and parameters: {'alpha': 3.8294597060006352, 'l1_ratio': 0.00015270789567562614}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.780e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.557e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:35,545] Trial 457 finished with value: -3.4277403557600064 and parameters: {'alpha': 0.000596236602270814, 'l1_ratio': 0.6662783822660255}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:45:46,062] Trial 467 finished with value: 0.09629062040162413 and parameters: {'alpha': 0.4331075608052211, 'l1_ratio': 0.23129370338864147}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:45:48,070] Trial 468 finished with value: 0.08912962969695115 and parameters: {'alpha': 0.43613453635805294, 'l1_ratio': 0.224659669907661}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.590e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:54,307] Trial 469 finished with value: 0.01185570600516687 and parameters: {'alpha': 0.38181171665092833, 'l1_ratio': 0.21450284589999974}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:45:54,552] Trial 472 finished with value: -0.015530983180227128 and parameters: {'alpha': 4824793197.085972, 'l1_ratio': 4.427951361617873e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:45:59,040] Trial 455 finished with value: -1.0331094715647526 and parameters: {'alpha': 0.9275829561651316, 'l1_ratio': 1.3140833405713113e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:45:59,887] Trial 474 finished with value: -1.4590037327890628 and parameters: {'alpha': 1.085949404933173e-09, 'l1_ratio': 1.3304811987836164e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:46:00,658] Trial 475 finished with value: 0.3197303136987384 and parameters: {'alpha': 27.550652020008148, 'l1_ratio': 0.4018828564645005}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:11,783] Trial 473 finished with value: -0.10748666340397776 and parameters: {'alpha': 1.6275212650712412, 'l1_ratio': 0.03195273547566518}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.102e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.086e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.623e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.000e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.022e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:19,251] Trial 459 finished with value: -0.010311694371020419 and parameters: {'alpha': 14.592427453942545, 'l1_ratio': 9.563552603524819e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:46:19,687] Trial 478 finished with value: 0.3204304508764704 and parameters: {'alpha': 104.83004477763096, 'l1_ratio': 0.1198337109351814}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:46:19,805] Trial 479 finished with value: -0.015530983180227128 and parameters: {'alpha': 281.4616533875522, 'l1_ratio': 0.9911887508821294}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.148e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:24,080] Trial 476 finished with value: 0.23882900318257852 and parameters: {'alpha': 1.5165968225328426, 'l1_ratio': 0.1333431121702069}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:28,407] Trial 462 finished with value: -0.8480015688133308 and parameters: {'alpha': 1.3363380387268686, 'l1_ratio': 1.2274479022147146e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.369e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:32,056] Trial 477 finished with value: 0.26991983437445616 and parameters: {'alpha': 1.7744007680325231, 'l1_ratio': 0.13599479127374586}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.504e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.762e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.596e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:38,348] Trial 466 finished with value: 0.3065756156315676 and parameters: {'alpha': 159.56599457342088, 'l1_ratio': 1.5862936024721236e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:46:39,133] Trial 484 finished with value: 0.3201190574452502 and parameters: {'alpha': 24.87529593290459, 'l1_ratio': 0.5941993013679004}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:44,395] Trial 465 finished with value: -1.239631454137545 and parameters: {'alpha': 0.6379235593774015, 'l1_ratio': 7.941561585206514e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:46:44,720] Trial 486 finished with value: 0.3207485586361093 and parameters: {'alpha': 6008.68052640565, 'l1_ratio': 0.0013479649427803084}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:46:46,089] Trial 487 finished with value: 0.32827692779201506 and parameters: {'alpha': 9.367903859497615, 'l1_ratio': 0.3734351858273218}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:49,954] Trial 488 finished with value: 0.15679517057561795 and parameters: {'alpha': 7.348997482302742, 'l1_ratio': 0.012694519608342414}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:46:50,083] Trial 489 finished with value: -0.015530983180227128 and parameters: {'alpha': 3300938673.521281, 'l1_ratio': 0.6344286815165496}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.560e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.325e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:58,206] Trial 470 finished with value: 0.2971055111276842 and parameters: {'alpha': 131.49675022824078, 'l1_ratio': 1.2412450492170114e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.987e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:46:58,914] Trial 471 finished with value: 0.2965333883497692 and parameters: {'alpha': 129.58493373046417, 'l1_ratio': 8.43107606692431e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:47:03,918] Trial 485 finished with value: -0.11508520687883768 and parameters: {'alpha': 8.93980477303209, 'l1_ratio': 0.0005266879353544093}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.129e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.279e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:47:19,442] Trial 492 finished with value: 0.2771944678038373 and parameters: {'alpha': 3.3827669310924033, 'l1_ratio': 0.07469184016381444}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:47:19,980] Trial 494 finished with value: 0.32009252723610654 and parameters: {'alpha': 28.630515127177432, 'l1_ratio': 0.4125688451301041}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:47:22,310] Trial 480 finished with value: -2.1243657559825193 and parameters: {'alpha': 0.0011597298116305253, 'l1_ratio': 0.010803780373228425}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:47:37,619] Trial 481 finished with value: -0.5900363819602418 and parameters: {'alpha': 2.3975491915655787, 'l1_ratio': 3.181443338625286e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.791e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.566e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:47:43,263] Trial 482 finished with value: -0.12925480111034296 and parameters: {'alpha': 9.27621965611236, 'l1_ratio': 3.8461067484332216e-10}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:47:45,935] Trial 483 finished with value: -0.13395604549890172 and parameters: {'alpha': 9.088291262464885, 'l1_ratio': 2.4412995292385444e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.221e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.285e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.098e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:47:54,178] Trial 491 finished with value: -3.322101992799808 and parameters: {'alpha': 0.015509145061274794, 'l1_ratio': 0.083098574879557}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.147e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.071e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:04,002] Trial 495 finished with value: -0.7278587454009573 and parameters: {'alpha': 0.09988548851520614, 'l1_ratio': 0.2739800037027587}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:04,447] Trial 498 finished with value: 0.19914503539835152 and parameters: {'alpha': 0.691665558226067, 'l1_ratio': 0.24496765903405185}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:04,764] Trial 502 finished with value: -0.015530983180227128 and parameters: {'alpha': 82960538.30802949, 'l1_ratio': 0.5010399821281805}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.051e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:07,900] Trial 490 finished with value: -3.247480444483889 and parameters: {'alpha': 0.020490801919827578, 'l1_ratio': 0.00032347060630150354}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:08,143] Trial 503 finished with value: 0.3580215169988141 and parameters: {'alpha': 2.3839101788538324, 'l1_ratio': 0.6469515104806812}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.227e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:09,322] Trial 499 finished with value: 0.2411413216041596 and parameters: {'alpha': 0.7145715454345447, 'l1_ratio': 0.28684503506680376}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:09,655] Trial 506 finished with value: -0.015530983180227128 and parameters: {'alpha': 7457951734.087728, 'l1_ratio': 0.7320369946641554}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:09,971] Trial 507 finished with value: -0.015530983180227128 and parameters: {'alpha': 729.2431097152692, 'l1_ratio': 0.6665041632702187}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:11,354] Trial 505 finished with value: 0.3582705974344014 and parameters: {'alpha': 2.1160854372569853, 'l1_ratio': 0.7122910004144762}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:11,948] Trial 508 finished with value: 0.3501283462911874 and parameters: {'alpha': 2.255776493851315, 'l1_ratio': 0.9476495297925001}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:15,042] Trial 510 finished with value: 0.35549412942962305 and parameters: {'alpha': 2.7147953145449697, 'l1_ratio': 0.43295123080787906}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:15,964] Trial 509 finished with value: 0.3576525739705391 and parameters: {'alpha': 2.333705073862951, 'l1_ratio': 0.4472266420755738}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.202e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:17,709] Trial 500 finished with value: 0.23796316047355137 and parameters: {'alpha': 0.6916588553997108, 'l1_ratio': 0.29218485389580423}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:17,943] Trial 501 finished with value: 0.3401914314367314 and parameters: {'alpha': 0.8911967532370529, 'l1_ratio': 0.6121380531776104}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:18,376] Trial 514 finished with value: -0.015530983180227128 and parameters: {'alpha': 1075543.320279161, 'l1_ratio': 0.9704579563433136}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:18,777] Trial 515 finished with value: -0.015530983180227128 and parameters: {'alpha': 2619594.452137305, 'l1_ratio': 0.0037761550913485917}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:18,887] Trial 513 finished with value: -1.4588577429004395 and parameters: {'alpha': 2.604855084286685e-09, 'l1_ratio': 0.6740978311264765}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.069e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:20,434] Trial 493 finished with value: -0.5225667432304725 and parameters: {'alpha': 2.842844566504232, 'l1_ratio': 3.278515107630646e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.241e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:22,237] Trial 497 finished with value: -0.758736101106032 and parameters: {'alpha': 0.09892882775972278, 'l1_ratio': 0.26267069356270784}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:22,956] Trial 519 finished with value: -1.4580939998116074 and parameters: {'alpha': 7.226577195045095e-09, 'l1_ratio': 0.0075237717121839015}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:23,468] Trial 518 finished with value: -1.3250420154970737 and parameters: {'alpha': 2.7670673469647266e-06, 'l1_ratio': 0.02438517584106439}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.178e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:28,069] Trial 496 finished with value: -0.6140669368969788 and parameters: {'alpha': 2.183463637779827, 'l1_ratio': 0.00040873090756016813}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.750e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:35,725] Trial 511 finished with value: 0.17119656952674733 and parameters: {'alpha': 0.3212219444441063, 'l1_ratio': 0.4459025990263991}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:48:36,215] Trial 523 finished with value: 0.318765495075478 and parameters: {'alpha': 48.073828830175316, 'l1_ratio': 0.17327696223512842}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.379e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:38,034] Trial 512 finished with value: 0.27618997225675895 and parameters: {'alpha': 0.2634264395176437, 'l1_ratio': 0.976975544989033}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.452e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:40,905] Trial 525 finished with value: 0.3590092124495716 and parameters: {'alpha': 26.24334136951651, 'l1_ratio': 0.05468439355312619}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.961e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:45,006] Trial 526 finished with value: 0.35765806097152913 and parameters: {'alpha': 23.427554607097186, 'l1_ratio': 0.0414274382795055}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.605e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.625e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:48:55,880] Trial 522 finished with value: -0.22415764325271706 and parameters: {'alpha': 0.30642435051899586, 'l1_ratio': 0.1716921264705272}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.458e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.287e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.990e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:07,744] Trial 517 finished with value: -1.5355455220283616 and parameters: {'alpha': 0.20980938452198536, 'l1_ratio': 0.021360779868529425}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:09,168] Trial 504 finished with value: -2.0310534784649583 and parameters: {'alpha': 0.00024696674793966224, 'l1_ratio': 0.051789462301436974}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:09,557] Trial 529 finished with value: 0.34680151319927427 and parameters: {'alpha': 51.999921977803275, 'l1_ratio': 0.046398797652594435}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:09,842] Trial 530 finished with value: 0.31125157963637934 and parameters: {'alpha': 52.87702676951076, 'l1_ratio': 0.12996581067483579}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:11,222] Trial 532 finished with value: 0.3264360480152067 and parameters: {'alpha': 11.065864407933525, 'l1_ratio': 0.3532372742005628}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:11,857] Trial 533 finished with value: 0.317557444180661 and parameters: {'alpha': 357.6870964682454, 'l1_ratio': 0.06901392237267939}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:12,058] Trial 520 finished with value: -1.2077031960076055 and parameters: {'alpha': 0.2753112145077649, 'l1_ratio': 0.026791975225981868}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.774e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:15,043] Trial 535 finished with value: 0.35800429176088616 and parameters: {'alpha': 16.20016941428908, 'l1_ratio': 0.09559772944319098}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:16,517] Trial 521 finished with value: -2.485572829925278 and parameters: {'alpha': 0.00013978866145071265, 'l1_ratio': 0.18296139292502725}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:19,689] Trial 536 finished with value: 0.3565337363533025 and parameters: {'alpha': 5.340215255524644, 'l1_ratio': 0.2006946229813564}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:20,127] Trial 538 finished with value: 0.31988040769645104 and parameters: {'alpha': 23.29104414560992, 'l1_ratio': 0.4009628280578049}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:20,334] Trial 539 finished with value: -0.015530983180227128 and parameters: {'alpha': 11997.854702997876, 'l1_ratio': 0.06069046486888325}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.282e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:22,209] Trial 537 finished with value: 0.11578527872929427 and parameters: {'alpha': 5.151952044634582, 'l1_ratio': 0.015818559687935642}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.324e-03, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:27,097] Trial 541 finished with value: -1.2824366448911533 and parameters: {'alpha': 5.639577888827406e-05, 'l1_ratio': 5.045009030110618e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:29,437] Trial 542 finished with value: -1.3871808668777832 and parameters: {'alpha': 1.0872177708213145e-06, 'l1_ratio': 7.733529299436723e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.227e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.480e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:31,769] Trial 516 finished with value: -1.8664980265537285 and parameters: {'alpha': 0.23592345538873777, 'l1_ratio': 3.336130841183954e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.064e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.622e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:44,592] Trial 540 finished with value: -0.1979089937043974 and parameters: {'alpha': 5.200660869623207, 'l1_ratio': 0.002600091821433287}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.005e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:45,354] Trial 545 finished with value: 0.31912913786308417 and parameters: {'alpha': 66.49650846382386, 'l1_ratio': 0.08675235185555148}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:45,484] Trial 524 finished with value: -1.8030956635184299 and parameters: {'alpha': 0.2618265902058016, 'l1_ratio': 3.724738836621647e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.587e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:49:46,161] Trial 527 finished with value: -1.9915872797116079 and parameters: {'alpha': 0.00013072415581327665, 'l1_ratio': 0.0545467332286365}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:46,313] Trial 546 finished with value: 0.3321389804692722 and parameters: {'alpha': 3832.5469149128808, 'l1_ratio': 0.0007550651221918978}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:46,472] Trial 547 finished with value: -1.4592856903403628 and parameters: {'alpha': 1.9797888765919159e-10, 'l1_ratio': 0.32924117091122296}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:49:47,012] Trial 548 finished with value: 0.320054750405451 and parameters: {'alpha': 24.24853284985114, 'l1_ratio': 0.35816922531969436}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.329e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.464e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.782e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:02,033] Trial 550 finished with value: 0.34515182008829265 and parameters: {'alpha': 1.0577245956720747, 'l1_ratio': 0.5462841924527695}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:50:02,073] Trial 528 finished with value: 0.2048837917693804 and parameters: {'alpha': 45.28508893956906, 'l1_ratio': 5.889645804927135e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.871e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.933e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.581e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:14,586] Trial 531 finished with value: -2.0947192565071995 and parameters: {'alpha': 5.970430148438401e-05, 'l1_ratio': 0.11562675270156042}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.365e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:25,601] Trial 553 finished with value: 0.26120913524871686 and parameters: {'alpha': 1.2879606296183563, 'l1_ratio': 0.17975329809876284}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.259e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:25,974] Trial 534 finished with value: 0.059883505784525504 and parameters: {'alpha': 19.569686466984425, 'l1_ratio': 5.7958729963736886e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:50:26,146] Trial 555 finished with value: 0.32417235114190385 and parameters: {'alpha': 39952.66720362784, 'l1_ratio': 0.00030790307027736444}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:27,771] Trial 556 finished with value: 0.3251466535172783 and parameters: {'alpha': 7.1367172727611194, 'l1_ratio': 0.6138029357971014}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.343e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:28,921] Trial 543 finished with value: -0.8202745005649644 and parameters: {'alpha': 1.0016037400953162, 'l1_ratio': 0.005582117559978315}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:50:30,613] Trial 559 finished with value: 0.33611980987919354 and parameters: {'alpha': 148147.17151082354, 'l1_ratio': 2.1315010229996935e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.281e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.733e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:49,167] Trial 544 finished with value: -0.9600358698474978 and parameters: {'alpha': 1.0652205287197158, 'l1_ratio': 2.799159427373248e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.030e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.445e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.477e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:54,873] Trial 561 finished with value: 0.35848760060982465 and parameters: {'alpha': 4.283969186598954, 'l1_ratio': 0.23365716712801643}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:50:56,433] Trial 549 finished with value: -0.8461107227636813 and parameters: {'alpha': 1.3064546553626328, 'l1_ratio': 0.0003514619156334449}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:51:08,400] Trial 551 finished with value: -0.9563664546385848 and parameters: {'alpha': 1.0728451811051358, 'l1_ratio': 2.476726960508197e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.827e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:51:13,700] Trial 562 finished with value: 0.3003708725906461 and parameters: {'alpha': 9.089945772710736, 'l1_ratio': 0.033515202447880046}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:16,508] Trial 563 finished with value: 0.2947905990108231 and parameters: {'alpha': 7.879920275197802, 'l1_ratio': 0.0370407784339455}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:17,482] Trial 566 finished with value: -1.459071482409423 and parameters: {'alpha': 6.458544042353701e-10, 'l1_ratio': 0.0008780780230224204}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:51:19,021] Trial 552 finished with value: -1.0408124695521126 and parameters: {'alpha': 0.9144444632633475, 'l1_ratio': 4.043087768726688e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:19,372] Trial 568 finished with value: -0.01417611650574598 and parameters: {'alpha': 583.245748129275, 'l1_ratio': 0.46008933891322784}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:21,198] Trial 569 finished with value: 0.3402071706583554 and parameters: {'alpha': 3.0613594908055553, 'l1_ratio': 0.9598221396037679}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:21,242] Trial 567 finished with value: -1.3533434915360392 and parameters: {'alpha': 9.527155317598098e-07, 'l1_ratio': 0.4272001516842154}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:21,351] Trial 560 finished with value: -0.4047925106032945 and parameters: {'alpha': 3.4114152359621506, 'l1_ratio': 0.0012191275273206498}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:25,066] Trial 570 finished with value: -1.2454379331087817 and parameters: {'alpha': 9.659558573983677e-06, 'l1_ratio': 0.010059108523363811}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:25,452] Trial 571 finished with value: -1.2163888129798313 and parameters: {'alpha': 1.947153855904714e-05, 'l1_ratio': 2.294470277508437e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:25,727] Trial 574 finished with value: 0.2787110440676368 and parameters: {'alpha': 181.85006273016432, 'l1_ratio': 0.2650167438729896}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:25,951] Trial 575 finished with value: -0.015530983180227128 and parameters: {'alpha': 32726.401481434455, 'l1_ratio': 0.1546392306879675}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.068e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:51:26,748] Trial 576 finished with value: 0.3199898967479248 and parameters: {'alpha': 16.017629044856772, 'l1_ratio': 0.5995133473309184}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:27,341] Trial 577 finished with value: 0.31429758218081766 and parameters: {'alpha': 98.20508623979751, 'l1_ratio': 0.3143665170694559}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:51:28,709] Trial 558 finished with value: -0.9068639932466932 and parameters: {'alpha': 1.0831949782125982, 'l1_ratio': 0.0012531639285753133}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:51:29,269] Trial 557 finished with value: -0.19415503325323338 and parameters: {'alpha': 7.321937599178585, 'l1_ratio': 0.00010208325753324948}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:51:34,212] Trial 554 finished with value: -0.8783777723335607 and parameters: {'alpha': 1.2544201362291105, 'l1_ratio': 7.377986170690298e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:51:35,561] Trial 581 finished with value: -1.517555969517879 and parameters: {'alpha': 1.3161261447077703e-07, 'l1_ratio': 0.08737052428981727}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.013e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.845e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.075e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.132e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.037e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.266e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.759e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:04,530] Trial 564 finished with value: -4.144038109063413 and parameters: {'alpha': 0.0008718250685372107, 'l1_ratio': 0.9848559714611163}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.397e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.368e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:18,730] Trial 572 finished with value: -2.124591846718434 and parameters: {'alpha': 2.6956685177988535e-05, 'l1_ratio': 0.27122739169249954}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.230e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:20,691] Trial 578 finished with value: -2.1681133956602676 and parameters: {'alpha': 0.052942383888120205, 'l1_ratio': 0.09511338949774713}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:52:20,947] Trial 585 finished with value: -0.015530983180227128 and parameters: {'alpha': 61560143.63624847, 'l1_ratio': 1.2462843816931383e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.886e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:26,820] Trial 565 finished with value: 0.3167671223679029 and parameters: {'alpha': 206.31133213478788, 'l1_ratio': 1.8010047260024438e-10}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.584e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:27,233] Trial 573 finished with value: -2.1486789761548835 and parameters: {'alpha': 3.010805325778497e-05, 'l1_ratio': 0.25581111939145484}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:52:27,590] Trial 587 finished with value: 0.3213172723681464 and parameters: {'alpha': 27.363634500462314, 'l1_ratio': 0.6449945987634395}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:52:27,724] Trial 588 finished with value: 0.32038895876691525 and parameters: {'alpha': 21.655407305160185, 'l1_ratio': 0.5765683480951329}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.129e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.912e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.175e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:40,036] Trial 579 finished with value: -0.2517336906262751 and parameters: {'alpha': 6.167603942621077, 'l1_ratio': 5.066713614984584e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:52:40,436] Trial 591 finished with value: -1.4547966029295487 and parameters: {'alpha': 3.5852061756344444e-08, 'l1_ratio': 0.9944569491506023}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:40,892] Trial 580 finished with value: -2.657490656966469 and parameters: {'alpha': 0.054332457545350446, 'l1_ratio': 1.5127671069443526e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:52:40,975] Trial 592 finished with value: -1.4577246596629323 and parameters: {'alpha': 1.0303526686896518e-08, 'l1_ratio': 0.18376307394054564}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.723e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.479e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.835e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:44,975] Trial 582 finished with value: 0.1508129192112416 and parameters: {'alpha': 32.137739607549655, 'l1_ratio': 8.566340185450887e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:52:48,210] Trial 595 finished with value: -1.2838435986902925 and parameters: {'alpha': 6.646432945407501e-06, 'l1_ratio': 0.015545515266716142}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:52:50,119] Trial 594 finished with value: 0.07519450813724142 and parameters: {'alpha': 3.895862639203052, 'l1_ratio': 0.019027311275603868}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.305e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.274e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:52:55,223] Trial 593 finished with value: 0.32035780768809236 and parameters: {'alpha': 2.856724397996042, 'l1_ratio': 0.14416035919653383}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.301e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.049e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:05,468] Trial 596 finished with value: 0.3137903833350297 and parameters: {'alpha': 2.729381275030404, 'l1_ratio': 0.13840914036499233}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.897e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:10,608] Trial 586 finished with value: -3.6309719371834768 and parameters: {'alpha': 0.010280829991817403, 'l1_ratio': 0.1733658391939464}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.816e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.878e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:21,114] Trial 583 finished with value: 0.1544524564112597 and parameters: {'alpha': 32.86710558990026, 'l1_ratio': 5.100094152408384e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:21,414] Trial 590 finished with value: -3.6493396321954834 and parameters: {'alpha': 0.010111306210752638, 'l1_ratio': 0.15537762607530706}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.125e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:22,421] Trial 598 finished with value: 0.22722357831246798 and parameters: {'alpha': 0.49537686529682196, 'l1_ratio': 0.38987177638332055}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:53:22,707] Trial 603 finished with value: -0.015530983180227128 and parameters: {'alpha': 7563400914.480205, 'l1_ratio': 0.5107988222107402}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:53:22,916] Trial 604 finished with value: -0.015530983180227128 and parameters: {'alpha': 280871473.4249573, 'l1_ratio': 0.0058725735246167345}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:53:23,346] Trial 605 finished with value: -1.4561817592040354 and parameters: {'alpha': 1.9444592105898794e-08, 'l1_ratio': 0.0022517427605814274}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.035e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:32,498] Trial 584 finished with value: -2.422221071448753 and parameters: {'alpha': 0.08387811595024008, 'l1_ratio': 0.0018530743445949092}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:33,969] Trial 599 finished with value: 0.2129694564947278 and parameters: {'alpha': 0.4523257546353109, 'l1_ratio': 0.403363861002805}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.512e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:38,559] Trial 589 finished with value: -0.4800849020707178 and parameters: {'alpha': 3.186420339877763, 'l1_ratio': 6.845549935958783e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.110e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.427e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:46,291] Trial 601 finished with value: 0.27078439757688855 and parameters: {'alpha': 0.6046876911054797, 'l1_ratio': 0.40502750627554424}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.378e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:48,604] Trial 602 finished with value: 0.25637591422105926 and parameters: {'alpha': 0.4930803982163239, 'l1_ratio': 0.4567065965416103}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:53:49,238] Trial 609 finished with value: 0.34812232571210816 and parameters: {'alpha': 11.933120485094035, 'l1_ratio': 0.04999829923484524}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:53:49,530] Trial 612 finished with value: -0.015530983180227128 and parameters: {'alpha': 538339778.1855991, 'l1_ratio': 4.013829338920652e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:53:53,100] Trial 613 finished with value: 0.3561959617013009 and parameters: {'alpha': 5.096271828808517, 'l1_ratio': 0.2516500540784794}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:53:57,777] Trial 610 finished with value: 0.3493742480997195 and parameters: {'alpha': 10.697042038025797, 'l1_ratio': 0.05960870174963385}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:53:58,221] Trial 615 finished with value: 0.2795870754956958 and parameters: {'alpha': 68.33767161052302, 'l1_ratio': 0.701173509573993}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:54:01,408] Trial 616 finished with value: 0.3553407582890843 and parameters: {'alpha': 1.844100247915208, 'l1_ratio': 0.9769932891907298}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.439e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:54:11,900] Trial 597 finished with value: -1.3030852462962523 and parameters: {'alpha': 0.5705615485418191, 'l1_ratio': 2.735147937708796e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:54:12,239] Trial 618 finished with value: -0.015530983180227128 and parameters: {'alpha': 172190257.604705, 'l1_ratio': 0.08983030079374717}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:54:28,926] Trial 600 finished with value: -1.2687998712805169 and parameters: {'alpha': 0.602674128437366, 'l1_ratio': 0.00016755393608546164}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:54:30,469] Trial 620 finished with value: 0.3327574256949249 and parameters: {'alpha': 9.981194209901588, 'l1_ratio': 0.3293748504779955}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.562e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:54:39,197] Trial 606 finished with value: -0.1211662885794876 and parameters: {'alpha': 9.543440149934943, 'l1_ratio': 2.1296676153915495e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:54:39,554] Trial 622 finished with value: -0.015530983180227128 and parameters: {'alpha': 8439145.021258919, 'l1_ratio': 0.6302036910748476}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:54:40,680] Trial 617 finished with value: 0.3393680485949116 and parameters: {'alpha': 2855.627382371227, 'l1_ratio': 5.3319235266236294e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:54:46,227] Trial 611 finished with value: -0.08404046543704391 and parameters: {'alpha': 10.693023420549702, 'l1_ratio': 0.0001244699691635732}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.578e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:54:49,615] Trial 607 finished with value: -0.12571209880544307 and parameters: {'alpha': 9.393350642481035, 'l1_ratio': 7.324394956303293e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.498e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:54:51,461] Trial 608 finished with value: -0.07408028577053798 and parameters: {'alpha': 11.314007749672752, 'l1_ratio': 1.6623568568371617e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:54:51,687] Trial 627 finished with value: 0.00985912368462379 and parameters: {'alpha': 789.04787772033, 'l1_ratio': 0.234478456705283}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.578e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.349e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.558e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:06,840] Trial 614 finished with value: -0.07437295570133844 and parameters: {'alpha': 11.30899203707645, 'l1_ratio': 1.2851668728348819e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.925e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:08,530] Trial 619 finished with value: -4.206927979808516 and parameters: {'alpha': 0.0027272989592945305, 'l1_ratio': 0.2712558734749587}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:09,387] Trial 630 finished with value: 0.313674552802458 and parameters: {'alpha': 275889.10691236675, 'l1_ratio': 2.861410013078374e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:10,081] Trial 631 finished with value: 0.33994448998307025 and parameters: {'alpha': 120300.15626260753, 'l1_ratio': 1.1743520314843844e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.731e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.142e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.143e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:20,249] Trial 629 finished with value: -0.06069600438672277 and parameters: {'alpha': 1.9265257453857036, 'l1_ratio': 0.029223155484580356}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:22,739] Trial 632 finished with value: -0.07679431670931695 and parameters: {'alpha': 1.5635252043081236, 'l1_ratio': 0.03618141315227113}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:25,218] Trial 624 finished with value: -0.49011235414007776 and parameters: {'alpha': 2.194687018945744, 'l1_ratio': 0.0037281538627746886}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:26,845] Trial 633 finished with value: 0.33335234357105353 and parameters: {'alpha': 8292.04022108272, 'l1_ratio': 3.5400441943542084e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:27,375] Trial 636 finished with value: 0.31686561532083074 and parameters: {'alpha': 245.56096768207303, 'l1_ratio': 0.11163990896044071}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.805e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:39,018] Trial 625 finished with value: -0.48030471306019 and parameters: {'alpha': 2.2357475667740085, 'l1_ratio': 0.00378789121486211}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.059e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:40,211] Trial 621 finished with value: 0.33872436419636354 and parameters: {'alpha': 542.461583099529, 'l1_ratio': 1.1012541149715463e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:41,423] Trial 638 finished with value: 0.34387954460932685 and parameters: {'alpha': 3.7109824394436117, 'l1_ratio': 0.7319788161156058}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:42,117] Trial 640 finished with value: -1.4525047372969182 and parameters: {'alpha': 4.5157363468172274e-08, 'l1_ratio': 5.51531929021822e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.502e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.950e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:45,203] Trial 623 finished with value: -0.6466471365699425 and parameters: {'alpha': 2.0731206459335296, 'l1_ratio': 0.00012002066256363234}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:45,841] Trial 642 finished with value: 0.3124440850602468 and parameters: {'alpha': 69.72434803313912, 'l1_ratio': 0.4658694970177643}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.186e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:46,707] Trial 643 finished with value: -1.4588958029007904 and parameters: {'alpha': 1.9495863138270462e-09, 'l1_ratio': 0.20229885208167078}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:55:47,100] Trial 644 finished with value: 0.3185798769335579 and parameters: {'alpha': 38.10824753075056, 'l1_ratio': 0.577885950434406}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:48,760] Trial 628 finished with value: -2.9049618809227606 and parameters: {'alpha': 0.005813061561030728, 'l1_ratio': 0.9980970683730025}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.785e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:55:53,910] Trial 639 finished with value: 0.09621218267102179 and parameters: {'alpha': 0.14545148193733373, 'l1_ratio': 0.6981088161300003}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.990e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.640e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.654e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.064e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:56:10,747] Trial 641 finished with value: -0.10494403673150261 and parameters: {'alpha': 0.1468062319837437, 'l1_ratio': 0.46345121719228405}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.235e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:56:12,465] Trial 626 finished with value: -0.6463054869554511 and parameters: {'alpha': 2.0978690695478672, 'l1_ratio': 2.2925710399119513e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.471e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.857e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:56:17,493] Trial 648 finished with value: 0.3547863225511882 and parameters: {'alpha': 89.18122641765548, 'l1_ratio': 0.009851098273705693}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.874e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.070e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.690e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:56:30,966] Trial 635 finished with value: -2.2408427557720936 and parameters: {'alpha': 0.11175313627649991, 'l1_ratio': 0.008151773019657908}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:56:41,771] Trial 646 finished with value: -0.9194754495981251 and parameters: {'alpha': 0.21935991953128742, 'l1_ratio': 0.07121408091507937}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.056e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:56:42,453] Trial 652 finished with value: -1.4988911901230664 and parameters: {'alpha': 2.611343320311203e-07, 'l1_ratio': 5.24592252403852e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:56:42,467] Trial 634 finished with value: 0.27889474956363675 and parameters: {'alpha': 98.06085504045404, 'l1_ratio': 9.784266936406452e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:56:42,782] Trial 653 finished with value: -0.015530983180227128 and parameters: {'alpha': 32120668.074127305, 'l1_ratio': 0.2912749332583029}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:56:44,045] Trial 645 finished with value: -0.8888432590930738 and parameters: {'alpha': 0.20762259443644113, 'l1_ratio': 0.08277963715038464}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.673e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.409e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:56:49,045] Trial 637 finished with value: -2.129403453120829 and parameters: {'alpha': 0.14684489464729433, 'l1_ratio': 1.5973332612908046e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:56:58,429] Trial 656 finished with value: 0.3477798718891792 and parameters: {'alpha': 4.72274847053509, 'l1_ratio': 0.12893444085855546}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:56:58,841] Trial 655 finished with value: 0.3370968261858521 and parameters: {'alpha': 4.5752421999218615, 'l1_ratio': 0.1125651550842071}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.226e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.328e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:57:08,431] Trial 647 finished with value: -0.3436034372555689 and parameters: {'alpha': 4.666230522969646, 'l1_ratio': 3.6045369620582443e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:08,670] Trial 660 finished with value: -0.015530983180227128 and parameters: {'alpha': 597202.1865749168, 'l1_ratio': 0.20475613586091984}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.205e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:57:09,685] Trial 661 finished with value: 0.31141071697362727 and parameters: {'alpha': 23.523900019133137, 'l1_ratio': 0.28560741359051545}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.588e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:57:17,145] Trial 650 finished with value: -0.30801565239474293 and parameters: {'alpha': 4.876872510625739, 'l1_ratio': 0.000494759658942682}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:17,348] Trial 663 finished with value: -0.015530983180227128 and parameters: {'alpha': 79793.18720331664, 'l1_ratio': 0.36906153184995594}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.646e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.862e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.860e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.032e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:57:29,626] Trial 651 finished with value: -3.0223649644227444 and parameters: {'alpha': 0.027717243380302375, 'l1_ratio': 0.06424800855330322}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:29,711] Trial 662 finished with value: 0.29377280851451687 and parameters: {'alpha': 0.7573240666213973, 'l1_ratio': 0.41793141002821904}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:30,252] Trial 666 finished with value: 0.3205039812705726 and parameters: {'alpha': 22.940505938077877, 'l1_ratio': 0.6928045474426004}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:57:35,773] Trial 649 finished with value: -0.30885782251984506 and parameters: {'alpha': 5.173234537991834, 'l1_ratio': 4.197679247146663e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:36,368] Trial 668 finished with value: -1.4586619588503071 and parameters: {'alpha': 3.4030956859117144e-09, 'l1_ratio': 8.116311656800301e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.478e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:57:36,812] Trial 654 finished with value: -2.055582947896753 and parameters: {'alpha': 0.02955668558098516, 'l1_ratio': 0.279044354967164}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:37,648] Trial 669 finished with value: -1.4342824655550332 and parameters: {'alpha': 5.835916312720223e-07, 'l1_ratio': 2.4608825852051986e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:40,706] Trial 665 finished with value: 0.34904683843411416 and parameters: {'alpha': 0.6623016160994547, 'l1_ratio': 0.9929952084678563}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:40,853] Trial 672 finished with value: -0.015530983180227128 and parameters: {'alpha': 1071175.7372455369, 'l1_ratio': 0.0007510120810281604}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.093e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:57:45,074] Trial 657 finished with value: -3.0976078729492342 and parameters: {'alpha': 0.0016950314434248236, 'l1_ratio': 0.14060029510227134}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:57:48,815] Trial 674 finished with value: -1.3200875894834236 and parameters: {'alpha': 3.510182007881692e-06, 'l1_ratio': 0.014187706013372978}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.056e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:57:58,383] Trial 667 finished with value: -0.450847413713562 and parameters: {'alpha': 1.0203841959165592, 'l1_ratio': 0.024549230157145364}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:08,245] Trial 676 finished with value: 0.34545469494947995 and parameters: {'alpha': 1294.142055949026, 'l1_ratio': 6.707465440499532e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:08,872] Trial 677 finished with value: -1.458998086567035 and parameters: {'alpha': 1.1244632443371443e-09, 'l1_ratio': 1.409634710306966e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.937e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:11,581] Trial 658 finished with value: -0.3360056045206083 and parameters: {'alpha': 4.771453707362558, 'l1_ratio': 2.0144205601920682e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.002e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.669e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:16,737] Trial 659 finished with value: 0.12075123409384174 and parameters: {'alpha': 27.041449323495897, 'l1_ratio': 3.3462903192199834e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:16,760] Trial 679 finished with value: -1.2546990794824073 and parameters: {'alpha': 8.493392018337756e-06, 'l1_ratio': 1.447059608212572e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.238e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:17,341] Trial 675 finished with value: 0.28056061481194117 and parameters: {'alpha': 1.438126241982502, 'l1_ratio': 0.18664831715160912}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:17,918] Trial 682 finished with value: 0.31976067045407447 and parameters: {'alpha': 16.0133401070425, 'l1_ratio': 0.5331068385101742}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:21,459] Trial 680 finished with value: -1.3836040947139567 and parameters: {'alpha': 7.899390577391785e-07, 'l1_ratio': 0.20294136470073904}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:21,745] Trial 684 finished with value: -0.015530983180227128 and parameters: {'alpha': 1716334678.8047578, 'l1_ratio': 0.3842982327997275}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.382e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:35,752] Trial 678 finished with value: 0.2883652493700352 and parameters: {'alpha': 1.4658910245991947, 'l1_ratio': 0.201625801754042}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.207e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:42,120] Trial 664 finished with value: -1.0880284048640538 and parameters: {'alpha': 0.8387342987787684, 'l1_ratio': 7.274505374193038e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.034e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:43,478] Trial 683 finished with value: 0.21730125561382774 and parameters: {'alpha': 0.5102203706602388, 'l1_ratio': 0.3635592098765514}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:44,317] Trial 688 finished with value: 0.31746152638231523 and parameters: {'alpha': 13.011206658817466, 'l1_ratio': 0.6226103999398657}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.899e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:47,365] Trial 685 finished with value: 0.2826380386830044 and parameters: {'alpha': 0.43352740770660714, 'l1_ratio': 0.6504544449250639}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:47,398] Trial 689 finished with value: 0.3571159983961219 and parameters: {'alpha': 41.503617984941734, 'l1_ratio': 0.0390407504192435}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:47,689] Trial 690 finished with value: -0.015530983180227128 and parameters: {'alpha': 148518147.44070187, 'l1_ratio': 0.0015689897810863005}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:48,372] Trial 691 finished with value: -1.4300640352212877 and parameters: {'alpha': 2.3588029468451382e-07, 'l1_ratio': 0.9657592121691457}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:48,989] Trial 692 finished with value: 0.34561251096594886 and parameters: {'alpha': 2.599542199361042, 'l1_ratio': 0.9955188797120541}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:49,518] Trial 694 finished with value: -1.4592834487066002 and parameters: {'alpha': 1.9861138085656912e-10, 'l1_ratio': 0.10096402122515157}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:49,880] Trial 695 finished with value: 0.24951047437652393 and parameters: {'alpha': 169.58029830090743, 'l1_ratio': 0.3334354206095532}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:52,203] Trial 673 finished with value: -0.8707000961143022 and parameters: {'alpha': 1.269991608809204, 'l1_ratio': 4.706377476198112e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:52,590] Trial 697 finished with value: -0.015530983180227128 and parameters: {'alpha': 455171.79595239495, 'l1_ratio': 0.0538711462592907}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:55,894] Trial 698 finished with value: 0.33367123140064814 and parameters: {'alpha': 13324.601128564304, 'l1_ratio': 8.232386335240913e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:58,114] Trial 699 finished with value: 0.3444372020625864 and parameters: {'alpha': 5.536102801076862, 'l1_ratio': 0.4837992096179268}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:58:58,600] Trial 700 finished with value: 0.3170096871567257 and parameters: {'alpha': 57.106814501302146, 'l1_ratio': 0.1400735697351461}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:58:59,515] Trial 671 finished with value: -0.9809027963120157 and parameters: {'alpha': 1.0092551304704058, 'l1_ratio': 0.00022882814781664926}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:59:02,524] Trial 702 finished with value: 0.338811262125063 and parameters: {'alpha': 31285.97410936569, 'l1_ratio': 5.275064780477365e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:59:05,496] Trial 696 finished with value: 0.3285110428132621 and parameters: {'alpha': 7.268317047073484, 'l1_ratio': 0.06116607591424365}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:59:06,201] Trial 670 finished with value: -1.154025538966952 and parameters: {'alpha': 0.7431343859188612, 'l1_ratio': 3.253728414127743e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.096e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:59:16,510] Trial 693 finished with value: -1.640254610544972 and parameters: {'alpha': 0.00018151323011544822, 'l1_ratio': 1.2354072274268786e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:59:21,685] Trial 706 finished with value: 0.3489795334728112 and parameters: {'alpha': 1661.2540238759505, 'l1_ratio': 0.00033174668662124023}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:59:22,554] Trial 707 finished with value: 0.32182340398716164 and parameters: {'alpha': 19.320796964381394, 'l1_ratio': 0.269548068053817}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.501e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.338e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.844e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.236e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:59:40,323] Trial 681 finished with value: -0.7777234079228538 and parameters: {'alpha': 1.5546487061978176, 'l1_ratio': 7.613070375497588e-10}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.085e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:59:53,151] Trial 709 finished with value: -0.014317561163031919 and parameters: {'alpha': 2.881323952279179, 'l1_ratio': 0.020077097365098065}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+00, tolerance: 4.591e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 16:59:54,030] Trial 687 finished with value: -1.4296680264107962 and parameters: {'alpha': 0.4621098435701359, 'l1_ratio': 3.7867736238772084e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:59:54,032] Trial 710 finished with value: 0.3217651086408016 and parameters: {'alpha': 8.55810681776878, 'l1_ratio': 0.6095033940034603}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:59:54,059] Trial 686 finished with value: -1.3873323518596086 and parameters: {'alpha': 0.49530336048427753, 'l1_ratio': 8.566562961829413e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:59:54,551] Trial 711 finished with value: -0.005880912456986113 and parameters: {'alpha': 35838370.20190191, 'l1_ratio': 1.1856774624544982e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 16:59:55,383] Trial 712 finished with value: -1.448317302815513 and parameters: {'alpha': 7.973078863014299e-08, 'l1_ratio': 0.339755887833714}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.608e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:00:12,939] Trial 701 finished with value: -2.3913557092249778 and parameters: {'alpha': 0.0026602378650669393, 'l1_ratio': 5.866849722398729e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:13,213] Trial 716 finished with value: 0.21951714364149677 and parameters: {'alpha': 334.1234135384851, 'l1_ratio': 0.19032125867631294}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:00:16,758] Trial 704 finished with value: -2.081176625590306 and parameters: {'alpha': 0.0007634637707900078, 'l1_ratio': 0.02113909441846981}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:18,078] Trial 715 finished with value: 0.28509989307991696 and parameters: {'alpha': 2.9487238888466982, 'l1_ratio': 0.0942505934878364}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.820e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:00:19,554] Trial 703 finished with value: -0.05989435991937305 and parameters: {'alpha': 11.977258456960977, 'l1_ratio': 3.313856763786488e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.695e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:00:21,245] Trial 708 finished with value: -2.9197447417064395 and parameters: {'alpha': 0.005122194798252709, 'l1_ratio': 0.00558957859786893}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:24,649] Trial 721 finished with value: 0.24746545663541378 and parameters: {'alpha': 50.734245289497515, 'l1_ratio': 0.0009213770932835883}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:28,223] Trial 722 finished with value: 0.35727993002476305 and parameters: {'alpha': 2.8829423022664225, 'l1_ratio': 0.5589510803446}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.245e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:00:28,830] Trial 705 finished with value: 0.039664624756437915 and parameters: {'alpha': 18.102758845651994, 'l1_ratio': 2.1326472431965697e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:29,306] Trial 723 finished with value: 0.31148809282870005 and parameters: {'alpha': 24.654722070414035, 'l1_ratio': 0.2702069181238955}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:31,903] Trial 725 finished with value: 0.35489223778275375 and parameters: {'alpha': 4.034665279590233, 'l1_ratio': 0.45606875280770903}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:39,801] Trial 720 finished with value: 0.3150568541298294 and parameters: {'alpha': 52.285778031683364, 'l1_ratio': 0.00504011182156975}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:40,995] Trial 718 finished with value: -0.3417145668286939 and parameters: {'alpha': 2.6510453692572162, 'l1_ratio': 0.005915341684208557}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+00, tolerance: 4.591e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:00:42,649] Trial 714 finished with value: 0.06276414313148926 and parameters: {'alpha': 19.22201484153929, 'l1_ratio': 0.00017658347257104682}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:43,174] Trial 729 finished with value: 0.005460781313970024 and parameters: {'alpha': 19208143.154923648, 'l1_ratio': 3.8391716921779497e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:44,135] Trial 730 finished with value: -1.4592909060877746 and parameters: {'alpha': 1.414226551560055e-10, 'l1_ratio': 8.805317058621989e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.323e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:00:51,673] Trial 713 finished with value: -0.4339345005778927 and parameters: {'alpha': 3.3924600921104022, 'l1_ratio': 0.0005744475778873197}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:52,278] Trial 732 finished with value: 0.3174931643621659 and parameters: {'alpha': 162.93795073981605, 'l1_ratio': 0.14381098046937282}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:00:52,637] Trial 733 finished with value: -0.015530983180227128 and parameters: {'alpha': 4280196432.2262497, 'l1_ratio': 0.6924771053896583}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.076e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.791e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.497e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.363e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.594e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:01:15,199] Trial 734 finished with value: 0.3353716977955163 and parameters: {'alpha': 4957.608229271734, 'l1_ratio': 4.9637374236107704e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.259e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.912e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.465e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.232e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:01:30,576] Trial 719 finished with value: 0.036877641608271526 and parameters: {'alpha': 17.87713921906065, 'l1_ratio': 1.5141821597400387e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:01:30,973] Trial 736 finished with value: -0.015530983180227128 and parameters: {'alpha': 1697714743.0559223, 'l1_ratio': 0.0022744481965091866}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.916e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:01:36,841] Trial 717 finished with value: -0.4889137188238864 and parameters: {'alpha': 3.1150375844283125, 'l1_ratio': 4.1893864016864414e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.428e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:01:39,832] Trial 724 finished with value: -2.4132381669868876 and parameters: {'alpha': 5.0444669734937105e-05, 'l1_ratio': 0.278839960644011}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.980e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.591e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.031e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:01:47,864] Trial 726 finished with value: -0.20903285856763884 and parameters: {'alpha': 7.054587264642778, 'l1_ratio': 1.9460039685403252e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.390e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:01:55,079] Trial 728 finished with value: -0.18179459606813883 and parameters: {'alpha': 7.740971093387634, 'l1_ratio': 4.1526543610076084e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.963e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.538e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:01:57,211] Trial 727 finished with value: 0.30439477388474856 and parameters: {'alpha': 152.13306259050464, 'l1_ratio': 9.65935091106997e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:01:59,326] Trial 742 finished with value: 0.35689390760137835 and parameters: {'alpha': 1.346259605747443, 'l1_ratio': 0.9884677991054943}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.873e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:04,705] Trial 731 finished with value: -0.212050241969299 and parameters: {'alpha': 7.003971301657608, 'l1_ratio': 3.717906190856498e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.644e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:05,271] Trial 739 finished with value: 0.18568783704299752 and parameters: {'alpha': 0.3660930947008303, 'l1_ratio': 0.4254042555086763}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:06,583] Trial 745 finished with value: -1.4532490867386936 and parameters: {'alpha': 3.9949291685017587e-08, 'l1_ratio': 0.03420746899668032}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:06,911] Trial 746 finished with value: -0.015530983180227128 and parameters: {'alpha': 3705747.527720324, 'l1_ratio': 0.10724058789471132}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:07,260] Trial 747 finished with value: -0.015530983180227128 and parameters: {'alpha': 162461.25746613165, 'l1_ratio': 0.2023030997423981}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.490e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.685e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.113e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:18,360] Trial 735 finished with value: -1.5756898654563372 and parameters: {'alpha': 0.34321429487308264, 'l1_ratio': 0.001686652434335768}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:22,006] Trial 744 finished with value: 0.161325646200834 and parameters: {'alpha': 0.31286373431056913, 'l1_ratio': 0.4346069354816606}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.768e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:28,621] Trial 748 finished with value: -0.04491270066423677 and parameters: {'alpha': 0.11444365491891341, 'l1_ratio': 0.6642204941807592}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.906e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.899e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.040e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:42,592] Trial 751 finished with value: 0.021074159249976316 and parameters: {'alpha': 1.1631079032760567, 'l1_ratio': 0.06635175255415089}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:42,849] Trial 752 finished with value: -0.015530983180227128 and parameters: {'alpha': 960497354.5591705, 'l1_ratio': 0.16472978506365055}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.295e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.266e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:45,771] Trial 737 finished with value: -2.4867973331643873 and parameters: {'alpha': 0.07502295084854076, 'l1_ratio': 1.9089025037125863e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.098e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:46,429] Trial 740 finished with value: -1.6716753277478882 and parameters: {'alpha': 0.3211692347090046, 'l1_ratio': 1.0405705647182596e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:47,613] Trial 750 finished with value: -0.513021377656454 and parameters: {'alpha': 0.06073909213568873, 'l1_ratio': 0.6754112835658879}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:47,617] Trial 749 finished with value: -0.18255624968993478 and parameters: {'alpha': 0.09248477213353962, 'l1_ratio': 0.6417726604879123}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:47,930] Trial 755 finished with value: -0.015530983180227128 and parameters: {'alpha': 615175327.3676616, 'l1_ratio': 0.30891706141781383}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:48,759] Trial 757 finished with value: -1.4582506008012097 and parameters: {'alpha': 6.8389570711813886e-09, 'l1_ratio': 0.31848722967092896}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:48,760] Trial 756 finished with value: -1.4592623522034285 and parameters: {'alpha': 3.3710578779175926e-10, 'l1_ratio': 0.01400848832324334}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.742e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:51,562] Trial 743 finished with value: -1.1116604722794263 and parameters: {'alpha': 0.2486155107628376, 'l1_ratio': 0.03946249232476149}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:02:52,862] Trial 738 finished with value: -0.897051093649644 and parameters: {'alpha': 1.2061570479052914, 'l1_ratio': 1.428195100382359e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:53,061] Trial 762 finished with value: -0.015530983180227128 and parameters: {'alpha': 1274792.964687177, 'l1_ratio': 0.112340892712399}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:02:55,861] Trial 763 finished with value: 0.35758761204492134 and parameters: {'alpha': 1.5759813535049336, 'l1_ratio': 0.9971850474191323}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.109e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.651e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.755e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:03:05,717] Trial 741 finished with value: -1.5944783458265779 and parameters: {'alpha': 0.3604281297935935, 'l1_ratio': 3.367707361423486e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:09,480] Trial 765 finished with value: 0.3565716196378776 and parameters: {'alpha': 6.187147910089373, 'l1_ratio': 0.21040649333864747}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:09,813] Trial 766 finished with value: -0.015530983180227128 and parameters: {'alpha': 52895120.42628145, 'l1_ratio': 8.592222750281378e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:09,989] Trial 761 finished with value: 0.16425992169448433 and parameters: {'alpha': 1.3599096191073008, 'l1_ratio': 0.09864736656463183}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.807e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:03:10,294] Trial 767 finished with value: 0.05711872402105833 and parameters: {'alpha': 5711804.153598262, 'l1_ratio': 2.9755174436181015e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:11,033] Trial 769 finished with value: 0.3201920666046058 and parameters: {'alpha': 28.808749567081055, 'l1_ratio': 0.41632427507040093}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:11,324] Trial 770 finished with value: 0.04912367557036242 and parameters: {'alpha': 560.6343069603736, 'l1_ratio': 0.21592217227694094}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:11,496] Trial 771 finished with value: -0.015530983180227128 and parameters: {'alpha': 119732189.54363404, 'l1_ratio': 0.008165050245990712}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:11,626] Trial 768 finished with value: -1.5106026292199455 and parameters: {'alpha': 1.7848248866712068e-07, 'l1_ratio': 3.4416930278535016e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:12,093] Trial 760 finished with value: 0.180282844365482 and parameters: {'alpha': 1.578469020247997, 'l1_ratio': 0.09316050691392648}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:13,851] Trial 773 finished with value: -1.2834431093630148 and parameters: {'alpha': 6.275442151486236e-06, 'l1_ratio': 2.2487303401976692e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:15,438] Trial 775 finished with value: 0.3234229063715591 and parameters: {'alpha': 9.808044952786894, 'l1_ratio': 0.4700583724546886}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.030e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.754e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.161e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:03:28,797] Trial 753 finished with value: -1.7460056076308736 and parameters: {'alpha': 0.031347361786195446, 'l1_ratio': 0.3505510516441919}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.658e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.405e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.782e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.387e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:03:40,036] Trial 777 finished with value: 0.3520003227920047 and parameters: {'alpha': 4.483246860356296, 'l1_ratio': 0.15236660917077657}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:40,230] Trial 754 finished with value: -2.366654744646537 and parameters: {'alpha': 0.020779488513639418, 'l1_ratio': 0.29709542583406534}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:40,404] Trial 778 finished with value: 0.2741472097858803 and parameters: {'alpha': 76.9819949200124, 'l1_ratio': 0.6452784441119858}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:03:41,231] Trial 780 finished with value: -1.4592428749922888 and parameters: {'alpha': 4.76571778820482e-10, 'l1_ratio': 0.0551475792360178}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:03:41,771] Trial 781 finished with value: -1.4589484499447365 and parameters: {'alpha': 1.4632268607329403e-09, 'l1_ratio': 1.3672557572935358e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:03:51,338] Trial 764 finished with value: -3.139433999176027 and parameters: {'alpha': 0.0012101547697532411, 'l1_ratio': 0.23668615513144853}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.395e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.589e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:00,999] Trial 782 finished with value: 0.3176585774961213 and parameters: {'alpha': 14.487501270110064, 'l1_ratio': 0.024418229398732453}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:02,593] Trial 759 finished with value: -0.8139010307476454 and parameters: {'alpha': 1.4358983190653556, 'l1_ratio': 1.013200252219789e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.201e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:04,514] Trial 784 finished with value: 0.3556128568111923 and parameters: {'alpha': 2.450220695291101, 'l1_ratio': 0.4908216919374409}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:05,652] Trial 758 finished with value: -0.8995157961813371 and parameters: {'alpha': 1.2012792237749432, 'l1_ratio': 1.9823614626504073e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:04:06,055] Trial 787 finished with value: 0.3130296640894251 and parameters: {'alpha': 44.74066209753284, 'l1_ratio': 0.715630936923998}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.805e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.292e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:13,320] Trial 774 finished with value: -2.8745745514525383 and parameters: {'alpha': 0.0002973570796376154, 'l1_ratio': 0.4828596636225825}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:04:13,737] Trial 789 finished with value: -0.015530983180227128 and parameters: {'alpha': 20380163.929110277, 'l1_ratio': 0.15524777875400025}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:04:14,572] Trial 790 finished with value: 0.3111204650472859 and parameters: {'alpha': 6.901242693066528, 'l1_ratio': 0.9958476094955778}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:04:14,919] Trial 791 finished with value: -0.015530983180227128 and parameters: {'alpha': 483717.8935824826, 'l1_ratio': 0.010809957182853025}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.235e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:15,368] Trial 776 finished with value: 0.21768753755328732 and parameters: {'alpha': 51.23021254418938, 'l1_ratio': 4.6693672679062826e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.876e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.794e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:24,359] Trial 772 finished with value: 0.2605795483986217 and parameters: {'alpha': 77.67753417772872, 'l1_ratio': 3.700179743638159e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.459e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.112e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.488e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.607e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.129e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.191e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.289e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:51,284] Trial 794 finished with value: 0.2726393953956624 and parameters: {'alpha': 4.21292850690436, 'l1_ratio': 0.0572237500052638}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.254e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:04:57,330] Trial 793 finished with value: -0.3307179576867995 and parameters: {'alpha': 3.1628850485850566, 'l1_ratio': 0.004020649446467134}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:04:58,412] Trial 796 finished with value: -1.4514145508624514 and parameters: {'alpha': 5.4666568186141046e-08, 'l1_ratio': 0.24476904156655288}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:00,127] Trial 795 finished with value: 0.11416818930880505 and parameters: {'alpha': 15.263943771381621, 'l1_ratio': 0.0026197523857545133}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:00,456] Trial 797 finished with value: 0.34185216723892364 and parameters: {'alpha': 1946.7894401692233, 'l1_ratio': 0.0010066179004731492}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:01,428] Trial 799 finished with value: -1.4586827269512468 and parameters: {'alpha': 3.67310859489759e-09, 'l1_ratio': 0.36988431842460556}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.364e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.065e+00, tolerance: 4.591e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.569e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:02,333] Trial 779 finished with value: 0.2792908789243675 and parameters: {'alpha': 98.61802477518357, 'l1_ratio': 2.037104720184771e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:10,303] Trial 798 finished with value: 0.3535353661013658 and parameters: {'alpha': 0.7147062325476174, 'l1_ratio': 0.9956092273803586}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.853e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:10,820] Trial 783 finished with value: -0.051234433369522714 and parameters: {'alpha': 12.385025932287821, 'l1_ratio': 1.1988937291242082e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:12,304] Trial 801 finished with value: 0.35428062348844386 and parameters: {'alpha': 0.7382221778804018, 'l1_ratio': 0.9831682122987532}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:12,959] Trial 802 finished with value: 0.34200954752552276 and parameters: {'alpha': 47890.40741455645, 'l1_ratio': 1.3842615102794956e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:13,185] Trial 804 finished with value: 0.32074009413985133 and parameters: {'alpha': 250.77972075473124, 'l1_ratio': 0.07952895192954561}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:21,402] Trial 785 finished with value: -0.489533408944461 and parameters: {'alpha': 3.0623456357607104, 'l1_ratio': 0.00014789815388005124}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:22,744] Trial 807 finished with value: 0.32575739184310004 and parameters: {'alpha': 7.205457178891847, 'l1_ratio': 0.5132374917117322}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:22,900] Trial 808 finished with value: -0.015530983180227128 and parameters: {'alpha': 2267168139.6945014, 'l1_ratio': 0.15444448971010277}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:25,020] Trial 806 finished with value: 0.3561429058649173 and parameters: {'alpha': 5.37994581485288, 'l1_ratio': 0.14087529710091365}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:25,512] Trial 810 finished with value: 0.31985723293243246 and parameters: {'alpha': 30.621256001282248, 'l1_ratio': 0.2962946759186765}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.831e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:26,502] Trial 786 finished with value: 0.26257398799403214 and parameters: {'alpha': 79.51362815378242, 'l1_ratio': 1.2154103770344773e-10}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.044e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:27,843] Trial 788 finished with value: -0.273654413598675 and parameters: {'alpha': 5.75592153800247, 'l1_ratio': 5.068623405687535e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:28,453] Trial 813 finished with value: -1.4590797205813855 and parameters: {'alpha': 5.965860958098997e-10, 'l1_ratio': 0.03650747032056896}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:29,594] Trial 792 finished with value: -0.33255337672436763 and parameters: {'alpha': 4.752047853507053, 'l1_ratio': 0.00011885053894172668}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.409e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.255e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:36,589] Trial 803 finished with value: 0.2569633984382244 and parameters: {'alpha': 2.7243699981778557, 'l1_ratio': 0.08177558236269993}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:44,092] Trial 811 finished with value: 0.3171250094250648 and parameters: {'alpha': 0.6389047470243574, 'l1_ratio': 0.6284032572781802}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:44,995] Trial 817 finished with value: -1.4571160017966678 and parameters: {'alpha': 1.3850963595844186e-08, 'l1_ratio': 0.2220798382502394}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:45,404] Trial 812 finished with value: 0.29657093846785904 and parameters: {'alpha': 0.630233959699894, 'l1_ratio': 0.5162491260987198}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:45,678] Trial 818 finished with value: -0.015530983180227128 and parameters: {'alpha': 881.6230205319828, 'l1_ratio': 0.39851672239524777}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:05:46,782] Trial 819 finished with value: 0.3111390680524177 and parameters: {'alpha': 19.566367075653528, 'l1_ratio': 0.35176647407464645}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:47,356] Trial 814 finished with value: 0.3224013086381676 and parameters: {'alpha': 0.6936229051732469, 'l1_ratio': 0.6180525916311655}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.681e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.699e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.730e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:05:52,079] Trial 822 finished with value: 0.3354599223114963 and parameters: {'alpha': 7607.927166535769, 'l1_ratio': 5.540017976029159e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.829e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:06:07,925] Trial 820 finished with value: 0.11685595375432352 and parameters: {'alpha': 23.899487564958072, 'l1_ratio': 0.00035078753526201383}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.512e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:06:11,004] Trial 805 finished with value: -3.697115951843775 and parameters: {'alpha': 0.00912265580856143, 'l1_ratio': 0.07643322101056138}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.041e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:06:16,771] Trial 823 finished with value: -0.253836980355315 and parameters: {'alpha': 1.842551828958824, 'l1_ratio': 0.017251659961270493}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:06:19,833] Trial 800 finished with value: -0.18019276394845452 and parameters: {'alpha': 7.782601641068878, 'l1_ratio': 1.290454342457523e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:06:23,785] Trial 815 finished with value: -2.836589669189297 and parameters: {'alpha': 0.008887530798482424, 'l1_ratio': 0.6050175163887312}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:06:24,024] Trial 828 finished with value: -0.015530983180227128 and parameters: {'alpha': 2819832.3202532292, 'l1_ratio': 0.00024382247813717288}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.992e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:06:30,603] Trial 824 finished with value: 0.2974172284331743 and parameters: {'alpha': 1.7092745186878286, 'l1_ratio': 0.18897193671685705}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:06:30,945] Trial 830 finished with value: 0.03641185168853215 and parameters: {'alpha': 7706921.408612097, 'l1_ratio': 5.066229247549752e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:06:31,294] Trial 831 finished with value: -0.015530983180227128 and parameters: {'alpha': 6036637527.819978, 'l1_ratio': 0.027319795092527105}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:06:33,313] Trial 825 finished with value: -0.18133353464166835 and parameters: {'alpha': 2.2887212724982224, 'l1_ratio': 0.01583190644912281}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:06:38,364] Trial 827 finished with value: 0.3243572030090798 and parameters: {'alpha': 1.981850975710211, 'l1_ratio': 0.2197301003208552}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:06:41,666] Trial 809 finished with value: -0.5848357738351018 and parameters: {'alpha': 2.4241892016136273, 'l1_ratio': 5.067578182848192e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:06:42,664] Trial 835 finished with value: -1.457469089664567 and parameters: {'alpha': 1.1477238687990773e-08, 'l1_ratio': 6.982383747745429e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.774e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.743e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:06:53,522] Trial 816 finished with value: -1.1966342181954486 and parameters: {'alpha': 0.6892579717173442, 'l1_ratio': 2.5463314379128402e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:06:55,880] Trial 837 finished with value: -1.3214230885094205 and parameters: {'alpha': 3.089731526123255e-06, 'l1_ratio': 0.00039704097427181007}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.002e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.782e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:09,123] Trial 821 finished with value: -0.6984280379751314 and parameters: {'alpha': 1.85733512941762, 'l1_ratio': 9.342653970193326e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.373e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:11,355] Trial 829 finished with value: -0.6346717182026453 and parameters: {'alpha': 0.17640220769411313, 'l1_ratio': 0.179756768577377}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:12,997] Trial 840 finished with value: -1.439171408964389 and parameters: {'alpha': 5.6001648859713e-07, 'l1_ratio': 2.3869229082559966e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:15,547] Trial 841 finished with value: 0.35678917580913855 and parameters: {'alpha': 13.332474926516085, 'l1_ratio': 0.12438847247838902}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:16,487] Trial 842 finished with value: -1.4991379056916205 and parameters: {'alpha': 2.1978667077864163e-07, 'l1_ratio': 0.3514624752237263}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.323e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.986e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.688e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:22,698] Trial 836 finished with value: -0.6836244252853094 and parameters: {'alpha': 0.2022939900178775, 'l1_ratio': 0.13608700788893838}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.301e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.613e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.758e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:39,531] Trial 826 finished with value: -0.07609937693499629 and parameters: {'alpha': 11.26109377484012, 'l1_ratio': 2.2025364144312898e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:39,936] Trial 845 finished with value: -0.015530983180227128 and parameters: {'alpha': 341.294181318182, 'l1_ratio': 0.9985304898334519}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.206e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:44,984] Trial 833 finished with value: -2.1118504542504013 and parameters: {'alpha': 0.15160055652211216, 'l1_ratio': 0.001688735068496046}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:45,183] Trial 847 finished with value: -0.012623737004465877 and parameters: {'alpha': 68661067.59484388, 'l1_ratio': 2.169564411206414e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.628e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:46,049] Trial 848 finished with value: 0.3200521974896526 and parameters: {'alpha': 28.686124198414454, 'l1_ratio': 0.30088631208101363}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:46,351] Trial 846 finished with value: 0.357452300328232 and parameters: {'alpha': 28.492402001105177, 'l1_ratio': 0.045374141957780785}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:47,164] Trial 832 finished with value: -0.025822392380145942 and parameters: {'alpha': 13.696956520717478, 'l1_ratio': 1.6840076008675843e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:48,099] Trial 850 finished with value: 0.33889852058266096 and parameters: {'alpha': 33133.362727881206, 'l1_ratio': 1.710052581469363e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:50,246] Trial 852 finished with value: 0.3257583039751088 and parameters: {'alpha': 5.396821355271803, 'l1_ratio': 0.6822043816012693}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:51,289] Trial 853 finished with value: -1.4592987534382902 and parameters: {'alpha': 1.0207858254593301e-10, 'l1_ratio': 0.42338821069066307}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:51,564] Trial 854 finished with value: -0.015530983180227128 and parameters: {'alpha': 3555.1717197746325, 'l1_ratio': 0.2698423342628492}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.287e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:52,025] Trial 855 finished with value: 0.028256184770042547 and parameters: {'alpha': 7521987.023319811, 'l1_ratio': 2.2364452375749825e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:52,374] Trial 856 finished with value: -0.010470835859536676 and parameters: {'alpha': 2477682.4347806955, 'l1_ratio': 9.425477043326669e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:53,589] Trial 857 finished with value: -1.453866656509673 and parameters: {'alpha': 3.509021479436804e-08, 'l1_ratio': 0.007203130429878445}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:55,336] Trial 858 finished with value: -1.439189068184881 and parameters: {'alpha': 4.8352381180158e-07, 'l1_ratio': 0.6973032321352369}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.113e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:07:58,698] Trial 839 finished with value: -0.6103085797124708 and parameters: {'alpha': 0.2520949113985756, 'l1_ratio': 0.12393312941695332}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:07:58,802] Trial 834 finished with value: -0.14281851492848918 and parameters: {'alpha': 8.807156498178305, 'l1_ratio': 2.715547369858248e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:08:10,046] Trial 859 finished with value: 0.30811960449392767 and parameters: {'alpha': 0.8184432874847455, 'l1_ratio': 0.44278418232369127}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.077e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.786e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.944e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:08:15,961] Trial 838 finished with value: -0.029052928898087454 and parameters: {'alpha': 13.520000702581543, 'l1_ratio': 9.37856544315477e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:08:16,484] Trial 863 finished with value: -1.4589790264347757 and parameters: {'alpha': 1.2545079333304071e-09, 'l1_ratio': 1.8474082477868994e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:08:17,846] Trial 861 finished with value: 0.3024378091839134 and parameters: {'alpha': 0.8719278515878747, 'l1_ratio': 0.3927927259673953}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:08:18,169] Trial 865 finished with value: 0.3197115312758058 and parameters: {'alpha': 155.354293130182, 'l1_ratio': 0.07082054756231379}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.305e-03, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:08:30,157] Trial 862 finished with value: 0.29885748864628986 and parameters: {'alpha': 4.286729652514997, 'l1_ratio': 0.07395514246377409}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.731e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:08:34,383] Trial 843 finished with value: -0.07396803276656716 and parameters: {'alpha': 11.34761481252015, 'l1_ratio': 2.1874756118566544e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:08:36,229] Trial 868 finished with value: 0.33693041411432695 and parameters: {'alpha': 3.1138473480491604, 'l1_ratio': 0.9954227139658487}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.367e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.322e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:08:37,766] Trial 844 finished with value: -0.10605233152828586 and parameters: {'alpha': 10.04526498546894, 'l1_ratio': 2.0967515024596126e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:08:38,459] Trial 870 finished with value: 0.32048530560363797 and parameters: {'alpha': 51.43049575922607, 'l1_ratio': 0.2500975005808855}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:08:38,685] Trial 867 finished with value: 0.3576425931721961 and parameters: {'alpha': 3.2704426462858214, 'l1_ratio': 0.2534937539093455}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:08:38,971] Trial 872 finished with value: -0.015530983180227128 and parameters: {'alpha': 173837.2119316316, 'l1_ratio': 0.6349814446102204}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.005e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:08:45,628] Trial 849 finished with value: -2.8001588455197486 and parameters: {'alpha': 3.4200917150568034e-05, 'l1_ratio': 0.6549898722282688}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.869e-01, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:08:53,188] Trial 869 finished with value: 0.0690710077374731 and parameters: {'alpha': 0.3546778698800376, 'l1_ratio': 0.2626052410452694}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:08:57,115] Trial 851 finished with value: -0.2581873817514521 and parameters: {'alpha': 6.034343716437765, 'l1_ratio': 1.1882815543818954e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.911e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:07,532] Trial 860 finished with value: -1.0948570254577572 and parameters: {'alpha': 0.7916452423929273, 'l1_ratio': 0.0008528771769314974}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.736e-02, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:15,957] Trial 873 finished with value: -0.7061407169586488 and parameters: {'alpha': 0.5040665074459167, 'l1_ratio': 0.037452184286232384}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:09:21,723] Trial 877 finished with value: -0.06630803809759316 and parameters: {'alpha': 1.4572669400969998, 'l1_ratio': 0.04061169002704003}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.807e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.400e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:29,712] Trial 866 finished with value: -0.42620339107639654 and parameters: {'alpha': 3.6130317626966315, 'l1_ratio': 0.00019209402952836242}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.785e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:32,609] Trial 864 finished with value: -0.3696070159863621 and parameters: {'alpha': 4.32660515864144, 'l1_ratio': 1.0870677184125376e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:09:33,836] Trial 881 finished with value: 0.3230322034270965 and parameters: {'alpha': 36.22476246676936, 'l1_ratio': 0.12991316637234868}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:35,336] Trial 874 finished with value: -0.8023305337513642 and parameters: {'alpha': 0.3531979085378931, 'l1_ratio': 0.04797854106398191}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.218e-02, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:38,604] Trial 882 finished with value: -1.4161956868768453 and parameters: {'alpha': 1.92299665237689e-06, 'l1_ratio': 0.42114002928909894}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:09:41,904] Trial 880 finished with value: 0.2580405385825567 and parameters: {'alpha': 34.554004276797684, 'l1_ratio': 0.003473433610492734}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:50,044] Trial 875 finished with value: -0.8053072330434713 and parameters: {'alpha': 1.163065980345749, 'l1_ratio': 0.0033834114944429248}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.755e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:54,597] Trial 871 finished with value: -1.4997825946640038 and parameters: {'alpha': 0.4153865344800291, 'l1_ratio': 2.182634776733677e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.227e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:09:55,134] Trial 876 finished with value: -2.932795712631943 and parameters: {'alpha': 0.0024827220442764446, 'l1_ratio': 0.035834832057958274}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:09:55,609] Trial 879 finished with value: 0.3425103224363916 and parameters: {'alpha': 795.4058989213901, 'l1_ratio': 7.642331399586532e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:09:59,559] Trial 889 finished with value: -1.313708159223527 and parameters: {'alpha': 4.205304973270183e-06, 'l1_ratio': 0.010345822410463263}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.017e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:10:03,228] Trial 883 finished with value: -1.6848623873609776 and parameters: {'alpha': 1.1361134145680118e-05, 'l1_ratio': 0.4325356366245741}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:10:03,715] Trial 891 finished with value: 0.3139912444126636 and parameters: {'alpha': 160.1628847003766, 'l1_ratio': 0.19449503992704828}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:10:07,076] Trial 888 finished with value: -1.5595916041806364 and parameters: {'alpha': 0.00011051910070967018, 'l1_ratio': 7.849728984918683e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.939e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:10:07,928] Trial 878 finished with value: -2.4675413750695645 and parameters: {'alpha': 0.035623946661183827, 'l1_ratio': 0.11677507034289702}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.635e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.457e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.893e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.114e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.800e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:10:29,127] Trial 884 finished with value: -1.9354625475862086 and parameters: {'alpha': 0.04598558312840777, 'l1_ratio': 0.16971645627065576}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.317e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:10:29,831] Trial 892 finished with value: 0.26357969012149857 and parameters: {'alpha': 2.3253420633376263, 'l1_ratio': 0.09986710029389419}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:10:30,186] Trial 896 finished with value: -0.015530983180227128 and parameters: {'alpha': 522691224.9801939, 'l1_ratio': 0.6248763893834064}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:10:30,343] Trial 897 finished with value: -0.015530983180227128 and parameters: {'alpha': 539380.3310489428, 'l1_ratio': 0.3579988506093938}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:10:30,666] Trial 898 finished with value: 0.19987500346486253 and parameters: {'alpha': 96.862914248018, 'l1_ratio': 0.7072712351740573}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:10:33,673] Trial 895 finished with value: 0.3588469294680684 and parameters: {'alpha': 2.4532892667533925, 'l1_ratio': 0.593457111263738}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.917e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:10:39,101] Trial 885 finished with value: -2.097399063678455 and parameters: {'alpha': 0.036747091987707495, 'l1_ratio': 0.18670554030354652}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.353e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.704e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.685e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:10:55,442] Trial 890 finished with value: -1.438225604431407 and parameters: {'alpha': 0.05996134626027, 'l1_ratio': 0.1907202467821469}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.145e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:02,689] Trial 893 finished with value: -3.3140551025640943 and parameters: {'alpha': 0.01675849868258017, 'l1_ratio': 0.10234756888935605}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.948e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.284e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:12,742] Trial 887 finished with value: -2.609449108165568 and parameters: {'alpha': 0.05937975925927322, 'l1_ratio': 7.169916405631343e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.826e-03, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:14,870] Trial 903 finished with value: 0.3333001270437866 and parameters: {'alpha': 12773.068006792275, 'l1_ratio': 4.529666971922891e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:15,231] Trial 905 finished with value: 0.3211013273526692 and parameters: {'alpha': 16.941792789065804, 'l1_ratio': 0.9975672322170335}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.127e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:19,417] Trial 886 finished with value: -1.7081721553718534 and parameters: {'alpha': 0.00044141955431560906, 'l1_ratio': 7.15491814583557e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:25,304] Trial 894 finished with value: -0.7077141372406534 and parameters: {'alpha': 1.8182696857517482, 'l1_ratio': 5.292338302825157e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:26,315] Trial 908 finished with value: -1.4559522865319048 and parameters: {'alpha': 2.222564889367081e-08, 'l1_ratio': 0.3302370770144042}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.414e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.442e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.308e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:35,368] Trial 899 finished with value: -0.7177900981327858 and parameters: {'alpha': 1.4770216414559416, 'l1_ratio': 0.0024578346997746183}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:40,958] Trial 909 finished with value: 0.20112735009320545 and parameters: {'alpha': 6.936497847417951, 'l1_ratio': 0.020397973343966817}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:41,250] Trial 911 finished with value: -0.015530983180227128 and parameters: {'alpha': 2244651.6948332656, 'l1_ratio': 0.48863819500777733}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:42,696] Trial 906 finished with value: -0.16221399256145777 and parameters: {'alpha': 6.190699535787962, 'l1_ratio': 0.002030972113441015}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:43,984] Trial 913 finished with value: 0.31921321323558366 and parameters: {'alpha': 18.85445303745472, 'l1_ratio': 0.3041653094038276}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:44,755] Trial 912 finished with value: -1.3324918345345875 and parameters: {'alpha': 1.9351693755837545e-06, 'l1_ratio': 0.0005987820823773875}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:47,647] Trial 914 finished with value: -1.3496886390902718 and parameters: {'alpha': 1.2157948318594162e-06, 'l1_ratio': 0.500249480557991}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:48,957] Trial 916 finished with value: 0.3421913130962326 and parameters: {'alpha': 43.333227489092835, 'l1_ratio': 0.06361694532405314}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:49,291] Trial 917 finished with value: -0.015530983180227128 and parameters: {'alpha': 17685960.82486378, 'l1_ratio': 0.66734199137951}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:49,465] Trial 918 finished with value: -0.015530983180227128 and parameters: {'alpha': 321.39852207695304, 'l1_ratio': 0.9972713389541826}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:49,820] Trial 902 finished with value: 0.013776508996084624 and parameters: {'alpha': 15.838609879990582, 'l1_ratio': 8.74363908032265e-05}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:50,246] Trial 919 finished with value: -1.514411204945636 and parameters: {'alpha': 1.414644179391733e-07, 'l1_ratio': 0.2603735118502571}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:50,503] Trial 921 finished with value: -0.015530983180227128 and parameters: {'alpha': 1346470459.4252841, 'l1_ratio': 0.0008958161108374177}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.315e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:51,061] Trial 922 finished with value: -1.458039511533223 and parameters: {'alpha': 7.587875160403526e-09, 'l1_ratio': 3.4000951339951274e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:51,248] Trial 901 finished with value: -0.20545725197618817 and parameters: {'alpha': 7.15667860252353, 'l1_ratio': 5.555996331505374e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:52,263] Trial 924 finished with value: -1.4592633928431915 and parameters: {'alpha': 3.836227091981758e-10, 'l1_ratio': 0.4443048338009485}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:11:52,652] Trial 925 finished with value: -0.015530983180227128 and parameters: {'alpha': 177849188.06661344, 'l1_ratio': 0.006334332533410882}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.759e-03, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.776e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.065e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:11:56,327] Trial 900 finished with value: 0.014955257149350643 and parameters: {'alpha': 16.220577456619818, 'l1_ratio': 3.72598389295863e-06}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.327e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.581e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:12:06,240] Trial 926 finished with value: 0.3259268898807265 and parameters: {'alpha': 2.5199247316574467, 'l1_ratio': 0.17666810656580273}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:12:06,536] Trial 928 finished with value: -0.015530983180227128 and parameters: {'alpha': 363163405.4078323, 'l1_ratio': 0.00020978377894844986}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:12:06,889] Trial 929 finished with value: -0.015530983180227128 and parameters: {'alpha': 27623690.511828117, 'l1_ratio': 0.010277566291217772}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:12:10,675] Trial 930 finished with value: -1.2383805367445837 and parameters: {'alpha': 1.3892344531613486e-05, 'l1_ratio': 0.026555593871231114}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:12:11,066] Trial 931 finished with value: 0.03417599580319641 and parameters: {'alpha': 242358.82068246696, 'l1_ratio': 0.0005550911961820852}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.747e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e-03, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.796e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.900e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:12:24,392] Trial 907 finished with value: -0.2032243514585487 and parameters: {'alpha': 6.94576792798441, 'l1_ratio': 0.0002645107837074656}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.219e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:12:30,552] Trial 904 finished with value: 0.03411482001979812 and parameters: {'alpha': 17.65743038193129, 'l1_ratio': 7.657198154233547e-09}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.706e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:12:39,725] Trial 915 finished with value: -3.990254572311704 and parameters: {'alpha': 0.00428881818088715, 'l1_ratio': 0.5430193887315237}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.057e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:12:44,392] Trial 910 finished with value: -2.5465462851803737 and parameters: {'alpha': 3.3893846336451614e-05, 'l1_ratio': 0.4880531745245692}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:12:44,549] Trial 936 finished with value: -0.015530983180227128 and parameters: {'alpha': 114604.76117192699, 'l1_ratio': 0.2747719326587733}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.345e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:12:50,890] Trial 934 finished with value: 0.30051183873630744 and parameters: {'alpha': 1.0230998132236129, 'l1_ratio': 0.32813333222025226}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:12:54,170] Trial 935 finished with value: 0.29803969998525864 and parameters: {'alpha': 1.104069247678736, 'l1_ratio': 0.29680709166010744}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:12:56,341] Trial 937 finished with value: 0.0763937427600712 and parameters: {'alpha': 0.886659522848997, 'l1_ratio': 0.10312590283287439}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.967e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.144e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.816e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:13:10,418] Trial 920 finished with value: -0.38358936064938326 and parameters: {'alpha': 4.157601180202006, 'l1_ratio': 6.661722803000758e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:13:11,002] Trial 941 finished with value: 0.3210191627468116 and parameters: {'alpha': 99.91536991425622, 'l1_ratio': 0.16699771370481886}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.678e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:13:11,484] Trial 938 finished with value: 0.28466936101103507 and parameters: {'alpha': 2.5773646334230436, 'l1_ratio': 0.10784580364581921}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:13:13,598] Trial 927 finished with value: -0.5446090757566071 and parameters: {'alpha': 2.695514012795409, 'l1_ratio': 8.803881779128782e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:13:13,837] Trial 942 finished with value: 0.3554633197527738 and parameters: {'alpha': 2.5240277167671237, 'l1_ratio': 0.7058101701759909}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:13:14,438] Trial 923 finished with value: -0.3743815071697198 and parameters: {'alpha': 4.268255352767977, 'l1_ratio': 8.067880219098736e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.441e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.035e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:13:24,088] Trial 933 finished with value: -2.8538256938154216 and parameters: {'alpha': 0.0005230617217665106, 'l1_ratio': 0.3093179102529711}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:13:30,550] Trial 932 finished with value: -1.0667065930268642 and parameters: {'alpha': 0.869863000378479, 'l1_ratio': 4.327976644484319e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.634e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.402e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.260e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.847e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.682e-01, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.213e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.373e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:13:57,922] Trial 947 finished with value: -0.6821247133226127 and parameters: {'alpha': 0.38183425555254885, 'l1_ratio': 0.06136542151733527}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:13:58,526] Trial 949 finished with value: 0.31571656595838477 and parameters: {'alpha': 42.06822839267243, 'l1_ratio': 0.6967501388933897}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:13:58,694] Trial 950 finished with value: -0.015530983180227128 and parameters: {'alpha': 811711.5047370502, 'l1_ratio': 0.0005444877168170125}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.980e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:01,848] Trial 939 finished with value: 0.27362540456490864 and parameters: {'alpha': 91.24549926237168, 'l1_ratio': 1.5035208983915485e-08}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.415e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.024e-01, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.870e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:10,473] Trial 940 finished with value: 0.26917790828729626 and parameters: {'alpha': 86.08326560687254, 'l1_ratio': 1.4302878071540433e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:15,316] Trial 952 finished with value: 0.021630583519937335 and parameters: {'alpha': 0.18851021314251715, 'l1_ratio': 0.45040797219090745}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:15,466] Trial 954 finished with value: -0.015530983180227128 and parameters: {'alpha': 1910.7471466061254, 'l1_ratio': 0.17669661598106534}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.084e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:19,739] Trial 944 finished with value: -2.039699070680622 and parameters: {'alpha': 0.17364598902244086, 'l1_ratio': 2.9019613389865636e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:20,235] Trial 956 finished with value: 0.31177416919504913 and parameters: {'alpha': 7.205172269452239, 'l1_ratio': 0.9851895552348832}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:21,178] Trial 957 finished with value: 0.3237042318332511 and parameters: {'alpha': 323.62746766179004, 'l1_ratio': 0.01452222976690326}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:21,296] Trial 953 finished with value: 0.3374179278697955 and parameters: {'alpha': 400.92902848913786, 'l1_ratio': 0.0001458102792096583}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.242e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:21,404] Trial 943 finished with value: -1.7742679945268736 and parameters: {'alpha': 0.27419325511335046, 'l1_ratio': 1.848375698675255e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:21,964] Trial 959 finished with value: -1.4555219065990597 and parameters: {'alpha': 2.4132483507624717e-08, 'l1_ratio': 1.1864394408328504e-09}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:23,792] Trial 960 finished with value: 0.3530702044948691 and parameters: {'alpha': 8.612282816622896, 'l1_ratio': 0.22542525934388963}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:25,721] Trial 955 finished with value: 0.335175685191468 and parameters: {'alpha': 5146.739594605126, 'l1_ratio': 5.338155871755616e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:26,365] Trial 962 finished with value: 0.34868643462580906 and parameters: {'alpha': 30.40088695015576, 'l1_ratio': 0.07480186568863392}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.261e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:27,714] Trial 946 finished with value: -2.1500021431343246 and parameters: {'alpha': 0.14124278984360003, 'l1_ratio': 1.5996979405824e-07}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:30,352] Trial 951 finished with value: 0.3387389731097537 and parameters: {'alpha': 520.0002628150773, 'l1_ratio': 2.251610482458419e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.693e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:32,155] Trial 945 finished with value: -2.0909830280289685 and parameters: {'alpha': 0.1578437225196511, 'l1_ratio': 5.659306430247883e-10}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.705e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:36,425] Trial 948 finished with value: 0.3435721391531418 and parameters: {'alpha': 1167.2978432451007, 'l1_ratio': 1.8173480983465772e-08}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:36,488] Trial 964 finished with value: 0.3529322955331178 and parameters: {'alpha': 1.5664909201120416, 'l1_ratio': 0.44771252264653183}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:37,231] Trial 966 finished with value: 0.3520436743431737 and parameters: {'alpha': 1.6010218308767032, 'l1_ratio': 0.4303247047946696}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:37,471] Trial 970 finished with value: -0.015530983180227128 and parameters: {'alpha': 2416215984.616257, 'l1_ratio': 0.7140032869330133}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:38,777] Trial 965 finished with value: 0.3550363134440149 and parameters: {'alpha': 1.5886960749017298, 'l1_ratio': 0.4647600608333556}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:39,142] Trial 972 finished with value: -0.015530983180227128 and parameters: {'alpha': 1658297.2191151031, 'l1_ratio': 0.005006433857300018}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:40,891] Trial 967 finished with value: 0.3526969765198833 and parameters: {'alpha': 1.5685523220987212, 'l1_ratio': 0.44500867716367526}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:41,850] Trial 969 finished with value: 0.35808171621483814 and parameters: {'alpha': 7.121587230874176, 'l1_ratio': 0.1429387694879626}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:42,880] Trial 975 finished with value: -1.4590356028617877 and parameters: {'alpha': 9.335465341699537e-10, 'l1_ratio': 0.21552014870311748}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.141e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:44,684] Trial 968 finished with value: 0.3500423650319993 and parameters: {'alpha': 1.548755234386886, 'l1_ratio': 0.431503808328853}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:44,707] Trial 961 finished with value: 0.28559869296371093 and parameters: {'alpha': 9.730373255276085, 'l1_ratio': 0.02620635416347348}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:45,015] Trial 973 finished with value: 0.3585006731722821 and parameters: {'alpha': 7.365809336703556, 'l1_ratio': 0.12612064983424554}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.963e+00, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:14:47,095] Trial 979 finished with value: 0.3494533119144711 and parameters: {'alpha': 21.938009000218567, 'l1_ratio': 0.09980559095055315}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:51,195] Trial 980 finished with value: 0.2513547747173234 and parameters: {'alpha': 47.00484631071585, 'l1_ratio': 0.0014468834599646822}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:55,068] Trial 976 finished with value: 0.06115402568167098 and parameters: {'alpha': 15.038292966542937, 'l1_ratio': 0.0012827840258336724}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:56,505] Trial 971 finished with value: -1.646240169050901 and parameters: {'alpha': 0.0001203691765867186, 'l1_ratio': 0.0012181062143809473}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:59,039] Trial 981 finished with value: 0.3564058919007555 and parameters: {'alpha': 16.308792190157888, 'l1_ratio': 0.05153213166173312}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:14:59,470] Trial 984 finished with value: -0.015530983180227128 and parameters: {'alpha': 111691991.84518386, 'l1_ratio': 0.13823443222756382}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.976e-03, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:15:05,777] Trial 974 finished with value: 0.259628348511263 and parameters: {'alpha': 8.957082640252475, 'l1_ratio': 0.02295279276313669}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:06,036] Trial 986 finished with value: -0.015530983180227128 and parameters: {'alpha': 4049436207.5462594, 'l1_ratio': 0.07360568216358804}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.140e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+00, tolerance: 3.922e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:15:12,428] Trial 978 finished with value: -0.5140333414145846 and parameters: {'alpha': 0.551685898647056, 'l1_ratio': 0.05332522671638178}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:12,907] Trial 982 finished with value: 0.2949778975936353 and parameters: {'alpha': 4.263498114881009, 'l1_ratio': 0.07160400460768014}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:13,465] Trial 988 finished with value: -1.4484870664168326 and parameters: {'alpha': 7.6263832109791e-08, 'l1_ratio': 0.11364343060003983}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:13,578] Trial 983 finished with value: 0.29299245321150563 and parameters: {'alpha': 5.79074313848074, 'l1_ratio': 0.0506052039574284}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:13,691] Trial 989 finished with value: 0.3195656030625804 and parameters: {'alpha': 45.559540446961726, 'l1_ratio': 0.12483975628354427}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:14,031] Trial 990 finished with value: 0.3135597113714967 and parameters: {'alpha': 31.801441777542422, 'l1_ratio': 0.20007212488231724}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:14,312] Trial 977 finished with value: -0.6359631986417477 and parameters: {'alpha': 0.5125527025471839, 'l1_ratio': 0.046032653818474725}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:14,609] Trial 992 finished with value: -1.4592935373441682 and parameters: {'alpha': 1.3296596036839101e-10, 'l1_ratio': 0.21899961809643967}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:21,985] Trial 985 finished with value: 0.28751574834271715 and parameters: {'alpha': 4.771510909473005, 'l1_ratio': 0.058481326973674724}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:25,080] Trial 996 finished with value: 0.35825148635079634 and parameters: {'alpha': 3.6652948682793483, 'l1_ratio': 0.27853611444911974}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e-01, tolerance: 4.506e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:15:27,802] Trial 997 finished with value: -1.341344373073883 and parameters: {'alpha': 1.5994011306468235e-06, 'l1_ratio': 6.275279599171207e-10}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:29,805] Trial 998 finished with value: -1.4286984150248523 and parameters: {'alpha': 6.091419506389226e-07, 'l1_ratio': 0.016394898825411945}. Best is trial 343 with value: 0.3603214034046899.\n",
      "[I 2023-06-16 17:15:29,983] Trial 999 finished with value: -0.015530983180227128 and parameters: {'alpha': 16717.859000582837, 'l1_ratio': 0.15627463310140166}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.776e-02, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.649e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:15:35,632] Trial 958 finished with value: -0.10344999000141131 and parameters: {'alpha': 10.175630083944336, 'l1_ratio': 5.252735430986636e-07}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.750e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:15:38,496] Trial 963 finished with value: 0.13417357536024588 and parameters: {'alpha': 29.15153343175557, 'l1_ratio': 9.16083517722135e-10}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.533e+00, tolerance: 4.506e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.659e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.567e-02, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:15:54,956] Trial 995 finished with value: 0.3140169956962356 and parameters: {'alpha': 185.61207045071404, 'l1_ratio': 5.47010029239751e-05}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.766e-02, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:15:58,913] Trial 991 finished with value: -3.1194842804488303 and parameters: {'alpha': 0.0013251754521426938, 'l1_ratio': 0.2058460233888853}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e-01, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:16:00,061] Trial 987 finished with value: -3.348314060665161 and parameters: {'alpha': 0.002875866183079527, 'l1_ratio': 0.10681176975759367}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e+00, tolerance: 3.922e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.784e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:16:13,507] Trial 994 finished with value: -0.3965436766797861 and parameters: {'alpha': 4.007905750972183, 'l1_ratio': 1.0053249344737589e-10}. Best is trial 343 with value: 0.3603214034046899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+00, tolerance: 4.591e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:16:16,172] Trial 993 finished with value: 0.3133844969375929 and parameters: {'alpha': 187.92101331645807, 'l1_ratio': 1.6098385439353738e-06}. Best is trial 343 with value: 0.3603214034046899.\n",
      "0.3603214034046899 {'alpha': 118.43682332925782, 'l1_ratio': 0.01089724282209381}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1e10, log=True)\n",
    "\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 1e-10, 1, log=True)\n",
    "\n",
    "\n",
    "    clf = ElasticNet(max_iter=100000, alpha=alpha, l1_ratio=l1_ratio, random_state=0)\n",
    "\n",
    "    # n_ft = trial.suggest_int('n_ft', 1, 10, log=True)\n",
    "    # clf = RFE(Ridge(max_iter=100000, alpha=alpha, solver=solver), n_features_to_select=n_ft)\n",
    "\n",
    "    estimator = utils.Utils(full_train)\n",
    "    return estimator.cross_value_score(clf)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "trial = study.best_trial\n",
    "print(trial.value, trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T21:16:16.289225766Z",
     "start_time": "2023-06-16T20:23:48.061368961Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      "\tR2\t\t\t\t:\t 0.5489053324031481 \n",
      "\tCV train\t\t:\t 0.3319601450626149 \n",
      "\tCustom CV train\t:\t 0.3603214034046899 \n",
      "\tQ2\t\t\t\t:\t -0.02535026125111517\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          -1.4588566440063353,
          -1.4186238795506367,
          -1.4544204143926058,
          0.34216137737701824,
          -1.4592894203414815,
          -1.2851724293152476,
          -1.0181034118687586,
          -1.2659143003247595,
          0.023625995974864034,
          -0.015530983180227128,
          -0.015500695097565983,
          0.3572658715830546,
          0.18025439973100474,
          -1.4608882846383286,
          -1.8180348210106962,
          -0.9927486221172465,
          -1.618533230604383,
          0.32058660350081286,
          0.10710902288645618,
          0.35549691245468323,
          -3.292956266082208,
          -3.0454415634994234,
          -3.318535151838067,
          -2.438316439548156,
          -0.015530983180227128,
          -1.3989318076014794,
          -3.3868368865403897,
          -4.113433421282801,
          0.3340060028910736,
          0.33983561911351234,
          0.33491988500858355,
          0.26951701759981045,
          -0.015530983180227128,
          0.22035503036760481,
          0.2978541917178748,
          0.35866430895057694,
          0.31373835674571315,
          0.12932749082335837,
          0.2425865490743435,
          -0.015530983180227128,
          -0.0014153394919703688,
          0.05550761445672888,
          0.31749073414887985,
          0.3175486877282333,
          -1.1737488389175899,
          -1.3870978362141995,
          -0.5628248380931161,
          0.058950514407528666,
          0.33701257267914336,
          -0.1089600358672342,
          0.3411702716182422,
          0.06594382135104937,
          0.3370592974448212,
          -0.015530983180227128,
          0.34086502615278663,
          0.3399125025660407,
          0.3166631619834335,
          0.3426261530747236,
          0.3430656613920456,
          0.3428946303035355,
          -0.28906591989821184,
          0.3398038819718452,
          -0.28947352898421286,
          0.24269347388740617,
          0.22539670765738998,
          -0.3246935341885149,
          -0.32852952940247465,
          0.2351915885891488,
          0.2566912048915019,
          0.34328843016891925,
          0.3306977645905042,
          0.3222144998955559,
          0.33545896210178877,
          0.3227062378834569,
          0.33553891230776783,
          -0.015530983180227128,
          0.3395437399406364,
          0.3421545316798636,
          0.3356873471001011,
          0.32008851483832546,
          0.311591958383739,
          -0.015530983180227128,
          0.3364179500414026,
          0.31990929657122014,
          -2.552278580876953,
          0.34352993099701296,
          0.34363297658866526,
          0.332995077061896,
          0.3432552668825773,
          0.3433832338164791,
          0.3431160500204338,
          0.08458993578110534,
          0.10621048729256448,
          0.11362359788401366,
          0.30289869328226565,
          0.3330673912108459,
          0.34356435978747873,
          0.3333014167749549,
          0.14007708989977863,
          0.34362671451946114,
          0.08795102420329966,
          0.10764145966097678,
          0.12525507384321607,
          0.13810773271791368,
          0.3436294319533494,
          -0.015530983180227128,
          -0.4976968424495506,
          -0.4938522708286848,
          0.3432729458915366,
          0.33538735142924614,
          0.34396407806549234,
          0.0676674772685731,
          0.28957983884197064,
          0.35559305952517556,
          0.28536753462302833,
          0.35449940302888366,
          0.353275923454508,
          0.3556806905288994,
          0.3584358498271417,
          0.3556802369386711,
          0.35823191211381694,
          0.3552871489429807,
          0.3475912627734778,
          0.3589629641662819,
          0.34775853994064815,
          0.35767131413199565,
          0.3577516548496169,
          0.3346303442322133,
          0.3590101021316477,
          0.19165048934513376,
          -0.4425521405306269,
          -0.2143361149375758,
          -0.5632198581246426,
          -0.022476813628028114,
          -0.14034568065295225,
          -0.6248525888870063,
          0.1651233144846966,
          0.17870736875553297,
          0.32086628728045785,
          0.32565535777254434,
          0.17142630796836122,
          0.3154372650158423,
          0.3574362412163299,
          0.35838071582056313,
          0.35542519269214107,
          0.3579673609234114,
          0.35625965438162227,
          0.3554621066345563,
          0.3562383860556151,
          0.35529740603277793,
          0.35857044104617514,
          0.3560802708808445,
          0.35849394056187145,
          0.3487610648407854,
          0.355639104055644,
          0.3569469677120692,
          0.34215713652774393,
          0.3437652860156858,
          0.34609535690051557,
          0.3243768327923027,
          0.30877608897240466,
          0.3089930429691231,
          0.26704037028675254,
          0.34644828885223344,
          0.3510282485296207,
          0.2154714599802278,
          0.35905311002504064,
          0.34012341942322943,
          0.3485484939160866,
          0.34947941784485514,
          0.10370870280683926,
          0.11582147497170252,
          -1.6444983307045624,
          0.31390624425061125,
          -1.3806280496304346,
          0.32690155719100483,
          -0.4927017233056891,
          0.3556432364883561,
          0.23748912871306463,
          0.323256356080263,
          0.3153598607041081,
          -0.22176279702005544,
          -0.23945852036809487,
          -0.049614966641591596,
          -0.2950643614828246,
          -0.10719945576620149,
          -0.07994009213256308,
          0.32642101451467614,
          0.18103193214229688,
          0.3583395099603423,
          0.3115455170461861,
          0.3588350989716463,
          0.35557156087560937,
          0.32067234758972546,
          0.35262644138693827,
          0.31996610285925775,
          0.28392867020650037,
          0.31153935292078166,
          0.35884432405815353,
          0.3522741400435548,
          0.35742331338950745,
          0.3584192220349806,
          0.35640425501286704,
          0.35879220830896286,
          0.3579958754257995,
          0.35515744247846576,
          0.35787433921658846,
          0.35264448755504135,
          0.35285039225925646,
          0.3357513389040881,
          0.33345496567479244,
          0.3559611854839141,
          0.3493149002385352,
          -0.08923461982228624,
          0.35556855893360867,
          -0.15820177871676164,
          0.3573679359980803,
          0.10908787265381932,
          0.35892927938510694,
          -0.11814645137514253,
          0.10875264898829029,
          0.3518024711046048,
          0.33473910846148713,
          0.3442385549313532,
          0.32631069680731545,
          0.0771552251210323,
          0.1583577688628215,
          -0.6459511846433815,
          0.3557450871356086,
          0.35139176040671194,
          0.187407148917166,
          -0.010748006623309289,
          0.1454187846058805,
          0.14465612142220094,
          0.16667109977434158,
          0.326119867509815,
          0.35641826878216215,
          0.35775727013691144,
          0.3585731346168109,
          0.35891917928167605,
          0.3231006491235032,
          -0.11381228325339994,
          0.013636084687276543,
          0.3510712442615813,
          0.3556739375191189,
          0.3379185646005755,
          0.3443113633113733,
          0.13738822317302932,
          0.3217881445098996,
          0.3477152669173245,
          -0.579929781497432,
          -0.6312305535032702,
          -0.6665962646133711,
          0.3112915288088999,
          -0.799392569560221,
          -0.9884734330291947,
          -0.8633357900213132,
          0.33479264608706344,
          0.3301770313869203,
          -1.4581299187241386,
          0.32985425594588347,
          0.3266386973062517,
          0.15714248753659377,
          -0.7542689492597158,
          0.35506109021892235,
          -0.015530983180227128,
          0.350659289563602,
          -0.10532896547230493,
          -1.4474188455224184,
          -1.2186626142315062,
          -0.2509122726884796,
          0.35784343733491525,
          0.32374614266479945,
          0.3228668773910273,
          0.33360694402947116,
          -1.459282765511732,
          0.35681147381100004,
          0.319676377553934,
          -0.0333862488790185,
          -0.0012424596238384729,
          0.349531794611252,
          0.2616054601382115,
          0.3489002420208785,
          -3.3942958905710605,
          0.3207160472169541,
          0.3265463936586212,
          0.10146932695958837,
          -4.179199352777676,
          -0.015530983180227128,
          -1.347034682280125,
          -3.102323190893002,
          -2.6363264195465734,
          0.35535121816891374,
          -1.3195634165693984,
          0.3008718993883735,
          0.20463377817227782,
          0.3507808698874323,
          0.3441369158278777,
          -0.12192646391065864,
          -0.48336143625031686,
          0.3054755423653524,
          0.31703469125452416,
          -0.6816296103098017,
          -0.6984491784464092,
          -0.561662838986741,
          0.32129606789500914,
          -1.3314918935177145,
          -1.7725634270981712,
          -0.6123112186063538,
          0.3380399824366615,
          0.3424848875982817,
          -1.4527132885932348,
          0.3211436181019196,
          0.28874869026131533,
          0.102895844197045,
          0.3198534893675102,
          0.3559026409491577,
          0.3561372329700137,
          -1.335982214810917,
          0.3558390170110048,
          -0.22183003775507992,
          0.35248011327402623,
          0.3482835006833344,
          0.27502723504919774,
          0.35529346564166436,
          0.021089969737206078,
          0.35412333708478216,
          0.036562496108139074,
          -0.015530983180227128,
          -0.47663256403224047,
          0.174490656215424,
          -0.4315309250671305,
          -3.6600910998854816,
          0.346478698066261,
          0.35769741116789106,
          0.35894922190117373,
          0.32048269253517847,
          -2.6158720724761952,
          0.31623366886675214,
          0.3575559488449212,
          0.31580800231750034,
          -0.015530983180227128,
          0.2947544802095244,
          0.3603214034046899,
          0.21037786751230458,
          0.3516787210976737,
          0.31668871842392793,
          0.3492435831402289,
          0.31177336760749125,
          0.35602028215560605,
          0.24427447613474965,
          0.08917838968842924,
          0.31751538386488976,
          0.03379042906960539,
          0.29546816414174276,
          0.16689944992487393,
          -2.091249557798951,
          -2.064419654972361,
          0.1309520358236441,
          -1.8644662372140417,
          0.3574592978371764,
          -1.8630823820148064,
          0.32216096431444846,
          0.3339996382023081,
          -1.8607245061478899,
          0.3256123187233857,
          -0.27195260026519646,
          0.355923982836866,
          0.22831156756388551,
          -0.2430285964127928,
          0.34842702376776635,
          0.3452648844291753,
          0.3478606276201634,
          0.35843994774725363,
          -0.18724976247032424,
          0.35692783008651174,
          0.30554291419607416,
          -2.67070363670904,
          -0.40574744615689207,
          -0.2679718814609029,
          0.34136822970543096,
          0.3205494509913016,
          -0.49765888458377594,
          0.24827278085196447,
          -4.177634302903346,
          0.25114625909675425,
          -2.65891362123988,
          0.11502151895902864,
          0.3453186802497291,
          0.356046210075102,
          0.32654497568528595,
          -0.015530983180227128,
          -1.5315663508411754,
          0.3339170272411143,
          0.35534227110870276,
          -0.6313760931421741,
          0.21893668452624773,
          0.19644780755835234,
          -1.264487029697481,
          0.3202112787439207,
          -1.8351786016940215,
          -1.5134361550753421,
          -2.2720082803825026,
          -2.0074292483467904,
          -1.459106552959043,
          0.085528337801892,
          0.3496716917010649,
          0.2944678536482575,
          0.3467481302066269,
          -1.4586713810436456,
          -0.015530983180227128,
          -0.23117528226447157,
          0.3578128020253674,
          0.3401368502092517,
          0.29559171726388894,
          0.2794560009966162,
          -0.06005171663412815,
          -2.1781679562009257,
          0.32816605472294685,
          0.3480812739315084,
          -0.015530983180227128,
          0.21664656672368152,
          -0.015530983180227128,
          0.23774034844378575,
          0.3175799951302369,
          0.05329001899922936,
          -1.4592954096167965,
          0.01283582291706605,
          -0.34420804318204073,
          -0.24570510294741574,
          -0.015530983180227128,
          0.33728565297216,
          0.2795618206553193,
          -0.351661529658744,
          0.3474372284556131,
          0.3581160246105819,
          0.31757421665635166,
          0.33682649212269117,
          0.325344128336722,
          0.3546562344166067,
          0.3584273177075202,
          -0.384034081123584,
          -0.015530983180227128,
          0.14360904634536809,
          0.3584507771804764,
          0.35487412511246247,
          -0.0234943738564715,
          -0.018104848896938048,
          -0.015530983180227128,
          0.35772746694155305,
          -0.3485847147437076,
          -0.40670478607532834,
          -0.3941703510715586,
          0.31811912576974893,
          -0.015530983180227128,
          -1.0331094715647526,
          -1.5120171381314516,
          -3.4277403557600064,
          0.059222216092806756,
          -0.010311694371020419,
          0.18648868337852595,
          -1.2870022917608257,
          -0.8480015688133308,
          0.3553138776992857,
          -1.2496700077227336,
          -1.239631454137545,
          0.3065756156315676,
          0.09629062040162413,
          0.08912962969695115,
          0.01185570600516687,
          0.2971055111276842,
          0.2965333883497692,
          -0.015530983180227128,
          -0.10748666340397776,
          -1.4590037327890628,
          0.3197303136987384,
          0.23882900318257852,
          0.26991983437445616,
          0.3204304508764704,
          -0.015530983180227128,
          -2.1243657559825193,
          -0.5900363819602418,
          -0.12925480111034296,
          -0.13395604549890172,
          0.3201190574452502,
          -0.11508520687883768,
          0.3207485586361093,
          0.32827692779201506,
          0.15679517057561795,
          -0.015530983180227128,
          -3.247480444483889,
          -3.322101992799808,
          0.2771944678038373,
          -0.5225667432304725,
          0.32009252723610654,
          -0.7278587454009573,
          -0.6140669368969788,
          -0.758736101106032,
          0.19914503539835152,
          0.2411413216041596,
          0.23796316047355137,
          0.3401914314367314,
          -0.015530983180227128,
          0.3580215169988141,
          -2.0310534784649583,
          0.3582705974344014,
          -0.015530983180227128,
          -0.015530983180227128,
          0.3501283462911874,
          0.3576525739705391,
          0.35549412942962305,
          0.17119656952674733,
          0.27618997225675895,
          -1.4588577429004395,
          -0.015530983180227128,
          -0.015530983180227128,
          -1.8664980265537285,
          -1.5355455220283616,
          -1.3250420154970737,
          -1.4580939998116074,
          -1.2077031960076055,
          -2.485572829925278,
          -0.22415764325271706,
          0.318765495075478,
          -1.8030956635184299,
          0.3590092124495716,
          0.35765806097152913,
          -1.9915872797116079,
          0.2048837917693804,
          0.34680151319927427,
          0.31125157963637934,
          -2.0947192565071995,
          0.3264360480152067,
          0.317557444180661,
          0.059883505784525504,
          0.35800429176088616,
          0.3565337363533025,
          0.11578527872929427,
          0.31988040769645104,
          -0.015530983180227128,
          -0.1979089937043974,
          -1.2824366448911533,
          -1.3871808668777832,
          -0.8202745005649644,
          -0.9600358698474978,
          0.31912913786308417,
          0.3321389804692722,
          -1.4592856903403628,
          0.320054750405451,
          -0.8461107227636813,
          0.34515182008829265,
          -0.9563664546385848,
          -1.0408124695521126,
          0.26120913524871686,
          -0.8783777723335607,
          0.32417235114190385,
          0.3251466535172783,
          -0.19415503325323338,
          -0.9068639932466932,
          0.33611980987919354,
          -0.4047925106032945,
          0.35848760060982465,
          0.3003708725906461,
          0.2947905990108231,
          -4.144038109063413,
          0.3167671223679029,
          -1.459071482409423,
          -1.3533434915360392,
          -0.01417611650574598,
          0.3402071706583554,
          -1.2454379331087817,
          -1.2163888129798313,
          -2.124591846718434,
          -2.1486789761548835,
          0.2787110440676368,
          -0.015530983180227128,
          0.3199898967479248,
          0.31429758218081766,
          -2.1681133956602676,
          -0.2517336906262751,
          -2.657490656966469,
          -1.517555969517879,
          0.1508129192112416,
          0.1544524564112597,
          -2.422221071448753,
          -0.015530983180227128,
          -3.6309719371834768,
          0.3213172723681464,
          0.32038895876691525,
          -0.4800849020707178,
          -3.6493396321954834,
          -1.4547966029295487,
          -1.4577246596629323,
          0.32035780768809236,
          0.07519450813724142,
          -1.2838435986902925,
          0.3137903833350297,
          -1.3030852462962523,
          0.22722357831246798,
          0.2129694564947278,
          -1.2687998712805169,
          0.27078439757688855,
          0.25637591422105926,
          -0.015530983180227128,
          -0.015530983180227128,
          -1.4561817592040354,
          -0.1211662885794876,
          -0.12571209880544307,
          -0.07408028577053798,
          0.34812232571210816,
          0.3493742480997195,
          -0.08404046543704391,
          -0.015530983180227128,
          0.3561959617013009,
          -0.07437295570133844,
          0.2795870754956958,
          0.3553407582890843,
          0.3393680485949116,
          -0.015530983180227128,
          -4.206927979808516,
          0.3327574256949249,
          0.33872436419636354,
          -0.015530983180227128,
          -0.6466471365699425,
          -0.49011235414007776,
          -0.48030471306019,
          -0.6463054869554511,
          0.00985912368462379,
          -2.9049618809227606,
          -0.06069600438672277,
          0.313674552802458,
          0.33994448998307025,
          -0.07679431670931695,
          0.33335234357105353,
          0.27889474956363675,
          -2.2408427557720936,
          0.31686561532083074,
          -2.129403453120829,
          0.34387954460932685,
          0.09621218267102179,
          -1.4525047372969182,
          -0.10494403673150261,
          0.3124440850602468,
          -1.4588958029007904,
          0.3185798769335579,
          -0.8888432590930738,
          -0.9194754495981251,
          -0.3436034372555689,
          0.3547863225511882,
          -0.30885782251984506,
          -0.30801565239474293,
          -3.0223649644227444,
          -1.4988911901230664,
          -0.015530983180227128,
          -2.055582947896753,
          0.3370968261858521,
          0.3477798718891792,
          -3.0976078729492342,
          -0.3360056045206083,
          0.12075123409384174,
          -0.015530983180227128,
          0.31141071697362727,
          0.29377280851451687,
          -0.015530983180227128,
          -1.0880284048640538,
          0.34904683843411416,
          0.3205039812705726,
          -0.450847413713562,
          -1.4586619588503071,
          -1.4342824655550332,
          -1.154025538966952,
          -0.9809027963120157,
          -0.015530983180227128,
          -0.8707000961143022,
          -1.3200875894834236,
          0.28056061481194117,
          0.34545469494947995,
          -1.458998086567035,
          0.2883652493700352,
          -1.2546990794824073,
          -1.3836040947139567,
          -0.7777234079228538,
          0.31976067045407447,
          0.21730125561382774,
          -0.015530983180227128,
          0.2826380386830044,
          -1.3873323518596086,
          -1.4296680264107962,
          0.31746152638231523,
          0.3571159983961219,
          -0.015530983180227128,
          -1.4300640352212877,
          0.34561251096594886,
          -1.640254610544972,
          -1.4592834487066002,
          0.24951047437652393,
          0.3285110428132621,
          -0.015530983180227128,
          0.33367123140064814,
          0.3444372020625864,
          0.3170096871567257,
          -2.3913557092249778,
          0.338811262125063,
          -0.05989435991937305,
          -2.081176625590306,
          0.039664624756437915,
          0.3489795334728112,
          0.32182340398716164,
          -2.9197447417064395,
          -0.014317561163031919,
          0.3217651086408016,
          -0.005880912456986113,
          -1.448317302815513,
          -0.4339345005778927,
          0.06276414313148926,
          0.28509989307991696,
          0.21951714364149677,
          -0.4889137188238864,
          -0.3417145668286939,
          0.036877641608271526,
          0.3150568541298294,
          0.24746545663541378,
          0.35727993002476305,
          0.31148809282870005,
          -2.4132381669868876,
          0.35489223778275375,
          -0.20903285856763884,
          0.30439477388474856,
          -0.18179459606813883,
          0.005460781313970024,
          -1.4592909060877746,
          -0.212050241969299,
          0.3174931643621659,
          -0.015530983180227128,
          0.3353716977955163,
          -1.5756898654563372,
          -0.015530983180227128,
          -2.4867973331643873,
          -0.897051093649644,
          0.18568783704299752,
          -1.6716753277478882,
          -1.5944783458265779,
          0.35689390760137835,
          -1.1116604722794263,
          0.161325646200834,
          -1.4532490867386936,
          -0.015530983180227128,
          -0.015530983180227128,
          -0.04491270066423677,
          -0.18255624968993478,
          -0.513021377656454,
          0.021074159249976316,
          -0.015530983180227128,
          -1.7460056076308736,
          -2.366654744646537,
          -0.015530983180227128,
          -1.4592623522034285,
          -1.4582506008012097,
          -0.8995157961813371,
          -0.8139010307476454,
          0.180282844365482,
          0.16425992169448433,
          -0.015530983180227128,
          0.35758761204492134,
          -3.139433999176027,
          0.3565716196378776,
          -0.015530983180227128,
          0.05711872402105833,
          -1.5106026292199455,
          0.3201920666046058,
          0.04912367557036242,
          -0.015530983180227128,
          0.2605795483986217,
          -1.2834431093630148,
          -2.8745745514525383,
          0.3234229063715591,
          0.21768753755328732,
          0.3520003227920047,
          0.2741472097858803,
          0.2792908789243675,
          -1.4592428749922888,
          -1.4589484499447365,
          0.3176585774961213,
          -0.051234433369522714,
          0.3556128568111923,
          -0.489533408944461,
          0.26257398799403214,
          0.3130296640894251,
          -0.273654413598675,
          -0.015530983180227128,
          0.3111204650472859,
          -0.015530983180227128,
          -0.33255337672436763,
          -0.3307179576867995,
          0.2726393953956624,
          0.11416818930880505,
          -1.4514145508624514,
          0.34185216723892364,
          0.3535353661013658,
          -1.4586827269512468,
          -0.18019276394845452,
          0.35428062348844386,
          0.34200954752552276,
          0.2569633984382244,
          0.32074009413985133,
          -3.697115951843775,
          0.3561429058649173,
          0.32575739184310004,
          -0.015530983180227128,
          -0.5848357738351018,
          0.31985723293243246,
          0.3171250094250648,
          0.29657093846785904,
          -1.4590797205813855,
          0.3224013086381676,
          -2.836589669189297,
          -1.1966342181954486,
          -1.4571160017966678,
          -0.015530983180227128,
          0.3111390680524177,
          0.11685595375432352,
          -0.6984280379751314,
          0.3354599223114963,
          -0.253836980355315,
          0.2974172284331743,
          -0.18133353464166835,
          -0.07609937693499629,
          0.3243572030090798,
          -0.015530983180227128,
          -0.6346717182026453,
          0.03641185168853215,
          -0.015530983180227128,
          -0.025822392380145942,
          -2.1118504542504013,
          -0.14281851492848918,
          -1.457469089664567,
          -0.6836244252853094,
          -1.3214230885094205,
          -0.029052928898087454,
          -0.6103085797124708,
          -1.439171408964389,
          0.35678917580913855,
          -1.4991379056916205,
          -0.07396803276656716,
          -0.10605233152828586,
          -0.015530983180227128,
          0.357452300328232,
          -0.012623737004465877,
          0.3200521974896526,
          -2.8001588455197486,
          0.33889852058266096,
          -0.2581873817514521,
          0.3257583039751088,
          -1.4592987534382902,
          -0.015530983180227128,
          0.028256184770042547,
          -0.010470835859536676,
          -1.453866656509673,
          -1.439189068184881,
          0.30811960449392767,
          -1.0948570254577572,
          0.3024378091839134,
          0.29885748864628986,
          -1.4589790264347757,
          -0.3696070159863621,
          0.3197115312758058,
          -0.42620339107639654,
          0.3576425931721961,
          0.33693041411432695,
          0.0690710077374731,
          0.32048530560363797,
          -1.4997825946640038,
          -0.015530983180227128,
          -0.7061407169586488,
          -0.8023305337513642,
          -0.8053072330434713,
          -2.932795712631943,
          -0.06630803809759316,
          -2.4675413750695645,
          0.3425103224363916,
          0.2580405385825567,
          0.3230322034270965,
          -1.4161956868768453,
          -1.6848623873609776,
          -1.9354625475862086,
          -2.097399063678455,
          -1.7081721553718534,
          -2.609449108165568,
          -1.5595916041806364,
          -1.313708159223527,
          -1.438225604431407,
          0.3139912444126636,
          0.26357969012149857,
          -3.3140551025640943,
          -0.7077141372406534,
          0.3588469294680684,
          -0.015530983180227128,
          -0.015530983180227128,
          0.19987500346486253,
          -0.7177900981327858,
          0.014955257149350643,
          -0.20545725197618817,
          0.013776508996084624,
          0.3333001270437866,
          0.03411482001979812,
          0.3211013273526692,
          -0.16221399256145777,
          -0.2032243514585487,
          -1.4559522865319048,
          0.20112735009320545,
          -2.5465462851803737,
          -0.015530983180227128,
          -1.3324918345345875,
          0.31921321323558366,
          -1.3496886390902718,
          -3.990254572311704,
          0.3421913130962326,
          -0.015530983180227128,
          -0.015530983180227128,
          -1.514411204945636,
          -0.38358936064938326,
          -0.015530983180227128,
          -1.458039511533223,
          -0.3743815071697198,
          -1.4592633928431915,
          -0.015530983180227128,
          0.3259268898807265,
          -0.5446090757566071,
          -0.015530983180227128,
          -0.015530983180227128,
          -1.2383805367445837,
          0.03417599580319641,
          -1.0667065930268642,
          -2.8538256938154216,
          0.30051183873630744,
          0.29803969998525864,
          -0.015530983180227128,
          0.0763937427600712,
          0.28466936101103507,
          0.27362540456490864,
          0.26917790828729626,
          0.3210191627468116,
          0.3554633197527738,
          -1.7742679945268736,
          -2.039699070680622,
          -2.0909830280289685,
          -2.1500021431343246,
          -0.6821247133226127,
          0.3435721391531418,
          0.31571656595838477,
          -0.015530983180227128,
          0.3387389731097537,
          0.021630583519937335,
          0.3374179278697955,
          -0.015530983180227128,
          0.335175685191468,
          0.31177416919504913,
          0.3237042318332511,
          -0.10344999000141131,
          -1.4555219065990597,
          0.3530702044948691,
          0.28559869296371093,
          0.34868643462580906,
          0.13417357536024588,
          0.3529322955331178,
          0.3550363134440149,
          0.3520436743431737,
          0.3526969765198833,
          0.3500423650319993,
          0.35808171621483814,
          -0.015530983180227128,
          -1.646240169050901,
          -0.015530983180227128,
          0.3585006731722821,
          0.259628348511263,
          -1.4590356028617877,
          0.06115402568167098,
          -0.6359631986417477,
          -0.5140333414145846,
          0.3494533119144711,
          0.2513547747173234,
          0.3564058919007555,
          0.2949778975936353,
          0.29299245321150563,
          -0.015530983180227128,
          0.28751574834271715,
          -0.015530983180227128,
          -3.348314060665161,
          -1.4484870664168326,
          0.3195656030625804,
          0.3135597113714967,
          -3.1194842804488303,
          -1.4592935373441682,
          0.3133844969375929,
          -0.3965436766797861,
          0.3140169956962356,
          0.35825148635079634,
          -1.341344373073883,
          -1.4286984150248523,
          -0.015530983180227128
         ],
         "type": "scatter"
        },
        {
         "name": "Best Value",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          -1.4588566440063353,
          -1.4186238795506367,
          -1.4186238795506367,
          0.34216137737701824,
          0.34216137737701824,
          0.34216137737701824,
          0.34216137737701824,
          0.34216137737701824,
          0.34216137737701824,
          0.34216137737701824,
          0.34216137737701824,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.3572658715830546,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.35866430895057694,
          0.3589629641662819,
          0.3589629641662819,
          0.3589629641662819,
          0.3589629641662819,
          0.3589629641662819,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.3590101021316477,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.35905311002504064,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899,
          0.3603214034046899
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        },
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"c1ae8ca1-1944-4763-a274-ca45c80337ce\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c1ae8ca1-1944-4763-a274-ca45c80337ce\")) {                    Plotly.newPlot(                        \"c1ae8ca1-1944-4763-a274-ca45c80337ce\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999],\"y\":[-1.4588566440063353,-1.4186238795506367,-1.4544204143926058,0.34216137737701824,-1.4592894203414815,-1.2851724293152476,-1.0181034118687586,-1.2659143003247595,0.023625995974864034,-0.015530983180227128,-0.015500695097565983,0.3572658715830546,0.18025439973100474,-1.4608882846383286,-1.8180348210106962,-0.9927486221172465,-1.618533230604383,0.32058660350081286,0.10710902288645618,0.35549691245468323,-3.292956266082208,-3.0454415634994234,-3.318535151838067,-2.438316439548156,-0.015530983180227128,-1.3989318076014794,-3.3868368865403897,-4.113433421282801,0.3340060028910736,0.33983561911351234,0.33491988500858355,0.26951701759981045,-0.015530983180227128,0.22035503036760481,0.2978541917178748,0.35866430895057694,0.31373835674571315,0.12932749082335837,0.2425865490743435,-0.015530983180227128,-0.0014153394919703688,0.05550761445672888,0.31749073414887985,0.3175486877282333,-1.1737488389175899,-1.3870978362141995,-0.5628248380931161,0.058950514407528666,0.33701257267914336,-0.1089600358672342,0.3411702716182422,0.06594382135104937,0.3370592974448212,-0.015530983180227128,0.34086502615278663,0.3399125025660407,0.3166631619834335,0.3426261530747236,0.3430656613920456,0.3428946303035355,-0.28906591989821184,0.3398038819718452,-0.28947352898421286,0.24269347388740617,0.22539670765738998,-0.3246935341885149,-0.32852952940247465,0.2351915885891488,0.2566912048915019,0.34328843016891925,0.3306977645905042,0.3222144998955559,0.33545896210178877,0.3227062378834569,0.33553891230776783,-0.015530983180227128,0.3395437399406364,0.3421545316798636,0.3356873471001011,0.32008851483832546,0.311591958383739,-0.015530983180227128,0.3364179500414026,0.31990929657122014,-2.552278580876953,0.34352993099701296,0.34363297658866526,0.332995077061896,0.3432552668825773,0.3433832338164791,0.3431160500204338,0.08458993578110534,0.10621048729256448,0.11362359788401366,0.30289869328226565,0.3330673912108459,0.34356435978747873,0.3333014167749549,0.14007708989977863,0.34362671451946114,0.08795102420329966,0.10764145966097678,0.12525507384321607,0.13810773271791368,0.3436294319533494,-0.015530983180227128,-0.4976968424495506,-0.4938522708286848,0.3432729458915366,0.33538735142924614,0.34396407806549234,0.0676674772685731,0.28957983884197064,0.35559305952517556,0.28536753462302833,0.35449940302888366,0.353275923454508,0.3556806905288994,0.3584358498271417,0.3556802369386711,0.35823191211381694,0.3552871489429807,0.3475912627734778,0.3589629641662819,0.34775853994064815,0.35767131413199565,0.3577516548496169,0.3346303442322133,0.3590101021316477,0.19165048934513376,-0.4425521405306269,-0.2143361149375758,-0.5632198581246426,-0.022476813628028114,-0.14034568065295225,-0.6248525888870063,0.1651233144846966,0.17870736875553297,0.32086628728045785,0.32565535777254434,0.17142630796836122,0.3154372650158423,0.3574362412163299,0.35838071582056313,0.35542519269214107,0.3579673609234114,0.35625965438162227,0.3554621066345563,0.3562383860556151,0.35529740603277793,0.35857044104617514,0.3560802708808445,0.35849394056187145,0.3487610648407854,0.355639104055644,0.3569469677120692,0.34215713652774393,0.3437652860156858,0.34609535690051557,0.3243768327923027,0.30877608897240466,0.3089930429691231,0.26704037028675254,0.34644828885223344,0.3510282485296207,0.2154714599802278,0.35905311002504064,0.34012341942322943,0.3485484939160866,0.34947941784485514,0.10370870280683926,0.11582147497170252,-1.6444983307045624,0.31390624425061125,-1.3806280496304346,0.32690155719100483,-0.4927017233056891,0.3556432364883561,0.23748912871306463,0.323256356080263,0.3153598607041081,-0.22176279702005544,-0.23945852036809487,-0.049614966641591596,-0.2950643614828246,-0.10719945576620149,-0.07994009213256308,0.32642101451467614,0.18103193214229688,0.3583395099603423,0.3115455170461861,0.3588350989716463,0.35557156087560937,0.32067234758972546,0.35262644138693827,0.31996610285925775,0.28392867020650037,0.31153935292078166,0.35884432405815353,0.3522741400435548,0.35742331338950745,0.3584192220349806,0.35640425501286704,0.35879220830896286,0.3579958754257995,0.35515744247846576,0.35787433921658846,0.35264448755504135,0.35285039225925646,0.3357513389040881,0.33345496567479244,0.3559611854839141,0.3493149002385352,-0.08923461982228624,0.35556855893360867,-0.15820177871676164,0.3573679359980803,0.10908787265381932,0.35892927938510694,-0.11814645137514253,0.10875264898829029,0.3518024711046048,0.33473910846148713,0.3442385549313532,0.32631069680731545,0.0771552251210323,0.1583577688628215,-0.6459511846433815,0.3557450871356086,0.35139176040671194,0.187407148917166,-0.010748006623309289,0.1454187846058805,0.14465612142220094,0.16667109977434158,0.326119867509815,0.35641826878216215,0.35775727013691144,0.3585731346168109,0.35891917928167605,0.3231006491235032,-0.11381228325339994,0.013636084687276543,0.3510712442615813,0.3556739375191189,0.3379185646005755,0.3443113633113733,0.13738822317302932,0.3217881445098996,0.3477152669173245,-0.579929781497432,-0.6312305535032702,-0.6665962646133711,0.3112915288088999,-0.799392569560221,-0.9884734330291947,-0.8633357900213132,0.33479264608706344,0.3301770313869203,-1.4581299187241386,0.32985425594588347,0.3266386973062517,0.15714248753659377,-0.7542689492597158,0.35506109021892235,-0.015530983180227128,0.350659289563602,-0.10532896547230493,-1.4474188455224184,-1.2186626142315062,-0.2509122726884796,0.35784343733491525,0.32374614266479945,0.3228668773910273,0.33360694402947116,-1.459282765511732,0.35681147381100004,0.319676377553934,-0.0333862488790185,-0.0012424596238384729,0.349531794611252,0.2616054601382115,0.3489002420208785,-3.3942958905710605,0.3207160472169541,0.3265463936586212,0.10146932695958837,-4.179199352777676,-0.015530983180227128,-1.347034682280125,-3.102323190893002,-2.6363264195465734,0.35535121816891374,-1.3195634165693984,0.3008718993883735,0.20463377817227782,0.3507808698874323,0.3441369158278777,-0.12192646391065864,-0.48336143625031686,0.3054755423653524,0.31703469125452416,-0.6816296103098017,-0.6984491784464092,-0.561662838986741,0.32129606789500914,-1.3314918935177145,-1.7725634270981712,-0.6123112186063538,0.3380399824366615,0.3424848875982817,-1.4527132885932348,0.3211436181019196,0.28874869026131533,0.102895844197045,0.3198534893675102,0.3559026409491577,0.3561372329700137,-1.335982214810917,0.3558390170110048,-0.22183003775507992,0.35248011327402623,0.3482835006833344,0.27502723504919774,0.35529346564166436,0.021089969737206078,0.35412333708478216,0.036562496108139074,-0.015530983180227128,-0.47663256403224047,0.174490656215424,-0.4315309250671305,-3.6600910998854816,0.346478698066261,0.35769741116789106,0.35894922190117373,0.32048269253517847,-2.6158720724761952,0.31623366886675214,0.3575559488449212,0.31580800231750034,-0.015530983180227128,0.2947544802095244,0.3603214034046899,0.21037786751230458,0.3516787210976737,0.31668871842392793,0.3492435831402289,0.31177336760749125,0.35602028215560605,0.24427447613474965,0.08917838968842924,0.31751538386488976,0.03379042906960539,0.29546816414174276,0.16689944992487393,-2.091249557798951,-2.064419654972361,0.1309520358236441,-1.8644662372140417,0.3574592978371764,-1.8630823820148064,0.32216096431444846,0.3339996382023081,-1.8607245061478899,0.3256123187233857,-0.27195260026519646,0.355923982836866,0.22831156756388551,-0.2430285964127928,0.34842702376776635,0.3452648844291753,0.3478606276201634,0.35843994774725363,-0.18724976247032424,0.35692783008651174,0.30554291419607416,-2.67070363670904,-0.40574744615689207,-0.2679718814609029,0.34136822970543096,0.3205494509913016,-0.49765888458377594,0.24827278085196447,-4.177634302903346,0.25114625909675425,-2.65891362123988,0.11502151895902864,0.3453186802497291,0.356046210075102,0.32654497568528595,-0.015530983180227128,-1.5315663508411754,0.3339170272411143,0.35534227110870276,-0.6313760931421741,0.21893668452624773,0.19644780755835234,-1.264487029697481,0.3202112787439207,-1.8351786016940215,-1.5134361550753421,-2.2720082803825026,-2.0074292483467904,-1.459106552959043,0.085528337801892,0.3496716917010649,0.2944678536482575,0.3467481302066269,-1.4586713810436456,-0.015530983180227128,-0.23117528226447157,0.3578128020253674,0.3401368502092517,0.29559171726388894,0.2794560009966162,-0.06005171663412815,-2.1781679562009257,0.32816605472294685,0.3480812739315084,-0.015530983180227128,0.21664656672368152,-0.015530983180227128,0.23774034844378575,0.3175799951302369,0.05329001899922936,-1.4592954096167965,0.01283582291706605,-0.34420804318204073,-0.24570510294741574,-0.015530983180227128,0.33728565297216,0.2795618206553193,-0.351661529658744,0.3474372284556131,0.3581160246105819,0.31757421665635166,0.33682649212269117,0.325344128336722,0.3546562344166067,0.3584273177075202,-0.384034081123584,-0.015530983180227128,0.14360904634536809,0.3584507771804764,0.35487412511246247,-0.0234943738564715,-0.018104848896938048,-0.015530983180227128,0.35772746694155305,-0.3485847147437076,-0.40670478607532834,-0.3941703510715586,0.31811912576974893,-0.015530983180227128,-1.0331094715647526,-1.5120171381314516,-3.4277403557600064,0.059222216092806756,-0.010311694371020419,0.18648868337852595,-1.2870022917608257,-0.8480015688133308,0.3553138776992857,-1.2496700077227336,-1.239631454137545,0.3065756156315676,0.09629062040162413,0.08912962969695115,0.01185570600516687,0.2971055111276842,0.2965333883497692,-0.015530983180227128,-0.10748666340397776,-1.4590037327890628,0.3197303136987384,0.23882900318257852,0.26991983437445616,0.3204304508764704,-0.015530983180227128,-2.1243657559825193,-0.5900363819602418,-0.12925480111034296,-0.13395604549890172,0.3201190574452502,-0.11508520687883768,0.3207485586361093,0.32827692779201506,0.15679517057561795,-0.015530983180227128,-3.247480444483889,-3.322101992799808,0.2771944678038373,-0.5225667432304725,0.32009252723610654,-0.7278587454009573,-0.6140669368969788,-0.758736101106032,0.19914503539835152,0.2411413216041596,0.23796316047355137,0.3401914314367314,-0.015530983180227128,0.3580215169988141,-2.0310534784649583,0.3582705974344014,-0.015530983180227128,-0.015530983180227128,0.3501283462911874,0.3576525739705391,0.35549412942962305,0.17119656952674733,0.27618997225675895,-1.4588577429004395,-0.015530983180227128,-0.015530983180227128,-1.8664980265537285,-1.5355455220283616,-1.3250420154970737,-1.4580939998116074,-1.2077031960076055,-2.485572829925278,-0.22415764325271706,0.318765495075478,-1.8030956635184299,0.3590092124495716,0.35765806097152913,-1.9915872797116079,0.2048837917693804,0.34680151319927427,0.31125157963637934,-2.0947192565071995,0.3264360480152067,0.317557444180661,0.059883505784525504,0.35800429176088616,0.3565337363533025,0.11578527872929427,0.31988040769645104,-0.015530983180227128,-0.1979089937043974,-1.2824366448911533,-1.3871808668777832,-0.8202745005649644,-0.9600358698474978,0.31912913786308417,0.3321389804692722,-1.4592856903403628,0.320054750405451,-0.8461107227636813,0.34515182008829265,-0.9563664546385848,-1.0408124695521126,0.26120913524871686,-0.8783777723335607,0.32417235114190385,0.3251466535172783,-0.19415503325323338,-0.9068639932466932,0.33611980987919354,-0.4047925106032945,0.35848760060982465,0.3003708725906461,0.2947905990108231,-4.144038109063413,0.3167671223679029,-1.459071482409423,-1.3533434915360392,-0.01417611650574598,0.3402071706583554,-1.2454379331087817,-1.2163888129798313,-2.124591846718434,-2.1486789761548835,0.2787110440676368,-0.015530983180227128,0.3199898967479248,0.31429758218081766,-2.1681133956602676,-0.2517336906262751,-2.657490656966469,-1.517555969517879,0.1508129192112416,0.1544524564112597,-2.422221071448753,-0.015530983180227128,-3.6309719371834768,0.3213172723681464,0.32038895876691525,-0.4800849020707178,-3.6493396321954834,-1.4547966029295487,-1.4577246596629323,0.32035780768809236,0.07519450813724142,-1.2838435986902925,0.3137903833350297,-1.3030852462962523,0.22722357831246798,0.2129694564947278,-1.2687998712805169,0.27078439757688855,0.25637591422105926,-0.015530983180227128,-0.015530983180227128,-1.4561817592040354,-0.1211662885794876,-0.12571209880544307,-0.07408028577053798,0.34812232571210816,0.3493742480997195,-0.08404046543704391,-0.015530983180227128,0.3561959617013009,-0.07437295570133844,0.2795870754956958,0.3553407582890843,0.3393680485949116,-0.015530983180227128,-4.206927979808516,0.3327574256949249,0.33872436419636354,-0.015530983180227128,-0.6466471365699425,-0.49011235414007776,-0.48030471306019,-0.6463054869554511,0.00985912368462379,-2.9049618809227606,-0.06069600438672277,0.313674552802458,0.33994448998307025,-0.07679431670931695,0.33335234357105353,0.27889474956363675,-2.2408427557720936,0.31686561532083074,-2.129403453120829,0.34387954460932685,0.09621218267102179,-1.4525047372969182,-0.10494403673150261,0.3124440850602468,-1.4588958029007904,0.3185798769335579,-0.8888432590930738,-0.9194754495981251,-0.3436034372555689,0.3547863225511882,-0.30885782251984506,-0.30801565239474293,-3.0223649644227444,-1.4988911901230664,-0.015530983180227128,-2.055582947896753,0.3370968261858521,0.3477798718891792,-3.0976078729492342,-0.3360056045206083,0.12075123409384174,-0.015530983180227128,0.31141071697362727,0.29377280851451687,-0.015530983180227128,-1.0880284048640538,0.34904683843411416,0.3205039812705726,-0.450847413713562,-1.4586619588503071,-1.4342824655550332,-1.154025538966952,-0.9809027963120157,-0.015530983180227128,-0.8707000961143022,-1.3200875894834236,0.28056061481194117,0.34545469494947995,-1.458998086567035,0.2883652493700352,-1.2546990794824073,-1.3836040947139567,-0.7777234079228538,0.31976067045407447,0.21730125561382774,-0.015530983180227128,0.2826380386830044,-1.3873323518596086,-1.4296680264107962,0.31746152638231523,0.3571159983961219,-0.015530983180227128,-1.4300640352212877,0.34561251096594886,-1.640254610544972,-1.4592834487066002,0.24951047437652393,0.3285110428132621,-0.015530983180227128,0.33367123140064814,0.3444372020625864,0.3170096871567257,-2.3913557092249778,0.338811262125063,-0.05989435991937305,-2.081176625590306,0.039664624756437915,0.3489795334728112,0.32182340398716164,-2.9197447417064395,-0.014317561163031919,0.3217651086408016,-0.005880912456986113,-1.448317302815513,-0.4339345005778927,0.06276414313148926,0.28509989307991696,0.21951714364149677,-0.4889137188238864,-0.3417145668286939,0.036877641608271526,0.3150568541298294,0.24746545663541378,0.35727993002476305,0.31148809282870005,-2.4132381669868876,0.35489223778275375,-0.20903285856763884,0.30439477388474856,-0.18179459606813883,0.005460781313970024,-1.4592909060877746,-0.212050241969299,0.3174931643621659,-0.015530983180227128,0.3353716977955163,-1.5756898654563372,-0.015530983180227128,-2.4867973331643873,-0.897051093649644,0.18568783704299752,-1.6716753277478882,-1.5944783458265779,0.35689390760137835,-1.1116604722794263,0.161325646200834,-1.4532490867386936,-0.015530983180227128,-0.015530983180227128,-0.04491270066423677,-0.18255624968993478,-0.513021377656454,0.021074159249976316,-0.015530983180227128,-1.7460056076308736,-2.366654744646537,-0.015530983180227128,-1.4592623522034285,-1.4582506008012097,-0.8995157961813371,-0.8139010307476454,0.180282844365482,0.16425992169448433,-0.015530983180227128,0.35758761204492134,-3.139433999176027,0.3565716196378776,-0.015530983180227128,0.05711872402105833,-1.5106026292199455,0.3201920666046058,0.04912367557036242,-0.015530983180227128,0.2605795483986217,-1.2834431093630148,-2.8745745514525383,0.3234229063715591,0.21768753755328732,0.3520003227920047,0.2741472097858803,0.2792908789243675,-1.4592428749922888,-1.4589484499447365,0.3176585774961213,-0.051234433369522714,0.3556128568111923,-0.489533408944461,0.26257398799403214,0.3130296640894251,-0.273654413598675,-0.015530983180227128,0.3111204650472859,-0.015530983180227128,-0.33255337672436763,-0.3307179576867995,0.2726393953956624,0.11416818930880505,-1.4514145508624514,0.34185216723892364,0.3535353661013658,-1.4586827269512468,-0.18019276394845452,0.35428062348844386,0.34200954752552276,0.2569633984382244,0.32074009413985133,-3.697115951843775,0.3561429058649173,0.32575739184310004,-0.015530983180227128,-0.5848357738351018,0.31985723293243246,0.3171250094250648,0.29657093846785904,-1.4590797205813855,0.3224013086381676,-2.836589669189297,-1.1966342181954486,-1.4571160017966678,-0.015530983180227128,0.3111390680524177,0.11685595375432352,-0.6984280379751314,0.3354599223114963,-0.253836980355315,0.2974172284331743,-0.18133353464166835,-0.07609937693499629,0.3243572030090798,-0.015530983180227128,-0.6346717182026453,0.03641185168853215,-0.015530983180227128,-0.025822392380145942,-2.1118504542504013,-0.14281851492848918,-1.457469089664567,-0.6836244252853094,-1.3214230885094205,-0.029052928898087454,-0.6103085797124708,-1.439171408964389,0.35678917580913855,-1.4991379056916205,-0.07396803276656716,-0.10605233152828586,-0.015530983180227128,0.357452300328232,-0.012623737004465877,0.3200521974896526,-2.8001588455197486,0.33889852058266096,-0.2581873817514521,0.3257583039751088,-1.4592987534382902,-0.015530983180227128,0.028256184770042547,-0.010470835859536676,-1.453866656509673,-1.439189068184881,0.30811960449392767,-1.0948570254577572,0.3024378091839134,0.29885748864628986,-1.4589790264347757,-0.3696070159863621,0.3197115312758058,-0.42620339107639654,0.3576425931721961,0.33693041411432695,0.0690710077374731,0.32048530560363797,-1.4997825946640038,-0.015530983180227128,-0.7061407169586488,-0.8023305337513642,-0.8053072330434713,-2.932795712631943,-0.06630803809759316,-2.4675413750695645,0.3425103224363916,0.2580405385825567,0.3230322034270965,-1.4161956868768453,-1.6848623873609776,-1.9354625475862086,-2.097399063678455,-1.7081721553718534,-2.609449108165568,-1.5595916041806364,-1.313708159223527,-1.438225604431407,0.3139912444126636,0.26357969012149857,-3.3140551025640943,-0.7077141372406534,0.3588469294680684,-0.015530983180227128,-0.015530983180227128,0.19987500346486253,-0.7177900981327858,0.014955257149350643,-0.20545725197618817,0.013776508996084624,0.3333001270437866,0.03411482001979812,0.3211013273526692,-0.16221399256145777,-0.2032243514585487,-1.4559522865319048,0.20112735009320545,-2.5465462851803737,-0.015530983180227128,-1.3324918345345875,0.31921321323558366,-1.3496886390902718,-3.990254572311704,0.3421913130962326,-0.015530983180227128,-0.015530983180227128,-1.514411204945636,-0.38358936064938326,-0.015530983180227128,-1.458039511533223,-0.3743815071697198,-1.4592633928431915,-0.015530983180227128,0.3259268898807265,-0.5446090757566071,-0.015530983180227128,-0.015530983180227128,-1.2383805367445837,0.03417599580319641,-1.0667065930268642,-2.8538256938154216,0.30051183873630744,0.29803969998525864,-0.015530983180227128,0.0763937427600712,0.28466936101103507,0.27362540456490864,0.26917790828729626,0.3210191627468116,0.3554633197527738,-1.7742679945268736,-2.039699070680622,-2.0909830280289685,-2.1500021431343246,-0.6821247133226127,0.3435721391531418,0.31571656595838477,-0.015530983180227128,0.3387389731097537,0.021630583519937335,0.3374179278697955,-0.015530983180227128,0.335175685191468,0.31177416919504913,0.3237042318332511,-0.10344999000141131,-1.4555219065990597,0.3530702044948691,0.28559869296371093,0.34868643462580906,0.13417357536024588,0.3529322955331178,0.3550363134440149,0.3520436743431737,0.3526969765198833,0.3500423650319993,0.35808171621483814,-0.015530983180227128,-1.646240169050901,-0.015530983180227128,0.3585006731722821,0.259628348511263,-1.4590356028617877,0.06115402568167098,-0.6359631986417477,-0.5140333414145846,0.3494533119144711,0.2513547747173234,0.3564058919007555,0.2949778975936353,0.29299245321150563,-0.015530983180227128,0.28751574834271715,-0.015530983180227128,-3.348314060665161,-1.4484870664168326,0.3195656030625804,0.3135597113714967,-3.1194842804488303,-1.4592935373441682,0.3133844969375929,-0.3965436766797861,0.3140169956962356,0.35825148635079634,-1.341344373073883,-1.4286984150248523,-0.015530983180227128],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999],\"y\":[-1.4588566440063353,-1.4186238795506367,-1.4186238795506367,0.34216137737701824,0.34216137737701824,0.34216137737701824,0.34216137737701824,0.34216137737701824,0.34216137737701824,0.34216137737701824,0.34216137737701824,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.3572658715830546,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.35866430895057694,0.3589629641662819,0.3589629641662819,0.3589629641662819,0.3589629641662819,0.3589629641662819,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.3590101021316477,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.35905311002504064,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899,0.3603214034046899],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('c1ae8ca1-1944-4763-a274-ca45c80337ce');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/Documents/Cours/Stage/QSAR/code/wrapper/utils.py:228: UserWarning:\n",
      "\n",
      "color is redundantly defined by the 'color' keyword argument and the fmt string \"--k\" (-> color='k'). The keyword argument will take precedence.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_utils.display_score(ElasticNet(**study.best_params, random_state=0, max_iter=100000), X_full_train, y_full_train, X_full_test, y_full_test)\n",
    "display(plot_optimization_history(study))\n",
    "\n",
    "rr = ElasticNet(**study.best_params, random_state=0, max_iter=100000).fit(X_full_train, y_full_train)\n",
    "y_full_train_pred = rr.predict(X_full_train)\n",
    "y_full_test_pred = rr.predict(X_full_test)\n",
    "\n",
    "test_utils.display_graph(rr, X_full_train, X_full_test, y_full_train, y_full_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T21:16:42.561262479Z",
     "start_time": "2023-06-16T21:16:36.617771237Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ionizable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 3 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      "\tR2\t\t\t\t:\t 0.7716500789423435 \n",
      "\tCV train\t\t:\t -1.9451061731634642 \n",
      "\tCustom CV train\t:\t -1.183618144578109 \n",
      "\tQ2\t\t\t\t:\t 0.2593798770428798\n"
     ]
    }
   ],
   "source": [
    "test_utils = utils.Utils(ionizable_train)\n",
    "test_utils.create_cv_folds(display=True)\n",
    "test_utils.display_score(ElasticNet(max_iter=100000, random_state=0), X_ionizable_train, y_ionizable_train, X_ionizable_test, y_ionizable_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T21:21:02.924806593Z",
     "start_time": "2023-06-16T21:20:45.622881407Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:24:08,939] A new study created in memory with name: no-name-5138d2a8-9db9-41d8-a66f-c67d4c9dd6c3\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cccf18b2629c4a13b15f42bc1a178dbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:24:09,663] Trial 1 finished with value: -0.011296077930571117 and parameters: {'alpha': 27567208.021340236, 'l1_ratio': 4.4305548179649205e-10}. Best is trial 1 with value: -0.011296077930571117.\n",
      "[I 2023-06-16 17:24:09,686] Trial 0 finished with value: -0.0010098328195528028 and parameters: {'alpha': 9142185.485605113, 'l1_ratio': 5.109538206466568e-08}. Best is trial 0 with value: -0.0010098328195528028.\n",
      "[I 2023-06-16 17:24:09,701] Trial 7 finished with value: -3.8565105649207716 and parameters: {'alpha': 1.4420922988194e-09, 'l1_ratio': 7.76116279408315e-09}. Best is trial 0 with value: -0.0010098328195528028.\n",
      "[I 2023-06-16 17:24:09,714] Trial 2 finished with value: 0.034777071152314355 and parameters: {'alpha': 2329791.274049727, 'l1_ratio': 1.0759711173764234e-06}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:09,810] Trial 6 finished with value: 0.00400445733287047 and parameters: {'alpha': 7068604.42085936, 'l1_ratio': 1.2185801368304706e-08}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:10,016] Trial 8 finished with value: 0.0002920127999291866 and parameters: {'alpha': 3542274.528464883, 'l1_ratio': 1.3813973932073864e-05}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:10,040] Trial 9 finished with value: -0.019875470650102756 and parameters: {'alpha': 55036.12842897851, 'l1_ratio': 0.00017575122618085376}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:10,352] Trial 13 finished with value: -3.8565087398318605 and parameters: {'alpha': 1.4510382626446732e-10, 'l1_ratio': 8.282753282308488e-06}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:10,371] Trial 14 finished with value: -3.8565186549481343 and parameters: {'alpha': 7.159774246818383e-09, 'l1_ratio': 0.00317968508792602}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:12,514] Trial 11 finished with value: -3.8622711760459767 and parameters: {'alpha': 8.079771471351319e-08, 'l1_ratio': 6.028647070526066e-08}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:12,613] Trial 4 finished with value: -1.174953364767386 and parameters: {'alpha': 2.4777742105091276e-05, 'l1_ratio': 5.75425374351222e-08}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:12,853] Trial 17 finished with value: -0.0632773861484754 and parameters: {'alpha': 73.50341870638513, 'l1_ratio': 0.6255498764266946}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:12,924] Trial 18 finished with value: -0.009217972097849803 and parameters: {'alpha': 876.2993465764597, 'l1_ratio': 0.9863220311662512}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:13,131] Trial 19 finished with value: -0.009258465945957361 and parameters: {'alpha': 8600962372.705767, 'l1_ratio': 1.0677294606924099e-10}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:13,180] Trial 20 finished with value: -0.009418227616481664 and parameters: {'alpha': 1703598415.0576699, 'l1_ratio': 1.233076592205954e-09}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:13,266] Trial 5 finished with value: -2.108642797494871 and parameters: {'alpha': 8.539903414751176e-06, 'l1_ratio': 0.01084668402680626}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:13,889] Trial 15 finished with value: -2.3736023802198605 and parameters: {'alpha': 0.000707980830986755, 'l1_ratio': 2.4532223038911098e-08}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:14,491] Trial 10 finished with value: -2.0843483848884956 and parameters: {'alpha': 0.0002649869030662355, 'l1_ratio': 0.0027772643198966935}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:24:16,765] Trial 25 finished with value: -0.0716903103210248 and parameters: {'alpha': 22172.387401866272, 'l1_ratio': 7.07418387907203e-07}. Best is trial 2 with value: 0.034777071152314355.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.809e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.781e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.296e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.233e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.443e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.720e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.880e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.868e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.686e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:09,283] Trial 24 finished with value: -2.848030811338504 and parameters: {'alpha': 0.1108185321454185, 'l1_ratio': 7.177566964256932e-07}. Best is trial 2 with value: 0.034777071152314355.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.293e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:10,932] Trial 16 finished with value: -4.291153282973293 and parameters: {'alpha': 0.03379627834873732, 'l1_ratio': 3.55621484685193e-06}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:25:11,259] Trial 28 finished with value: -0.004422367170267967 and parameters: {'alpha': 2822555.0032727816, 'l1_ratio': 3.5469359369904097e-05}. Best is trial 2 with value: 0.034777071152314355.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:13,411] Trial 23 finished with value: -2.3450855727979247 and parameters: {'alpha': 0.5077651189249919, 'l1_ratio': 2.8336975123352988e-06}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:25:13,625] Trial 30 finished with value: -0.010017020368572993 and parameters: {'alpha': 256190633.68274435, 'l1_ratio': 6.718426989245284e-07}. Best is trial 2 with value: 0.034777071152314355.\n",
      "[I 2023-06-16 17:25:14,012] Trial 31 finished with value: 0.053483421678251264 and parameters: {'alpha': 263443.059893136, 'l1_ratio': 4.839991624549378e-09}. Best is trial 31 with value: 0.053483421678251264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.817e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:14,444] Trial 3 finished with value: -1.5024784592876343 and parameters: {'alpha': 40.88548428964667, 'l1_ratio': 1.3446015712056137e-10}. Best is trial 31 with value: 0.053483421678251264.\n",
      "[I 2023-06-16 17:25:14,768] Trial 32 finished with value: 0.0028281042727549277 and parameters: {'alpha': 85684.31097311463, 'l1_ratio': 5.6942087222747785e-09}. Best is trial 31 with value: 0.053483421678251264.\n",
      "[I 2023-06-16 17:25:15,020] Trial 34 finished with value: -0.009665043638839244 and parameters: {'alpha': 745965109.9945296, 'l1_ratio': 2.135819884611595e-09}. Best is trial 31 with value: 0.053483421678251264.\n",
      "[I 2023-06-16 17:25:15,275] Trial 35 finished with value: 0.06709256597835896 and parameters: {'alpha': 693165.6779317335, 'l1_ratio': 2.4564795179285705e-07}. Best is trial 35 with value: 0.06709256597835896.\n",
      "[I 2023-06-16 17:25:15,740] Trial 36 finished with value: 0.05606006278211684 and parameters: {'alpha': 286212.191803656, 'l1_ratio': 1.5973254785201706e-07}. Best is trial 35 with value: 0.06709256597835896.\n",
      "[I 2023-06-16 17:25:16,121] Trial 33 finished with value: -0.01152397956182701 and parameters: {'alpha': 64543.84760577657, 'l1_ratio': 3.4997866996403904e-09}. Best is trial 35 with value: 0.06709256597835896.\n",
      "[I 2023-06-16 17:25:16,333] Trial 38 finished with value: -0.011920350903106058 and parameters: {'alpha': 64112628.13162208, 'l1_ratio': 1.2255787817994247e-07}. Best is trial 35 with value: 0.06709256597835896.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:16,599] Trial 12 finished with value: -1.2141451954744273 and parameters: {'alpha': 172.97438320588617, 'l1_ratio': 1.6837770168552544e-06}. Best is trial 35 with value: 0.06709256597835896.\n",
      "[I 2023-06-16 17:25:16,767] Trial 39 finished with value: 0.06055107847553017 and parameters: {'alpha': 1071147.8646316074, 'l1_ratio': 1.4155320102667395e-07}. Best is trial 35 with value: 0.06709256597835896.\n",
      "[I 2023-06-16 17:25:16,910] Trial 40 finished with value: 0.061120846503111746 and parameters: {'alpha': 1044810.6287997868, 'l1_ratio': 1.3704428377199852e-07}. Best is trial 35 with value: 0.06709256597835896.\n",
      "[I 2023-06-16 17:25:17,033] Trial 41 finished with value: -0.01193016511916234 and parameters: {'alpha': 52500028.28797724, 'l1_ratio': 2.524267410652477e-07}. Best is trial 35 with value: 0.06709256597835896.\n",
      "[I 2023-06-16 17:25:17,186] Trial 42 finished with value: -0.012010942818341697 and parameters: {'alpha': 44041701.62240472, 'l1_ratio': 1.6626412120320204e-07}. Best is trial 35 with value: 0.06709256597835896.\n",
      "[I 2023-06-16 17:25:17,550] Trial 44 finished with value: 0.06755068102388358 and parameters: {'alpha': 536478.5060064296, 'l1_ratio': 2.680713204114036e-08}. Best is trial 44 with value: 0.06755068102388358.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:18,384] Trial 22 finished with value: -2.2860388668434224 and parameters: {'alpha': 0.1952426778863631, 'l1_ratio': 1.7482663732970794e-06}. Best is trial 44 with value: 0.06755068102388358.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.316e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:20,227] Trial 37 finished with value: -0.2116932215842501 and parameters: {'alpha': 7490.024972869381, 'l1_ratio': 1.1072380798926924e-07}. Best is trial 44 with value: 0.06755068102388358.\n",
      "[I 2023-06-16 17:25:20,367] Trial 47 finished with value: 0.059313164684552944 and parameters: {'alpha': 1135137.0305557305, 'l1_ratio': 2.8064667691802993e-08}. Best is trial 44 with value: 0.06755068102388358.\n",
      "[I 2023-06-16 17:25:20,372] Trial 21 finished with value: -3.4891438028075594 and parameters: {'alpha': 0.06097849457931243, 'l1_ratio': 1.115031353381659e-06}. Best is trial 44 with value: 0.06755068102388358.\n",
      "[I 2023-06-16 17:25:20,686] Trial 49 finished with value: 0.04662710001505984 and parameters: {'alpha': 1743623.608477369, 'l1_ratio': 2.4554527245449037e-08}. Best is trial 44 with value: 0.06755068102388358.\n",
      "[I 2023-06-16 17:25:20,716] Trial 48 finished with value: 0.05988551720749913 and parameters: {'alpha': 1108436.980642522, 'l1_ratio': 3.3329527771930744e-08}. Best is trial 44 with value: 0.06755068102388358.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.511e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:25,496] Trial 26 finished with value: -2.9522591851309383 and parameters: {'alpha': 1.4984987135335868, 'l1_ratio': 1.2514570051220672e-06}. Best is trial 44 with value: 0.06755068102388358.\n",
      "[I 2023-06-16 17:25:25,667] Trial 52 finished with value: -0.004352549004563315 and parameters: {'alpha': 11440377.527970143, 'l1_ratio': 1.3576222848138754e-08}. Best is trial 44 with value: 0.06755068102388358.\n",
      "[I 2023-06-16 17:25:25,877] Trial 53 finished with value: 0.06767113932168241 and parameters: {'alpha': 555218.7296897447, 'l1_ratio': 4.6139731042874166e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:27,549] Trial 46 finished with value: -0.3744606573161654 and parameters: {'alpha': 3978.72031730804, 'l1_ratio': 2.5587411642617988e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:28,011] Trial 45 finished with value: -0.3103462290001178 and parameters: {'alpha': 4957.894573899797, 'l1_ratio': 3.437267613478829e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:28,271] Trial 56 finished with value: -0.0036700574250639515 and parameters: {'alpha': 10902328.283004258, 'l1_ratio': 9.713230208169649e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:28,528] Trial 50 finished with value: -0.24865949529351672 and parameters: {'alpha': 6325.289180760645, 'l1_ratio': 1.995939909046606e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:28,799] Trial 58 finished with value: 0.06739632915842601 and parameters: {'alpha': 524459.4392189543, 'l1_ratio': 6.804247526983284e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:29,117] Trial 59 finished with value: 0.05173789120382203 and parameters: {'alpha': 251318.76298168983, 'l1_ratio': 3.3417114894819596e-07}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:29,442] Trial 60 finished with value: 0.004764086813811279 and parameters: {'alpha': 6772316.751818734, 'l1_ratio': 1.0243747173472648e-07}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:30,134] Trial 61 finished with value: 0.06458728720319788 and parameters: {'alpha': 407489.1734528449, 'l1_ratio': 7.744272956616616e-09}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:31,761] Trial 51 finished with value: -0.3071428742533792 and parameters: {'alpha': 5016.794280458169, 'l1_ratio': 1.5494781676494332e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:33,174] Trial 63 finished with value: -0.039970666754965335 and parameters: {'alpha': 37122.84398502541, 'l1_ratio': 8.97598041162982e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:33,354] Trial 64 finished with value: -0.010555762082375075 and parameters: {'alpha': 222452913.40424493, 'l1_ratio': 5.923467808201554e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:33,733] Trial 54 finished with value: -0.1891757340660971 and parameters: {'alpha': 8413.915708294, 'l1_ratio': 6.097972931917394e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:34,038] Trial 66 finished with value: 0.05186496864246518 and parameters: {'alpha': 251408.22935751354, 'l1_ratio': 5.5300785586383884e-08}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.911e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:25:49,465] Trial 43 finished with value: -0.749977810626106 and parameters: {'alpha': 1370.5437075713494, 'l1_ratio': 2.5876171596770184e-07}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:49,605] Trial 68 finished with value: 0.06486554423830242 and parameters: {'alpha': 864710.5469885414, 'l1_ratio': 7.727404032288482e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:49,719] Trial 69 finished with value: -0.009252045369155137 and parameters: {'alpha': 18447539.92531929, 'l1_ratio': 5.797581619137227e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:25:49,825] Trial 70 finished with value: 0.018568375371639873 and parameters: {'alpha': 4038915.663418039, 'l1_ratio': 2.5294989729395184e-09}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.416e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.734e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.812e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:12,278] Trial 27 finished with value: -2.509483538204112 and parameters: {'alpha': 7.764337450558945, 'l1_ratio': 3.5555661900260973e-09}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:12,789] Trial 29 finished with value: -1.4193516341799033 and parameters: {'alpha': 52.14749898866279, 'l1_ratio': 4.7320692284445394e-07}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:22,945] Trial 67 finished with value: -0.8980096909468468 and parameters: {'alpha': 879.5418822789796, 'l1_ratio': 6.311700371536794e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:24,372] Trial 74 finished with value: -0.034455324889440885 and parameters: {'alpha': 41184.03220793626, 'l1_ratio': 5.549512562578129e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:24,745] Trial 75 finished with value: 0.039488303572486706 and parameters: {'alpha': 183297.84088564367, 'l1_ratio': 1.302719609306635e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:25,029] Trial 76 finished with value: 0.061936775982102565 and parameters: {'alpha': 1013629.2364495056, 'l1_ratio': 9.431547268653654e-09}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.897e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:29,321] Trial 65 finished with value: -0.9658585566189066 and parameters: {'alpha': 695.6274060546805, 'l1_ratio': 5.391173179224762e-08}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.756e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:29,770] Trial 78 finished with value: 0.0628522986208756 and parameters: {'alpha': 969334.0318787053, 'l1_ratio': 7.2271119609223915e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:29,906] Trial 57 finished with value: -1.0594168357147604 and parameters: {'alpha': 472.34637298789823, 'l1_ratio': 3.092817145124805e-07}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:30,058] Trial 79 finished with value: 0.011464609478371357 and parameters: {'alpha': 5181076.057970047, 'l1_ratio': 8.385690825553886e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:30,355] Trial 80 finished with value: 0.018066119277764876 and parameters: {'alpha': 4105058.008264111, 'l1_ratio': 7.918573945244756e-09}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:31,975] Trial 55 finished with value: -0.8927149418235852 and parameters: {'alpha': 894.8690188710135, 'l1_ratio': 8.936454363257322e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:32,376] Trial 83 finished with value: 0.06393904448241639 and parameters: {'alpha': 392640.52047277085, 'l1_ratio': 2.5673065639711883e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:33,635] Trial 82 finished with value: -0.05219260802873497 and parameters: {'alpha': 29893.773856478118, 'l1_ratio': 2.389782041660644e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:34,117] Trial 81 finished with value: -0.08209855471301182 and parameters: {'alpha': 19446.734215514247, 'l1_ratio': 2.529189224937482e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:34,176] Trial 85 finished with value: 0.065288257183639 and parameters: {'alpha': 425715.7511623788, 'l1_ratio': 2.6601379784106353e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:34,382] Trial 87 finished with value: -0.011635918281038826 and parameters: {'alpha': 94192575.45325477, 'l1_ratio': 1.8485648615971826e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:34,736] Trial 88 finished with value: 0.06675781582660363 and parameters: {'alpha': 479467.37647240795, 'l1_ratio': 1.5574658080942172e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:35,049] Trial 86 finished with value: 0.01862053876158254 and parameters: {'alpha': 117337.17597302128, 'l1_ratio': 2.4827660692677166e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:35,199] Trial 84 finished with value: -0.06788886302574804 and parameters: {'alpha': 23431.551535483173, 'l1_ratio': 2.707067183749984e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:35,615] Trial 91 finished with value: 0.06762778057154828 and parameters: {'alpha': 543048.656183267, 'l1_ratio': 1.3853290464547367e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:35,641] Trial 90 finished with value: 0.06603014340316053 and parameters: {'alpha': 449239.7877540355, 'l1_ratio': 1.0319300058933572e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:35,756] Trial 89 finished with value: 0.01528527573150218 and parameters: {'alpha': 109716.96351144789, 'l1_ratio': 2.844999573370846e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:35,963] Trial 92 finished with value: -0.009397523390874038 and parameters: {'alpha': 18898384.801181067, 'l1_ratio': 1.275567093540612e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:36,118] Trial 94 finished with value: -0.011731681643030475 and parameters: {'alpha': 32340074.35130623, 'l1_ratio': 1.1471912745966101e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:36,328] Trial 95 finished with value: -0.009378037323975278 and parameters: {'alpha': 18846572.315855104, 'l1_ratio': 4.974771068946322e-10}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+00, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:36,567] Trial 96 finished with value: 0.01663931074431387 and parameters: {'alpha': 4307977.291933473, 'l1_ratio': 4.382126488283272e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:36,825] Trial 97 finished with value: 0.030130495553588005 and parameters: {'alpha': 2825870.845180258, 'l1_ratio': 1.0130512463857631e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:37,201] Trial 98 finished with value: 0.06751056380775496 and parameters: {'alpha': 529983.4996740213, 'l1_ratio': 3.0970066077256452e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:37,335] Trial 99 finished with value: 0.0650887442290415 and parameters: {'alpha': 420202.33648897667, 'l1_ratio': 1.5324575911184236e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:37,522] Trial 93 finished with value: -0.001707924848566041 and parameters: {'alpha': 78347.9837979197, 'l1_ratio': 1.4503953527293788e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:38,239] Trial 102 finished with value: 0.061860974130556134 and parameters: {'alpha': 354767.39900154603, 'l1_ratio': 7.386324973288934e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:38,586] Trial 100 finished with value: 0.006865262284968569 and parameters: {'alpha': 92797.306784771, 'l1_ratio': 1.6120938797388805e-09}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.959e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:38,831] Trial 62 finished with value: -1.049391892799418 and parameters: {'alpha': 494.961379065809, 'l1_ratio': 8.978955466229593e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:38,893] Trial 101 finished with value: 0.005424151545247151 and parameters: {'alpha': 90190.26576160216, 'l1_ratio': 1.5390822871764503e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:39,013] Trial 104 finished with value: 0.03351486961304784 and parameters: {'alpha': 2559336.906189516, 'l1_ratio': 3.789147023708102e-09}. Best is trial 53 with value: 0.06767113932168241.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+00, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:39,385] Trial 106 finished with value: 0.04011910370843145 and parameters: {'alpha': 2114373.3403137275, 'l1_ratio': 3.223441356873363e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:39,463] Trial 105 finished with value: 0.06725570483150851 and parameters: {'alpha': 508675.24039753695, 'l1_ratio': 3.1031795518280872e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:39,662] Trial 107 finished with value: 0.06765808915511118 and parameters: {'alpha': 547088.1518143243, 'l1_ratio': 9.497537323841918e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:39,701] Trial 103 finished with value: 0.005478138283521912 and parameters: {'alpha': 90287.27751999361, 'l1_ratio': 3.457661790303856e-09}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:40,010] Trial 108 finished with value: 0.06666825662806293 and parameters: {'alpha': 475146.3547236294, 'l1_ratio': 8.272929001276665e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:40,060] Trial 109 finished with value: 0.06689716407261097 and parameters: {'alpha': 486559.7726778324, 'l1_ratio': 4.412672779735502e-10}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:40,202] Trial 111 finished with value: -0.000471635992446003 and parameters: {'alpha': 8894420.316023191, 'l1_ratio': 1.7865752859315576e-08}. Best is trial 53 with value: 0.06767113932168241.\n",
      "[I 2023-06-16 17:26:40,338] Trial 110 finished with value: 0.0678263814712522 and parameters: {'alpha': 599317.8637732802, 'l1_ratio': 3.8775241987070284e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:40,697] Trial 113 finished with value: -0.0022392503507592623 and parameters: {'alpha': 9911468.726980723, 'l1_ratio': 6.769107124045889e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:41,138] Trial 116 finished with value: 0.04873390439254891 and parameters: {'alpha': 1637053.1015108114, 'l1_ratio': 1.0382383719910592e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:42,031] Trial 117 finished with value: 0.03814175248281145 and parameters: {'alpha': 177691.19930491838, 'l1_ratio': 3.9684315496280555e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:45,018] Trial 115 finished with value: -0.0956114276068016 and parameters: {'alpha': 16706.712266605788, 'l1_ratio': 4.1499182268311244e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:45,507] Trial 119 finished with value: 0.06656657149620615 and parameters: {'alpha': 758906.1470786157, 'l1_ratio': 7.935663519997779e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:46,201] Trial 112 finished with value: -0.1118245938511458 and parameters: {'alpha': 14283.702557122244, 'l1_ratio': 8.680488830998543e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:46,613] Trial 114 finished with value: -0.1502162227418399 and parameters: {'alpha': 10627.155721256808, 'l1_ratio': 9.006923550966896e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:47,816] Trial 122 finished with value: -0.03819220577713197 and parameters: {'alpha': 38374.147834434574, 'l1_ratio': 2.464123252132285e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:47,818] Trial 118 finished with value: -0.14577967094752578 and parameters: {'alpha': 10952.118323019566, 'l1_ratio': 4.578294870177946e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:48,092] Trial 121 finished with value: -0.047359414997742356 and parameters: {'alpha': 32481.10844469048, 'l1_ratio': 3.394251996248212e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:48,266] Trial 123 finished with value: 0.04664272400132711 and parameters: {'alpha': 1744936.812068307, 'l1_ratio': 1.683355359475674e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:48,466] Trial 125 finished with value: 0.045092424965616905 and parameters: {'alpha': 1827402.7902687523, 'l1_ratio': 5.046325081858409e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:48,921] Trial 124 finished with value: 0.04179998252501416 and parameters: {'alpha': 193524.6302036531, 'l1_ratio': 1.62435648018395e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:49,050] Trial 127 finished with value: 0.049314478703218256 and parameters: {'alpha': 234021.98959819553, 'l1_ratio': 2.2754446094838672e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:49,096] Trial 126 finished with value: 0.04258817725725328 and parameters: {'alpha': 197221.5204054985, 'l1_ratio': 4.914683548290025e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:49,432] Trial 128 finished with value: 0.06253537541689258 and parameters: {'alpha': 985177.5073855607, 'l1_ratio': 1.9210862138026075e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:49,480] Trial 129 finished with value: 0.06715820581992653 and parameters: {'alpha': 710548.3281190373, 'l1_ratio': 6.671302523744811e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:49,532] Trial 130 finished with value: 0.06546476451671239 and parameters: {'alpha': 829887.6115191537, 'l1_ratio': 1.4088105729022283e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:49,778] Trial 131 finished with value: 0.008221554007407983 and parameters: {'alpha': 5878675.96458963, 'l1_ratio': 1.7188105597046726e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:49,823] Trial 132 finished with value: 0.005443660724919567 and parameters: {'alpha': 6617099.271188067, 'l1_ratio': 1.6418863710172238e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:49,897] Trial 133 finished with value: -0.011699196056889663 and parameters: {'alpha': 31869833.01077611, 'l1_ratio': 1.0939602616997244e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:50,192] Trial 134 finished with value: 0.0022643079444099787 and parameters: {'alpha': 7698265.59568591, 'l1_ratio': 1.2054355604084467e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:50,222] Trial 135 finished with value: -0.011253999138743068 and parameters: {'alpha': 27235223.02189241, 'l1_ratio': 8.599539192070321e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:50,433] Trial 137 finished with value: -0.011343310839840415 and parameters: {'alpha': 109236312.54717831, 'l1_ratio': 7.782101903711364e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.705e+00, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:50,756] Trial 138 finished with value: 0.06780476579517958 and parameters: {'alpha': 578342.7747351122, 'l1_ratio': 5.558290435880668e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:50,971] Trial 139 finished with value: 0.06351852397421998 and parameters: {'alpha': 936427.0988440042, 'l1_ratio': 6.392108589712782e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:51,478] Trial 136 finished with value: -0.01603520973293678 and parameters: {'alpha': 59050.40733549429, 'l1_ratio': 8.843646855744148e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:51,486] Trial 140 finished with value: 0.06757983271686896 and parameters: {'alpha': 537141.8410067823, 'l1_ratio': 4.777111398381653e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:51,858] Trial 142 finished with value: 0.03062104941890072 and parameters: {'alpha': 2785361.703665338, 'l1_ratio': 4.134132486661924e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:52,351] Trial 144 finished with value: 0.06721653008962063 and parameters: {'alpha': 508088.80213886505, 'l1_ratio': 3.874231019631692e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:53,355] Trial 141 finished with value: -0.014262720205582799 and parameters: {'alpha': 61141.25299118953, 'l1_ratio': 3.7539450932598694e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:53,769] Trial 145 finished with value: 0.010069598429232532 and parameters: {'alpha': 98879.9585559893, 'l1_ratio': 1.9842289364417805e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:54,089] Trial 146 finished with value: 0.031280966137334776 and parameters: {'alpha': 152672.41663910224, 'l1_ratio': 3.2947817599243235e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:54,407] Trial 148 finished with value: 0.06634018270602911 and parameters: {'alpha': 462400.0579495597, 'l1_ratio': 4.61039570076985e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:54,436] Trial 147 finished with value: 0.04097216835750309 and parameters: {'alpha': 189794.94947692717, 'l1_ratio': 3.6481281334059254e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:54,648] Trial 149 finished with value: 0.030004774330175676 and parameters: {'alpha': 2807638.01768776, 'l1_ratio': 1.6687448635268412e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:54,775] Trial 150 finished with value: 0.027878290597069404 and parameters: {'alpha': 2980190.6341194706, 'l1_ratio': 2.1697162039937618e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:55,103] Trial 152 finished with value: 0.06575955526327182 and parameters: {'alpha': 812884.9246381801, 'l1_ratio': 5.303501362334781e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:55,444] Trial 153 finished with value: 0.06624910922817058 and parameters: {'alpha': 457423.6551833599, 'l1_ratio': 2.470363917850661e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.905e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:26:56,412] Trial 71 finished with value: -1.062841830869715 and parameters: {'alpha': 464.92824009529755, 'l1_ratio': 9.316795790697043e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:56,862] Trial 154 finished with value: -0.02769039089174456 and parameters: {'alpha': 46934.47364786738, 'l1_ratio': 2.4104504100533203e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:57,103] Trial 156 finished with value: -0.00916782114115274 and parameters: {'alpha': 18297690.209874492, 'l1_ratio': 1.3855881112166326e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:57,434] Trial 157 finished with value: 0.054950728036399665 and parameters: {'alpha': 1337226.4755052843, 'l1_ratio': 3.032826726086461e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:57,624] Trial 155 finished with value: -0.037574396691252475 and parameters: {'alpha': 38775.628419734305, 'l1_ratio': 4.5945790597391227e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:57,911] Trial 158 finished with value: 0.061762084454942134 and parameters: {'alpha': 353219.6828258103, 'l1_ratio': 6.512037135931436e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:26:58,121] Trial 159 finished with value: 0.06472674857944194 and parameters: {'alpha': 410786.8230522124, 'l1_ratio': 6.628503250172049e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.073e+00, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:27:11,034] Trial 120 finished with value: -0.4950352118702635 and parameters: {'alpha': 2766.2243273240956, 'l1_ratio': 2.0804039911099607e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:11,457] Trial 162 finished with value: 0.0678027470673765 and parameters: {'alpha': 577439.9944748996, 'l1_ratio': 3.1685169435544045e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:11,608] Trial 163 finished with value: 0.013469461490132914 and parameters: {'alpha': 4814884.852068984, 'l1_ratio': 3.0160319304266153e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:12,419] Trial 164 finished with value: 0.03875188398138122 and parameters: {'alpha': 180194.22917291918, 'l1_ratio': 1.6215344789500137e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:12,821] Trial 165 finished with value: 0.054235279935850866 and parameters: {'alpha': 1370723.3984508764, 'l1_ratio': 3.457803974801478e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:13,089] Trial 166 finished with value: -0.004937071126575747 and parameters: {'alpha': 11969853.87633486, 'l1_ratio': 2.13047384354787e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:13,277] Trial 167 finished with value: 0.06773802635952912 and parameters: {'alpha': 634644.1260521812, 'l1_ratio': 5.476312023070929e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:13,577] Trial 168 finished with value: 0.06701205047376646 and parameters: {'alpha': 723341.2504829386, 'l1_ratio': 4.21632135150925e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:13,864] Trial 169 finished with value: 0.06684030568206482 and parameters: {'alpha': 737568.3537621393, 'l1_ratio': 5.1697715897632405e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:14,059] Trial 170 finished with value: 0.044384441396601394 and parameters: {'alpha': 1865610.8838829924, 'l1_ratio': 1.1103362308501784e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:14,781] Trial 171 finished with value: 0.019796676385155032 and parameters: {'alpha': 120169.59933202369, 'l1_ratio': 7.067243321674375e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:14,970] Trial 172 finished with value: 0.018619395657449116 and parameters: {'alpha': 4032548.6970633073, 'l1_ratio': 1.0712626974333726e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:15,148] Trial 173 finished with value: 0.0676990994901681 and parameters: {'alpha': 633065.2836313889, 'l1_ratio': 5.370722181208249e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.217e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:27:15,414] Trial 73 finished with value: -0.9431159668735857 and parameters: {'alpha': 755.0014995742251, 'l1_ratio': 9.575103451738729e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:15,951] Trial 175 finished with value: 0.0381744655522119 and parameters: {'alpha': 177841.74167629486, 'l1_ratio': 2.030400213227682e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:16,110] Trial 176 finished with value: 0.05671934762068587 and parameters: {'alpha': 1247955.1466424481, 'l1_ratio': 1.2269709993578897e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:16,225] Trial 177 finished with value: -0.0096251742061364 and parameters: {'alpha': 818207016.0175997, 'l1_ratio': 3.153495824870658e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:16,637] Trial 178 finished with value: 0.06738170941147592 and parameters: {'alpha': 524223.4489258384, 'l1_ratio': 8.229080724887438e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:16,993] Trial 179 finished with value: 0.06609626948702026 and parameters: {'alpha': 453689.0823968691, 'l1_ratio': 7.072881892675845e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:17,646] Trial 180 finished with value: -0.0050926533649281085 and parameters: {'alpha': 73295.06929985798, 'l1_ratio': 3.1336117505716704e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.962e+00, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:27:17,883] Trial 181 finished with value: 0.04819089455760713 and parameters: {'alpha': 1654607.8544970243, 'l1_ratio': 1.231890700809752e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:18,270] Trial 182 finished with value: 0.05304899840624958 and parameters: {'alpha': 260236.0930680423, 'l1_ratio': 5.4062621446676995e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:20,470] Trial 183 finished with value: -0.06314772536992282 and parameters: {'alpha': 25107.560805724497, 'l1_ratio': 4.405461073494361e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:22,736] Trial 151 finished with value: -0.5422579400127361 and parameters: {'alpha': 2423.083888508279, 'l1_ratio': 2.848209432781207e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:22,961] Trial 185 finished with value: 0.006188575629748024 and parameters: {'alpha': 6372294.171718905, 'l1_ratio': 7.704592855554015e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:23,378] Trial 160 finished with value: -0.4583543150513079 and parameters: {'alpha': 3075.1270118720067, 'l1_ratio': 2.983303905197378e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:23,519] Trial 187 finished with value: -0.00925366310666198 and parameters: {'alpha': 6199485668.11139, 'l1_ratio': 1.1446744206043035e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:23,782] Trial 188 finished with value: 0.06704430991620595 and parameters: {'alpha': 718815.0061107292, 'l1_ratio': 2.3128994891454332e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:23,926] Trial 189 finished with value: 0.06499402488703121 and parameters: {'alpha': 854994.3614356531, 'l1_ratio': 4.926780015482536e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:24,068] Trial 190 finished with value: 0.032925997583604184 and parameters: {'alpha': 2601210.77716829, 'l1_ratio': 1.903841174925748e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:24,387] Trial 191 finished with value: 0.04655476000905571 and parameters: {'alpha': 217642.19819997228, 'l1_ratio': 6.192907355211124e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:24,564] Trial 192 finished with value: 0.06774181491062851 and parameters: {'alpha': 626005.0694629103, 'l1_ratio': 3.61092126478329e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:25,231] Trial 193 finished with value: 0.005870480715862454 and parameters: {'alpha': 91003.38631688865, 'l1_ratio': 3.398172430658155e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:25,414] Trial 194 finished with value: 0.06715926339601042 and parameters: {'alpha': 513200.8624606458, 'l1_ratio': 1.900064174500691e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:25,514] Trial 143 finished with value: -0.5609011574664348 and parameters: {'alpha': 2301.598545037263, 'l1_ratio': 3.6030353436119175e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:25,842] Trial 195 finished with value: 0.055539066809278115 and parameters: {'alpha': 281621.6712751901, 'l1_ratio': 2.0976271214515136e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:26,001] Trial 196 finished with value: 0.055474140044195853 and parameters: {'alpha': 282005.9668948561, 'l1_ratio': 4.3454409311270996e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:26,147] Trial 197 finished with value: 0.04156672260589467 and parameters: {'alpha': 2015440.3796563426, 'l1_ratio': 1.1557438408974711e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:26,395] Trial 198 finished with value: 0.0627775642438183 and parameters: {'alpha': 967036.0022311005, 'l1_ratio': 1.1099203752423271e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:26,598] Trial 161 finished with value: -0.48317710968910316 and parameters: {'alpha': 2861.575226420516, 'l1_ratio': 3.4187988655730276e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:26,884] Trial 200 finished with value: 0.06743955248946583 and parameters: {'alpha': 674206.6250163533, 'l1_ratio': 6.15494629012638e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:27,098] Trial 202 finished with value: 0.014808796199520025 and parameters: {'alpha': 4525130.133135612, 'l1_ratio': 2.1955233041990405e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:28,073] Trial 203 finished with value: 0.007357871525452124 and parameters: {'alpha': 93735.11126001239, 'l1_ratio': 6.005685669585113e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:27:28,436] Trial 204 finished with value: 0.06748480871888733 and parameters: {'alpha': 633445.2289809921, 'l1_ratio': 2.738683089925891e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:27:30,602] Trial 72 finished with value: -1.120893135009286 and parameters: {'alpha': 342.0001834229945, 'l1_ratio': 1.0502037513364131e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:27:45,315] Trial 77 finished with value: -1.1892095211668674 and parameters: {'alpha': 213.34166379981917, 'l1_ratio': 8.160732678051974e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.650e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.176e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.653e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.275e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.297e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:20,678] Trial 174 finished with value: -2.205071679466721 and parameters: {'alpha': 12.15705081906422, 'l1_ratio': 1.1624960738824916e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:20,864] Trial 208 finished with value: 0.06723164218051303 and parameters: {'alpha': 670498.0867746955, 'l1_ratio': 3.018020975718935e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:21,083] Trial 209 finished with value: 0.06621136694866418 and parameters: {'alpha': 489430.040703538, 'l1_ratio': 9.168226620172437e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:21,403] Trial 210 finished with value: 0.032878972870139335 and parameters: {'alpha': 2580037.8444950357, 'l1_ratio': 1.8400106140079015e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:21,894] Trial 211 finished with value: 0.025202077329751882 and parameters: {'alpha': 134448.3581768853, 'l1_ratio': 4.337572421765396e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:22,050] Trial 212 finished with value: 0.06750190252652825 and parameters: {'alpha': 535945.7162820316, 'l1_ratio': 7.874785349613532e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.885e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:26,411] Trial 186 finished with value: -1.2857689183117536 and parameters: {'alpha': 97.68582686895842, 'l1_ratio': 2.64157238882428e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:26,825] Trial 214 finished with value: 0.05613737453175749 and parameters: {'alpha': 286576.5904894714, 'l1_ratio': 7.940880599559963e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:27,111] Trial 215 finished with value: 0.04903260118881162 and parameters: {'alpha': 1599736.4825900013, 'l1_ratio': 2.823393386516255e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+00, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:28,749] Trial 216 finished with value: -0.030615174152583784 and parameters: {'alpha': 44340.96133534032, 'l1_ratio': 4.6151828577015116e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:29,071] Trial 217 finished with value: 0.06754843568481798 and parameters: {'alpha': 552106.1258728373, 'l1_ratio': 1.600065448315619e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:29,428] Trial 218 finished with value: 0.06716305176974213 and parameters: {'alpha': 511495.11972161056, 'l1_ratio': 1.5765874186799948e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:30,089] Trial 219 finished with value: 0.035349988719423076 and parameters: {'alpha': 166905.6266337048, 'l1_ratio': 6.959697814102587e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:31,530] Trial 201 finished with value: -1.322908746371077 and parameters: {'alpha': 78.09498398796688, 'l1_ratio': 6.462177677291316e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:31,681] Trial 221 finished with value: 0.05598254986558038 and parameters: {'alpha': 1279450.05241847, 'l1_ratio': 1.5789432055631167e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:31,888] Trial 222 finished with value: 0.06627025405276506 and parameters: {'alpha': 479592.92312451365, 'l1_ratio': 6.175784809780895e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:34,021] Trial 213 finished with value: -3.995476640182349 and parameters: {'alpha': 0.013238732959267268, 'l1_ratio': 7.525299460125741e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.861e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:34,288] Trial 224 finished with value: -0.005498260369548887 and parameters: {'alpha': 12485946.03433944, 'l1_ratio': 3.555925787836075e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:34,387] Trial 206 finished with value: -2.056786421069551 and parameters: {'alpha': 15.06812421235206, 'l1_ratio': 6.604943700271491e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:34,632] Trial 225 finished with value: 0.020746588801133486 and parameters: {'alpha': 3686401.8601259515, 'l1_ratio': 3.095068575180794e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:34,719] Trial 226 finished with value: 0.025755474564641483 and parameters: {'alpha': 3161655.725191979, 'l1_ratio': 2.84931222937172e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:35,041] Trial 227 finished with value: 0.06322369248224617 and parameters: {'alpha': 943992.5251693347, 'l1_ratio': 1.2675401972905927e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:35,127] Trial 228 finished with value: 0.06769686436414861 and parameters: {'alpha': 611066.6996702123, 'l1_ratio': 1.256599151454819e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:35,394] Trial 229 finished with value: 0.06049946090792113 and parameters: {'alpha': 336324.47128644603, 'l1_ratio': 1.63889375472706e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:35,549] Trial 230 finished with value: 0.05035739541059022 and parameters: {'alpha': 244109.96921430138, 'l1_ratio': 1.265840647845973e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:35,754] Trial 232 finished with value: 0.06435606684759314 and parameters: {'alpha': 886782.9428398558, 'l1_ratio': 1.0439995411018551e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:36,236] Trial 231 finished with value: 0.025213069410493356 and parameters: {'alpha': 134320.02491177554, 'l1_ratio': 4.141758294034948e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:36,330] Trial 233 finished with value: 0.005573295763270554 and parameters: {'alpha': 90496.12749360745, 'l1_ratio': 9.840682890136614e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:36,574] Trial 234 finished with value: 0.05283613973776639 and parameters: {'alpha': 1429454.7620133553, 'l1_ratio': 1.0085049395429716e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:36,657] Trial 235 finished with value: 0.04285559288121247 and parameters: {'alpha': 1698448.9757080514, 'l1_ratio': 3.0087934836996497e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:37,033] Trial 237 finished with value: 0.06345733481983007 and parameters: {'alpha': 588981.8414939536, 'l1_ratio': 5.427898907860946e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:37,105] Trial 236 finished with value: 0.06689390335033236 and parameters: {'alpha': 487383.3461646729, 'l1_ratio': 2.2751533138041708e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:37,338] Trial 238 finished with value: 0.06531312643067884 and parameters: {'alpha': 431028.71442495397, 'l1_ratio': 2.0934037845388723e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:37,534] Trial 239 finished with value: 0.061651767030180195 and parameters: {'alpha': 353300.06317801296, 'l1_ratio': 1.7147722436820606e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.840e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:37,717] Trial 240 finished with value: 0.051242599174389 and parameters: {'alpha': 247306.96835433858, 'l1_ratio': 1.6671762290801943e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:37,869] Trial 184 finished with value: -1.2439018590588569 and parameters: {'alpha': 134.45445697739297, 'l1_ratio': 1.9114015722388086e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:38,175] Trial 243 finished with value: 0.06536752804548755 and parameters: {'alpha': 833456.9134957303, 'l1_ratio': 4.908521736604153e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:38,614] Trial 242 finished with value: -0.02134734600064514 and parameters: {'alpha': 53198.86790197605, 'l1_ratio': 3.718272766723699e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:38,859] Trial 245 finished with value: 0.006664388026633161 and parameters: {'alpha': 6264749.575020804, 'l1_ratio': 3.4547138035734675e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:38,974] Trial 244 finished with value: -0.010268640469267898 and parameters: {'alpha': 66235.34088085653, 'l1_ratio': 3.4312003378426646e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:39,121] Trial 246 finished with value: 0.04459366201433427 and parameters: {'alpha': 1801893.6593521251, 'l1_ratio': 5.879398126628186e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:39,250] Trial 247 finished with value: 0.03928612639754062 and parameters: {'alpha': 2095338.3739763566, 'l1_ratio': 6.438476929999128e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:39,555] Trial 248 finished with value: 0.06763625448616406 and parameters: {'alpha': 654736.117990165, 'l1_ratio': 1.1864309478860358e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:39,712] Trial 249 finished with value: 0.06754337797408543 and parameters: {'alpha': 533176.1031582454, 'l1_ratio': 9.773495295023906e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:39,990] Trial 250 finished with value: 0.06779154264611753 and parameters: {'alpha': 620861.6227154414, 'l1_ratio': 9.547490503071807e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:40,944] Trial 252 finished with value: 0.029509313669957054 and parameters: {'alpha': 146972.26313093206, 'l1_ratio': 1.2364819128128617e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.294e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:41,286] Trial 199 finished with value: -2.386777295269801 and parameters: {'alpha': 9.344140281529953, 'l1_ratio': 2.480201803604814e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:41,288] Trial 253 finished with value: 0.06526006638258612 and parameters: {'alpha': 842689.2443400456, 'l1_ratio': 1.7657565680146343e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:41,435] Trial 241 finished with value: -2.521012105618737 and parameters: {'alpha': 4.217237838333156e-06, 'l1_ratio': 4.929311562604655e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:41,985] Trial 256 finished with value: 0.05616639502708428 and parameters: {'alpha': 286487.7113745644, 'l1_ratio': 9.312692164009505e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:42,049] Trial 255 finished with value: 0.03950327176777069 and parameters: {'alpha': 183349.80691194627, 'l1_ratio': 1.1135858212263863e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:42,109] Trial 254 finished with value: 0.03974564397488715 and parameters: {'alpha': 184384.8881111329, 'l1_ratio': 9.619772928502716e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:42,371] Trial 257 finished with value: 0.05447990440038367 and parameters: {'alpha': 1359287.473625865, 'l1_ratio': 6.620169692770935e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:42,415] Trial 258 finished with value: 0.025043745142014944 and parameters: {'alpha': 3290565.5442835903, 'l1_ratio': 7.632449421408804e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:42,551] Trial 259 finished with value: 0.05550796530396651 and parameters: {'alpha': 1311594.1546707656, 'l1_ratio': 4.68887872267313e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:42,708] Trial 260 finished with value: 0.012800221330007392 and parameters: {'alpha': 4932833.695975525, 'l1_ratio': 1.8222885401450753e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:42,775] Trial 261 finished with value: 0.0012154546008110723 and parameters: {'alpha': 8123689.787645973, 'l1_ratio': 1.949584435113452e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:43,106] Trial 264 finished with value: 0.014852741457029084 and parameters: {'alpha': 632353.4652789509, 'l1_ratio': 0.00012692884396304244}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:43,184] Trial 263 finished with value: 0.06774087483612168 and parameters: {'alpha': 561142.7784619917, 'l1_ratio': 2.2719579960011453e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:45,766] Trial 265 finished with value: -0.047043522527560055 and parameters: {'alpha': 32665.100266508136, 'l1_ratio': 2.6171207024746092e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:46,499] Trial 267 finished with value: 0.015769379800835665 and parameters: {'alpha': 110787.95970515777, 'l1_ratio': 1.5412497015729835e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:48,246] Trial 207 finished with value: -1.3531876272624346 and parameters: {'alpha': 67.32333622364104, 'l1_ratio': 3.133341471384085e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:48,430] Trial 269 finished with value: 0.06461815577237547 and parameters: {'alpha': 878584.9573385043, 'l1_ratio': 3.611514920355676e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:28:49,210] Trial 205 finished with value: -1.1936936088140095 and parameters: {'alpha': 205.75461313598447, 'l1_ratio': 8.301969526023858e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:49,678] Trial 271 finished with value: 0.034354959678820074 and parameters: {'alpha': 2498214.7968076775, 'l1_ratio': 5.355055410753562e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:53,301] Trial 220 finished with value: -4.020301925183382 and parameters: {'alpha': 0.014113948235209131, 'l1_ratio': 1.462860675274286e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:53,745] Trial 273 finished with value: 0.05997954457463606 and parameters: {'alpha': 328139.2454171649, 'l1_ratio': 5.336116057519028e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:54,132] Trial 274 finished with value: -0.010734881007073982 and parameters: {'alpha': 189880370.42149237, 'l1_ratio': 1.32282767765634e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:54,439] Trial 268 finished with value: -0.14561478455909269 and parameters: {'alpha': 10964.467400864774, 'l1_ratio': 3.6783655060341157e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:54,581] Trial 275 finished with value: 0.0511378317390608 and parameters: {'alpha': 891334.7976860972, 'l1_ratio': 1.3884015198992622e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:28:55,053] Trial 276 finished with value: 0.027327985730783582 and parameters: {'alpha': 140363.57327569436, 'l1_ratio': 1.7326648924758365e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.227e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.137e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.949e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.748e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:29:14,332] Trial 223 finished with value: -4.653994723081402 and parameters: {'alpha': 0.026964817346022785, 'l1_ratio': 2.876232113449911e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:14,516] Trial 279 finished with value: -0.010830839637583245 and parameters: {'alpha': 24415192.9277682, 'l1_ratio': 5.259172264898741e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:15,183] Trial 280 finished with value: 0.06087897608658236 and parameters: {'alpha': 340168.01902166166, 'l1_ratio': 2.091474792192542e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.376e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.287e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.273e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.056e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.216e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.965e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:29:43,251] Trial 251 finished with value: -2.941302403658604 and parameters: {'alpha': 1.342580361473922, 'l1_ratio': 9.72572960253709e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:43,426] Trial 282 finished with value: 0.035932259295867186 and parameters: {'alpha': 2385474.913818307, 'l1_ratio': 1.0540738015311274e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:44,275] Trial 283 finished with value: -0.005944530557091099 and parameters: {'alpha': 72064.62786929602, 'l1_ratio': 2.006563711905637e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:44,485] Trial 284 finished with value: -0.009217972097849803 and parameters: {'alpha': 42649783.008475445, 'l1_ratio': 0.36244926169513914}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:44,734] Trial 285 finished with value: -3.8565095310430473 and parameters: {'alpha': 7.073801349589109e-10, 'l1_ratio': 2.5464441252786525e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:44,893] Trial 286 finished with value: -0.00925808569102767 and parameters: {'alpha': 7923934833.178809, 'l1_ratio': 2.222179554924932e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.925e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:29:48,108] Trial 262 finished with value: -2.96666313131891 and parameters: {'alpha': 2.444271093534483, 'l1_ratio': 1.9656334619372434e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:48,383] Trial 288 finished with value: -0.009217972097849803 and parameters: {'alpha': 1721436635.0764902, 'l1_ratio': 1.9471128191551082e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:48,770] Trial 289 finished with value: 0.06749411490038111 and parameters: {'alpha': 674790.7020201513, 'l1_ratio': 3.4851742913438127e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:49,055] Trial 290 finished with value: 0.000415710194904569 and parameters: {'alpha': 8480810.057434924, 'l1_ratio': 3.7775612136548766e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:29:49,368] Trial 270 finished with value: -2.906876927587524 and parameters: {'alpha': 3.409338439211469, 'l1_ratio': 4.956006136186592e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.699e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:29:51,006] Trial 266 finished with value: -2.3072048082820835 and parameters: {'alpha': 0.48173428181871525, 'l1_ratio': 1.2391521904161525e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:51,187] Trial 291 finished with value: -0.055134100081222916 and parameters: {'alpha': 28470.85581740185, 'l1_ratio': 6.953613101621128e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:53,788] Trial 292 finished with value: -0.07809410734638977 and parameters: {'alpha': 20433.78669476278, 'l1_ratio': 1.3130462774193538e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:54,656] Trial 294 finished with value: 0.05125205592076543 and parameters: {'alpha': 246881.9239628452, 'l1_ratio': 3.583716955251674e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:55,244] Trial 295 finished with value: 0.04972367987756284 and parameters: {'alpha': 236631.9769906314, 'l1_ratio': 1.9789169586888396e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:55,371] Trial 296 finished with value: 0.05577006246650192 and parameters: {'alpha': 1299507.4566651813, 'l1_ratio': 2.1313654541956885e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:55,774] Trial 297 finished with value: 0.05188722051282298 and parameters: {'alpha': 1477145.9115172857, 'l1_ratio': 6.537442607262923e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:55,849] Trial 298 finished with value: 0.06775034581243906 and parameters: {'alpha': 577805.6670515595, 'l1_ratio': 5.802035668524767e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:56,059] Trial 299 finished with value: 0.023441759463068812 and parameters: {'alpha': 3456968.780107164, 'l1_ratio': 5.459801556364923e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:56,188] Trial 300 finished with value: 0.012081509721192226 and parameters: {'alpha': 5060928.711052036, 'l1_ratio': 1.4289604091212556e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:56,643] Trial 302 finished with value: 0.06778130649800351 and parameters: {'alpha': 595576.5978089237, 'l1_ratio': 4.874100987646402e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.912e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:29:56,945] Trial 278 finished with value: -2.1259741143170707 and parameters: {'alpha': 0.3049903552834001, 'l1_ratio': 2.5168802342866746e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:57,714] Trial 303 finished with value: 0.009407951778563314 and parameters: {'alpha': 97612.80518097788, 'l1_ratio': 4.3381037335285345e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:57,893] Trial 305 finished with value: 0.0670648870593858 and parameters: {'alpha': 716057.7753692212, 'l1_ratio': 3.3278031535115707e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:57,960] Trial 304 finished with value: -0.0021335894559217916 and parameters: {'alpha': 77702.16867992489, 'l1_ratio': 3.104753100980762e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:57,963] Trial 293 finished with value: -0.08962784659522512 and parameters: {'alpha': 17820.485637469952, 'l1_ratio': 5.063805069176989e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.899e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:29:58,269] Trial 307 finished with value: -0.011968741685072448 and parameters: {'alpha': 65540066.420595214, 'l1_ratio': 5.6737956070154916e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:58,364] Trial 277 finished with value: -2.9393004344805855 and parameters: {'alpha': 1.3237145767543965, 'l1_ratio': 2.2038792130934996e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:58,439] Trial 306 finished with value: 0.062363604921894 and parameters: {'alpha': 363540.73825950746, 'l1_ratio': 5.158344518631049e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:58,500] Trial 308 finished with value: 0.062258881046092375 and parameters: {'alpha': 362010.9396738923, 'l1_ratio': 7.17476830197874e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:58,837] Trial 309 finished with value: 0.06140575906281535 and parameters: {'alpha': 347797.84493475803, 'l1_ratio': 8.844162741332882e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:58,848] Trial 310 finished with value: 0.06307900359625562 and parameters: {'alpha': 375817.4307600472, 'l1_ratio': 2.0630327446757743e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:58,891] Trial 311 finished with value: 0.043531707973517055 and parameters: {'alpha': 1914163.7882998495, 'l1_ratio': 8.661727382028572e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:58,938] Trial 312 finished with value: 0.0504801934384882 and parameters: {'alpha': 1548719.0418188497, 'l1_ratio': 1.9506971008359816e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:59,374] Trial 315 finished with value: -0.0065857992675054655 and parameters: {'alpha': 13753034.284720616, 'l1_ratio': 2.4943063423998167e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:59,442] Trial 314 finished with value: 0.04788089869925779 and parameters: {'alpha': 1680570.9907604298, 'l1_ratio': 2.5830626624733493e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:59,474] Trial 313 finished with value: 0.0449052820896468 and parameters: {'alpha': 1838042.732276064, 'l1_ratio': 2.801443518647529e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:29:59,586] Trial 316 finished with value: 0.06123407254126038 and parameters: {'alpha': 1047529.3314960406, 'l1_ratio': 3.8785517025037256e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:00,039] Trial 318 finished with value: 0.027972959858348617 and parameters: {'alpha': 142342.4191674071, 'l1_ratio': 1.1445037670197178e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:00,305] Trial 321 finished with value: 0.009591557642149287 and parameters: {'alpha': 5566683.019125372, 'l1_ratio': 1.2660858978066957e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:00,454] Trial 320 finished with value: 0.026098724511859277 and parameters: {'alpha': 136790.48252666954, 'l1_ratio': 7.277003342492471e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:00,607] Trial 319 finished with value: 0.009400479685411689 and parameters: {'alpha': 97579.2895147157, 'l1_ratio': 7.583646250059434e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:00,816] Trial 323 finished with value: 0.0659898016920774 and parameters: {'alpha': 791643.0509595677, 'l1_ratio': 1.0079674720149622e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:00,960] Trial 324 finished with value: 0.0661812284605835 and parameters: {'alpha': 779581.2032598702, 'l1_ratio': 9.04882045186844e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.753e-02, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:03,280] Trial 326 finished with value: -1.0457939007251043 and parameters: {'alpha': 6.076493834930072e-05, 'l1_ratio': 3.0770683220693534e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:03,616] Trial 272 finished with value: -2.9530121248178696 and parameters: {'alpha': 2.8049784819902928, 'l1_ratio': 3.732603466849644e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.866e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:04,712] Trial 327 finished with value: -0.01447482353917077 and parameters: {'alpha': 60885.502908024435, 'l1_ratio': 1.1302144962090405e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:04,867] Trial 329 finished with value: 0.02729459656321061 and parameters: {'alpha': 3064892.121859428, 'l1_ratio': 4.6937595232294405e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.073e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.587e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.283e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.478e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.859e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.506e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:25,954] Trial 281 finished with value: -2.8172848464718965 and parameters: {'alpha': 0.9337125445118432, 'l1_ratio': 2.166361712212602e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:26,150] Trial 331 finished with value: -0.010065809556867089 and parameters: {'alpha': 377001360.1679699, 'l1_ratio': 1.3655719258890627e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.142e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:26,993] Trial 332 finished with value: 0.04420842955744934 and parameters: {'alpha': 205166.036990059, 'l1_ratio': 5.274989673368576e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:27,341] Trial 333 finished with value: 0.06772441423516821 and parameters: {'alpha': 638833.7612499618, 'l1_ratio': 1.0260489309440783e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:27,689] Trial 334 finished with value: 0.06779857336800184 and parameters: {'alpha': 575800.2759656967, 'l1_ratio': 1.0958191912869091e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:27,969] Trial 335 finished with value: 0.004738513232801426 and parameters: {'alpha': 6840336.398040811, 'l1_ratio': 2.1902368778109954e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:30,557] Trial 336 finished with value: -3.0573084196422715 and parameters: {'alpha': 0.0025323896740039363, 'l1_ratio': 1.6452419664218067e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:30,686] Trial 337 finished with value: -0.009377325043385213 and parameters: {'alpha': 18845158.27720907, 'l1_ratio': 1.4856069705863096e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.972e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.805e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:39,859] Trial 338 finished with value: -0.22526513023480754 and parameters: {'alpha': 7023.18246146598, 'l1_ratio': 4.770766144249188e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:41,150] Trial 339 finished with value: -0.03738561422404244 and parameters: {'alpha': 38959.70060212014, 'l1_ratio': 1.341271805454168e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:41,346] Trial 340 finished with value: 0.06744931892083927 and parameters: {'alpha': 680268.4072073847, 'l1_ratio': 1.2268427479788256e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:41,747] Trial 341 finished with value: 0.04711964859490373 and parameters: {'alpha': 220822.0705102817, 'l1_ratio': 1.1315157906933152e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:42,015] Trial 342 finished with value: 0.024720980205670113 and parameters: {'alpha': 3323209.40231815, 'l1_ratio': 8.011694108441186e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:42,239] Trial 343 finished with value: 0.06706028859380464 and parameters: {'alpha': 495769.506911523, 'l1_ratio': 1.817219411378208e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.803e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.791e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:44,366] Trial 287 finished with value: -2.271378086814556 and parameters: {'alpha': 0.19895411573178048, 'l1_ratio': 3.2946718114190273e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:44,730] Trial 345 finished with value: 0.03785038092882753 and parameters: {'alpha': 177450.55477726145, 'l1_ratio': 9.944313167925213e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:45,000] Trial 346 finished with value: 0.058494925003515975 and parameters: {'alpha': 1174388.164265057, 'l1_ratio': 5.810926497810038e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:45,182] Trial 347 finished with value: 0.0268697582140676 and parameters: {'alpha': 3113270.2923070192, 'l1_ratio': 1.5470817148556221e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:45,456] Trial 348 finished with value: -0.011443369787502192 and parameters: {'alpha': 109493757.970298, 'l1_ratio': 3.051158242631867e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.427e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:47,984] Trial 349 finished with value: -0.02218686269643544 and parameters: {'alpha': 52283.6021634073, 'l1_ratio': 1.0887736118790796e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:48,479] Trial 350 finished with value: 0.06674926761567727 and parameters: {'alpha': 479020.8031012442, 'l1_ratio': 8.391464922963808e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:48,840] Trial 351 finished with value: 0.06251171335026107 and parameters: {'alpha': 986198.0850947632, 'l1_ratio': 4.072107627749521e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:49,722] Trial 352 finished with value: 0.04250552359550186 and parameters: {'alpha': 196825.17611653786, 'l1_ratio': 4.061165111741587e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:49,938] Trial 353 finished with value: 0.004267501841302017 and parameters: {'alpha': 6990220.248947232, 'l1_ratio': 1.0343768784747256e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:50,326] Trial 354 finished with value: 0.04363509602935319 and parameters: {'alpha': 1471494.7606361124, 'l1_ratio': 6.002334811199131e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:50,950] Trial 355 finished with value: 0.06614674706710166 and parameters: {'alpha': 453512.1250594993, 'l1_ratio': 1.3301222265078488e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:51,341] Trial 356 finished with value: -0.009217972097849803 and parameters: {'alpha': 994258350.6587552, 'l1_ratio': 2.5247517272409677e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:52,086] Trial 357 finished with value: 0.002682976528344113 and parameters: {'alpha': 85443.26925763738, 'l1_ratio': 1.4643188416314976e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:52,213] Trial 358 finished with value: -0.006272942676783096 and parameters: {'alpha': 13370511.777252307, 'l1_ratio': 1.9878406060777788e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:52,430] Trial 359 finished with value: -0.014202463370378485 and parameters: {'alpha': 235037.3229085176, 'l1_ratio': 0.0010607486617832363}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.742e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:30:57,803] Trial 317 finished with value: -2.7061523645716186 and parameters: {'alpha': 0.12788897547893, 'l1_ratio': 7.4393968351017695e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:57,956] Trial 360 finished with value: -0.10148130352149227 and parameters: {'alpha': 15740.381439352035, 'l1_ratio': 7.709864568488483e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:30:58,198] Trial 361 finished with value: 0.029861300233720505 and parameters: {'alpha': 2848262.412274337, 'l1_ratio': 6.975931291953457e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.231e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:31:00,258] Trial 328 finished with value: -0.9757832329417666 and parameters: {'alpha': 670.4498344027675, 'l1_ratio': 1.2248579086671447e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.662e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.056e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:31:02,768] Trial 325 finished with value: -1.5546271480109182 and parameters: {'alpha': 35.994545362433996, 'l1_ratio': 1.2699778970407489e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.523e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:31:03,835] Trial 330 finished with value: -3.015016805584427 and parameters: {'alpha': 0.09292776366412371, 'l1_ratio': 6.60681445940684e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:04,054] Trial 366 finished with value: 0.06043884659487094 and parameters: {'alpha': 901839.2299908533, 'l1_ratio': 3.3807305757386036e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.848e-01, tolerance: 1.853e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:31:04,262] Trial 301 finished with value: -1.6571260901920233 and parameters: {'alpha': 28.990360498459175, 'l1_ratio': 4.364577837434549e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:04,314] Trial 322 finished with value: -2.5547493174474365 and parameters: {'alpha': 0.1477600181755086, 'l1_ratio': 7.3586656325096275e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:04,351] Trial 367 finished with value: 0.06369336263617487 and parameters: {'alpha': 387546.1121396005, 'l1_ratio': 3.0688396317800494e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:05,322] Trial 370 finished with value: 0.01948067508666551 and parameters: {'alpha': 119397.93477666793, 'l1_ratio': 2.726367993345145e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:14,234] Trial 368 finished with value: -0.24741134911746107 and parameters: {'alpha': 6359.874724963126, 'l1_ratio': 3.5196983180264684e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:14,371] Trial 372 finished with value: -0.00930671069659413 and parameters: {'alpha': 2663404229.7908964, 'l1_ratio': 1.6845533138913328e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:14,696] Trial 373 finished with value: 0.03911083239600729 and parameters: {'alpha': 2177384.207190837, 'l1_ratio': 1.0237576657744676e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:14,877] Trial 374 finished with value: 0.06633662517506933 and parameters: {'alpha': 766830.2247733752, 'l1_ratio': 1.1802464137671504e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:14,892] Trial 365 finished with value: -0.3289637820932618 and parameters: {'alpha': 4638.637145121217, 'l1_ratio': 2.8354753917267835e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:18,448] Trial 376 finished with value: -3.9095951653776946 and parameters: {'alpha': 1.852065199024821e-07, 'l1_ratio': 2.2555647036106583e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:18,857] Trial 377 finished with value: 0.04813483878548278 and parameters: {'alpha': 256088.68384432024, 'l1_ratio': 1.2494126737313972e-05}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.278e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+00, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:31:21,513] Trial 378 finished with value: -0.03763626142808781 and parameters: {'alpha': 38776.56013365861, 'l1_ratio': 4.560389023911153e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:21,705] Trial 379 finished with value: 0.048348241391149384 and parameters: {'alpha': 1656308.3071579973, 'l1_ratio': 4.728138140115664e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:21,904] Trial 380 finished with value: -0.009217972097849803 and parameters: {'alpha': 524607349.69021016, 'l1_ratio': 1.6272894417411288e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:22,018] Trial 381 finished with value: 0.01100996136086363 and parameters: {'alpha': 4947993.077524042, 'l1_ratio': 8.912693889294404e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:22,218] Trial 382 finished with value: 0.0676784710079004 and parameters: {'alpha': 560535.2492636895, 'l1_ratio': 6.931491783228862e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.255e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:31:28,278] Trial 369 finished with value: -0.5545477043699476 and parameters: {'alpha': 2342.081829922394, 'l1_ratio': 2.5101608179582863e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:28,932] Trial 384 finished with value: 0.024043994239420496 and parameters: {'alpha': 131104.54003663984, 'l1_ratio': 3.7407932615732567e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:29,211] Trial 385 finished with value: 0.06627345640233928 and parameters: {'alpha': 460292.0594689745, 'l1_ratio': 6.507073737687885e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:31,304] Trial 386 finished with value: -2.3734388060720617 and parameters: {'alpha': 0.0007076691132088723, 'l1_ratio': 1.0942984848059216e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.315e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.644e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:31:38,239] Trial 344 finished with value: -1.5129594514238147 and parameters: {'alpha': 39.78903289487904, 'l1_ratio': 9.266603943347669e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:38,660] Trial 388 finished with value: 0.06505388638010097 and parameters: {'alpha': 854487.0256485477, 'l1_ratio': 2.084514098610658e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:31:39,017] Trial 389 finished with value: -0.011808558077662198 and parameters: {'alpha': 33583325.2285764, 'l1_ratio': 2.476726376860248e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.860e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:31:40,993] Trial 390 finished with value: -0.012039014456542318 and parameters: {'alpha': 63889.388497182794, 'l1_ratio': 1.6586730215002264e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.358e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.885e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.459e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.104e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:02,667] Trial 362 finished with value: -0.99093011157342 and parameters: {'alpha': 632.6927239456629, 'l1_ratio': 2.4484323498033588e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.357e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:04,365] Trial 363 finished with value: -3.812844944122106 and parameters: {'alpha': 0.04782788052833057, 'l1_ratio': 1.9898331314461094e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:04,505] Trial 393 finished with value: 0.030196272732689915 and parameters: {'alpha': 2805083.1972660874, 'l1_ratio': 8.926269782528814e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:05,259] Trial 394 finished with value: 0.06054981529297173 and parameters: {'alpha': 335628.4031623019, 'l1_ratio': 1.0278513512286177e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.322e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:06,633] Trial 364 finished with value: -3.4865591587046687 and parameters: {'alpha': 0.06109520991147806, 'l1_ratio': 2.6996823378795245e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:06,849] Trial 396 finished with value: -0.009217972097849803 and parameters: {'alpha': 13316249.010806141, 'l1_ratio': 7.555754166387449e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:07,020] Trial 397 finished with value: -0.011177771670721018 and parameters: {'alpha': 127526049.08403903, 'l1_ratio': 4.631970116117063e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:07,173] Trial 398 finished with value: 0.05463485378829162 and parameters: {'alpha': 1352081.9839171043, 'l1_ratio': 4.960405871151061e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:07,496] Trial 399 finished with value: 0.041007951824639455 and parameters: {'alpha': 189923.89351622123, 'l1_ratio': 4.31421684214659e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:07,686] Trial 400 finished with value: 0.0115140760707824 and parameters: {'alpha': 5173884.069987892, 'l1_ratio': 1.540517348208803e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:07,986] Trial 401 finished with value: 0.06729030474603541 and parameters: {'alpha': 515698.65862620214, 'l1_ratio': 7.105413173722825e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.522e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.851e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:18,607] Trial 375 finished with value: -2.776076304159275 and parameters: {'alpha': 4.845864956925162, 'l1_ratio': 2.192545013686844e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:18,986] Trial 403 finished with value: -0.05598310108416593 and parameters: {'alpha': 20877.884159627498, 'l1_ratio': 0.0003633395523908245}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.750e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:19,560] Trial 371 finished with value: -1.098308688396379 and parameters: {'alpha': 388.53784321817375, 'l1_ratio': 4.112196510871656e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:19,950] Trial 404 finished with value: 0.02429772829315761 and parameters: {'alpha': 131768.07540170796, 'l1_ratio': 9.90635621716279e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.828e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:21,513] Trial 383 finished with value: -1.0795001980240702 and parameters: {'alpha': 428.53513168910706, 'l1_ratio': 2.7378457638938345e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:21,652] Trial 407 finished with value: 0.052331560696828316 and parameters: {'alpha': 1427008.9052683073, 'l1_ratio': 4.807251068675705e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:21,789] Trial 408 finished with value: -0.009217972097849803 and parameters: {'alpha': 5101883135.208477, 'l1_ratio': 0.041465699092758615}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:21,959] Trial 409 finished with value: 0.06227251620201905 and parameters: {'alpha': 363086.82798819616, 'l1_ratio': 1.4681017829785724e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:22,093] Trial 410 finished with value: -3.8565971637355303 and parameters: {'alpha': 1.5289980741938628e-08, 'l1_ratio': 7.278142170499203e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:23,214] Trial 411 finished with value: -0.02965861677429941 and parameters: {'alpha': 45169.3189418745, 'l1_ratio': 1.0629439557849733e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:23,381] Trial 412 finished with value: -0.012094370014468373 and parameters: {'alpha': 59061511.11505641, 'l1_ratio': 1.6353188322766033e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:23,691] Trial 413 finished with value: 0.06702759076179787 and parameters: {'alpha': 722154.3234693155, 'l1_ratio': 2.569014637634545e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:23,831] Trial 414 finished with value: 0.03215594908124808 and parameters: {'alpha': 2662849.674650771, 'l1_ratio': 1.723696695195658e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:33,426] Trial 391 finished with value: -0.9651920818141498 and parameters: {'alpha': 697.315044762292, 'l1_ratio': 7.878419837596468e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:34,107] Trial 416 finished with value: 0.03668681776346805 and parameters: {'alpha': 171922.40069996257, 'l1_ratio': 2.9091901283057085e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.211e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.772e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:36,923] Trial 387 finished with value: -2.520041608103117 and parameters: {'alpha': 7.637515106841173, 'l1_ratio': 1.752827721520145e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:37,323] Trial 418 finished with value: 0.06272861216106596 and parameters: {'alpha': 973494.433793154, 'l1_ratio': 4.0923114194111045e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:37,659] Trial 419 finished with value: -0.0024502253407719574 and parameters: {'alpha': 10039312.81170199, 'l1_ratio': 5.842635973440029e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:37,935] Trial 417 finished with value: -2.332210398078947 and parameters: {'alpha': 5.975246061460147e-06, 'l1_ratio': 4.393443544257033e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:38,262] Trial 421 finished with value: -0.010697005443094154 and parameters: {'alpha': 196294284.07912302, 'l1_ratio': 5.2351291198935e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:39,004] Trial 422 finished with value: -0.0005224886763923742 and parameters: {'alpha': 80240.07965021706, 'l1_ratio': 1.2513530100543549e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:39,412] Trial 423 finished with value: 0.057910724677580516 and parameters: {'alpha': 304020.46143944224, 'l1_ratio': 1.5096614989564722e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:39,773] Trial 424 finished with value: 0.02101124804522055 and parameters: {'alpha': 2890812.888358656, 'l1_ratio': 4.427134748345235e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:40,230] Trial 425 finished with value: 0.06443432381836274 and parameters: {'alpha': 888699.6004297986, 'l1_ratio': 8.40208620445114e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:40,970] Trial 426 finished with value: 0.05494583111374055 and parameters: {'alpha': 275501.3004380588, 'l1_ratio': 2.259328510892369e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:41,268] Trial 427 finished with value: 0.05120406801835168 and parameters: {'alpha': 1510261.3770946641, 'l1_ratio': 6.232124310885833e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:41,813] Trial 428 finished with value: 0.015179651945153805 and parameters: {'alpha': 109486.37650809369, 'l1_ratio': 3.250733000974288e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:42,032] Trial 429 finished with value: 0.06685977318427812 and parameters: {'alpha': 484571.99565741053, 'l1_ratio': 1.0181359706191762e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:42,219] Trial 430 finished with value: 0.015183994833419071 and parameters: {'alpha': 4530799.5727246, 'l1_ratio': 3.3071053891833e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+00, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:46,296] Trial 431 finished with value: -1.8618654202358904 and parameters: {'alpha': 0.00017279755983018157, 'l1_ratio': 1.3360571139754695e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:47,138] Trial 432 finished with value: -0.028525046300526286 and parameters: {'alpha': 46690.500972272384, 'l1_ratio': 5.984900612003745e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.209e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:32:52,557] Trial 433 finished with value: -0.11781290388652332 and parameters: {'alpha': 13557.193352147731, 'l1_ratio': 7.540230373572615e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:52,970] Trial 434 finished with value: 0.06713303457139574 and parameters: {'alpha': 693015.4737968697, 'l1_ratio': 2.0665003421737068e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:53,227] Trial 435 finished with value: -0.009217972097849803 and parameters: {'alpha': 9788456184.000788, 'l1_ratio': 0.009954049699295005}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:32:53,987] Trial 436 finished with value: 0.04272496307476459 and parameters: {'alpha': 197869.38453790898, 'l1_ratio': 1.830691222992475e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.095e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:02,998] Trial 392 finished with value: -2.6826485468794075 and parameters: {'alpha': 5.818314786509466, 'l1_ratio': 1.0111363102138506e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:03,282] Trial 438 finished with value: 0.04547466215294379 and parameters: {'alpha': 1806636.239632766, 'l1_ratio': 5.84761092058593e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.756e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:13,581] Trial 402 finished with value: -2.075909625374493 and parameters: {'alpha': 14.652382019710783, 'l1_ratio': 8.38768476084251e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:13,974] Trial 440 finished with value: 0.0042304031062859 and parameters: {'alpha': 6936740.026691613, 'l1_ratio': 1.0686663708177851e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:17,200] Trial 441 finished with value: -3.2126983457601037 and parameters: {'alpha': 0.0030874752124371756, 'l1_ratio': 3.660532933339662e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:17,506] Trial 442 finished with value: -0.010294357298468912 and parameters: {'alpha': 272070910.27730185, 'l1_ratio': 3.386198051576663e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:17,817] Trial 443 finished with value: -0.010449208152439105 and parameters: {'alpha': 22466584.199973483, 'l1_ratio': 5.4609161387212944e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:18,213] Trial 444 finished with value: 0.06550164142943715 and parameters: {'alpha': 432292.4586905868, 'l1_ratio': 1.421969514497231e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:19,849] Trial 395 finished with value: -1.2492640516069002 and parameters: {'alpha': 128.63007196764718, 'l1_ratio': 5.355551921574216e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:20,150] Trial 446 finished with value: 0.05395410647818329 and parameters: {'alpha': 1383688.3939650247, 'l1_ratio': 3.0214654012769742e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+00, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:21,095] Trial 445 finished with value: -3.8444103250397106 and parameters: {'alpha': 6.882610744603449e-07, 'l1_ratio': 2.5256220326742407e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:21,296] Trial 448 finished with value: -0.009217972097849803 and parameters: {'alpha': 1186510043.0160027, 'l1_ratio': 1.6185435952100499e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.814e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:22,055] Trial 405 finished with value: -1.9015554824740308 and parameters: {'alpha': 19.04147999816477, 'l1_ratio': 8.134320688726523e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:22,413] Trial 450 finished with value: 0.0029989241880887065 and parameters: {'alpha': 89928.98053611637, 'l1_ratio': 3.756020056647279e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:22,771] Trial 451 finished with value: -0.009366016733535284 and parameters: {'alpha': 2285865543.273534, 'l1_ratio': 1.9964218786307544e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:22,854] Trial 449 finished with value: 0.018914246302112803 and parameters: {'alpha': 118036.08858836522, 'l1_ratio': 1.5061934953223977e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:23,352] Trial 453 finished with value: 0.053828267436091294 and parameters: {'alpha': 318090.61066005635, 'l1_ratio': 1.2629158180299654e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:23,592] Trial 454 finished with value: 0.027590027161764546 and parameters: {'alpha': 3047016.9073020373, 'l1_ratio': 1.4885953013745376e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:23,814] Trial 455 finished with value: -3.8565107258913005 and parameters: {'alpha': 1.5564822906854598e-09, 'l1_ratio': 1.441298037587598e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.420e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:31,366] Trial 406 finished with value: -1.1489700480909593 and parameters: {'alpha': 286.6142565313024, 'l1_ratio': 1.038813462803706e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.226e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:36,492] Trial 415 finished with value: -1.1892207977496903 and parameters: {'alpha': 213.30846611155684, 'l1_ratio': 5.0280282587428236e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:36,767] Trial 458 finished with value: 0.06529819675263977 and parameters: {'alpha': 834597.4460074248, 'l1_ratio': 9.64777108940322e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:38,016] Trial 459 finished with value: -0.05637380550222859 and parameters: {'alpha': 27859.81191280614, 'l1_ratio': 4.6679759113022625e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.818e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:45,548] Trial 420 finished with value: -1.2580534118058782 and parameters: {'alpha': 119.8079976337757, 'l1_ratio': 5.061107540885919e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e-02, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:46,110] Trial 461 finished with value: 0.0678217023743668 and parameters: {'alpha': 592752.9910543269, 'l1_ratio': 4.735781528341036e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.243e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:47,101] Trial 462 finished with value: 0.04501693242181778 and parameters: {'alpha': 209333.8131425101, 'l1_ratio': 7.274122240463448e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:47,365] Trial 463 finished with value: 0.03798566934471089 and parameters: {'alpha': 2248815.789014305, 'l1_ratio': 4.8478113369082745e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:47,680] Trial 464 finished with value: 0.005989635487906431 and parameters: {'alpha': 6466860.894852264, 'l1_ratio': 3.591551253531606e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:48,078] Trial 465 finished with value: 0.06761445039995151 and parameters: {'alpha': 542211.3471946145, 'l1_ratio': 8.982842782267462e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+00, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:33:52,612] Trial 466 finished with value: -0.19750785017350614 and parameters: {'alpha': 8049.850670722551, 'l1_ratio': 8.1679851315463e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:52,982] Trial 467 finished with value: 0.05902823232568496 and parameters: {'alpha': 1149642.2051922786, 'l1_ratio': 4.825974739772465e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:53,528] Trial 468 finished with value: 0.047905128611978744 and parameters: {'alpha': 225398.2721619507, 'l1_ratio': 3.0823349113994694e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:55,409] Trial 469 finished with value: -0.02480473352668644 and parameters: {'alpha': 49662.027332981146, 'l1_ratio': 1.6609310001805278e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:55,683] Trial 470 finished with value: 0.06780265020542853 and parameters: {'alpha': 580765.8937863831, 'l1_ratio': 8.400569187718464e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:58,975] Trial 452 finished with value: -0.598258864216003 and parameters: {'alpha': 2078.0137915653704, 'l1_ratio': 8.434661556077724e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:59,321] Trial 472 finished with value: 0.06718517417223113 and parameters: {'alpha': 504862.01212175406, 'l1_ratio': 2.0937526730904627e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:59,483] Trial 473 finished with value: 0.03163401727998157 and parameters: {'alpha': 2702645.895751589, 'l1_ratio': 8.710734910143434e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:33:59,672] Trial 474 finished with value: -0.002520861989748583 and parameters: {'alpha': 10069411.137380581, 'l1_ratio': 1.816952233708565e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.610e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:00,136] Trial 437 finished with value: -2.072129881443962 and parameters: {'alpha': 14.671296928957833, 'l1_ratio': 6.431790993131934e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:00,255] Trial 475 finished with value: 0.019825881842120936 and parameters: {'alpha': 120244.36561074664, 'l1_ratio': 1.2863019122076534e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:01,096] Trial 476 finished with value: 0.022363581882165213 and parameters: {'alpha': 126631.10220187822, 'l1_ratio': 1.073187849519398e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:01,257] Trial 478 finished with value: -0.011400653881949552 and parameters: {'alpha': 1278472.9614831437, 'l1_ratio': 0.00027497679854157544}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:01,597] Trial 479 finished with value: 0.06594509647882045 and parameters: {'alpha': 446398.621667224, 'l1_ratio': 5.6459971607038235e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:01,889] Trial 480 finished with value: 0.06264698879013857 and parameters: {'alpha': 978285.2312248087, 'l1_ratio': 2.703664078913971e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:02,047] Trial 481 finished with value: 0.020661465598849738 and parameters: {'alpha': 3765432.735797483, 'l1_ratio': 3.33095265074687e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.977e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:11,568] Trial 439 finished with value: -1.3483461200425082 and parameters: {'alpha': 68.83065465890078, 'l1_ratio': 8.190488040029594e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:11,877] Trial 483 finished with value: 0.0482957657900962 and parameters: {'alpha': 230101.41354095162, 'l1_ratio': 1.1024081998523079e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:11,996] Trial 484 finished with value: -0.008667368941879064 and parameters: {'alpha': 17141008.70140701, 'l1_ratio': 2.607171098439257e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:12,149] Trial 485 finished with value: 0.0628955913585096 and parameters: {'alpha': 516802.27713648434, 'l1_ratio': 6.192912876808501e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:12,279] Trial 486 finished with value: -0.012117586358537213 and parameters: {'alpha': 56135168.12753094, 'l1_ratio': 1.761610549847173e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:12,648] Trial 482 finished with value: -4.04181818083688 and parameters: {'alpha': 0.010787785120641828, 'l1_ratio': 2.297548444720927e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e-02, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:13,037] Trial 488 finished with value: -0.012144019450377389 and parameters: {'alpha': 40992.56663124225, 'l1_ratio': 0.001688048108564433}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:13,270] Trial 489 finished with value: 0.04468994497676737 and parameters: {'alpha': 1849338.4798272739, 'l1_ratio': 5.477891853194254e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e-02, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:16,024] Trial 490 finished with value: -3.509704656462726 and parameters: {'alpha': 2.1822860570530636e-06, 'l1_ratio': 1.3140619140554766e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:18,382] Trial 491 finished with value: -1.1030348522872775 and parameters: {'alpha': 3.068013840676407e-05, 'l1_ratio': 2.3064273643272761e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:18,589] Trial 492 finished with value: 0.05456090623941656 and parameters: {'alpha': 312382.76770913857, 'l1_ratio': 8.605754686835484e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:18,827] Trial 493 finished with value: 0.06308997380368771 and parameters: {'alpha': 957955.9124204726, 'l1_ratio': 5.991376358435007e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:21,638] Trial 494 finished with value: -2.058187506107567 and parameters: {'alpha': 0.0002846575576762636, 'l1_ratio': 1.013488093058799e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:21,753] Trial 495 finished with value: 0.013094340173658292 and parameters: {'alpha': 4639758.675938242, 'l1_ratio': 7.413583084118244e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:22,693] Trial 457 finished with value: -0.8475648925072825 and parameters: {'alpha': 1031.192077066051, 'l1_ratio': 8.288760992964682e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:22,919] Trial 496 finished with value: -0.005591525401734391 and parameters: {'alpha': 72568.36851094455, 'l1_ratio': 1.258197979490984e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:25,643] Trial 498 finished with value: -0.1079719992850997 and parameters: {'alpha': 14792.149284732748, 'l1_ratio': 3.3090301270967005e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:27,706] Trial 499 finished with value: -1.0642165529773686 and parameters: {'alpha': 3.875674811614738e-05, 'l1_ratio': 4.055764310041503e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:27,826] Trial 500 finished with value: -0.009217972097849803 and parameters: {'alpha': 411698849.82408637, 'l1_ratio': 2.9393232673577645e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:28,167] Trial 501 finished with value: 0.046403039493297604 and parameters: {'alpha': 216883.4373055622, 'l1_ratio': 4.871958621886447e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:28,671] Trial 502 finished with value: 0.06767661962862233 and parameters: {'alpha': 648081.0925817923, 'l1_ratio': 1.7884771928991333e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:28,984] Trial 503 finished with value: 0.03822997259531687 and parameters: {'alpha': 2233555.3413498313, 'l1_ratio': 1.1436935134593749e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.226e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:36,123] Trial 471 finished with value: -4.693147912007717 and parameters: {'alpha': 0.0220102994156315, 'l1_ratio': 1.0589320934342641e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:36,495] Trial 505 finished with value: -3.8566049104202405 and parameters: {'alpha': 2.063142787326565e-08, 'l1_ratio': 2.932120752885605e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:36,736] Trial 506 finished with value: 0.0632331793734429 and parameters: {'alpha': 950833.9785033475, 'l1_ratio': 1.6233762114173615e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:36,981] Trial 507 finished with value: 0.06490656017780742 and parameters: {'alpha': 415349.960336295, 'l1_ratio': 2.2889896412669303e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:36,999] Trial 456 finished with value: -2.141307810730809 and parameters: {'alpha': 0.2563695214156513, 'l1_ratio': 7.694402790099045e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:37,226] Trial 509 finished with value: 0.004724179522971476 and parameters: {'alpha': 6707561.5052374955, 'l1_ratio': 2.382940493479174e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:37,258] Trial 508 finished with value: -0.009217972097849803 and parameters: {'alpha': 3005061528.9323096, 'l1_ratio': 2.1571625952449967e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:37,808] Trial 511 finished with value: 0.02204196785743695 and parameters: {'alpha': 125806.97528619437, 'l1_ratio': 2.0004663956709918e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:37,990] Trial 512 finished with value: 0.043669543600947845 and parameters: {'alpha': 1592852.084821104, 'l1_ratio': 3.985388011991509e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:38,250] Trial 513 finished with value: 0.06506919577839676 and parameters: {'alpha': 544138.7690710466, 'l1_ratio': 3.1402038533573966e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:38,391] Trial 514 finished with value: -0.011024297409506648 and parameters: {'alpha': 25580834.932140958, 'l1_ratio': 1.7333739452872798e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:38,532] Trial 515 finished with value: -0.009217972097849803 and parameters: {'alpha': 242135.2901327144, 'l1_ratio': 0.07411011400302737}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:39,077] Trial 516 finished with value: -0.006225843202229631 and parameters: {'alpha': 71675.22780327623, 'l1_ratio': 3.645636609733045e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.700e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:42,235] Trial 447 finished with value: -2.6374744836504695 and parameters: {'alpha': 0.7272166439116692, 'l1_ratio': 1.7148092036755425e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:43,643] Trial 518 finished with value: -3.868971170395043 and parameters: {'alpha': 9.5594923937675e-08, 'l1_ratio': 6.962019320887663e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:43,806] Trial 519 finished with value: -0.009217972097849803 and parameters: {'alpha': 1964483.5965397016, 'l1_ratio': 0.5122329246332992}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e-02, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:49,816] Trial 510 finished with value: -0.2936167166012854 and parameters: {'alpha': 5276.79179973365, 'l1_ratio': 1.8805515451319947e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:50,144] Trial 521 finished with value: 0.0642955348188945 and parameters: {'alpha': 873005.628010846, 'l1_ratio': 3.821068094784108e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.604e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:54,540] Trial 522 finished with value: -3.3148879680948284 and parameters: {'alpha': 0.0034365148768955643, 'l1_ratio': 3.7705659310905397e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.028e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:34:55,862] Trial 477 finished with value: -4.437839704758244 and parameters: {'alpha': 0.03046060365156864, 'l1_ratio': 6.07346389106968e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:56,190] Trial 524 finished with value: 0.019742055855544078 and parameters: {'alpha': 3872700.8013377083, 'l1_ratio': 5.5289765582695996e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:58,187] Trial 523 finished with value: -1.0629150264013554 and parameters: {'alpha': 8.846248880174604e-05, 'l1_ratio': 1.7171779398003877e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:58,452] Trial 525 finished with value: -0.05351067875792318 and parameters: {'alpha': 29242.50950053571, 'l1_ratio': 1.847240402966099e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:58,839] Trial 527 finished with value: -0.0066217683501080815 and parameters: {'alpha': 228875.50095453922, 'l1_ratio': 0.0006867018980272019}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:59,184] Trial 528 finished with value: -0.003292867936953825 and parameters: {'alpha': 10605729.415580606, 'l1_ratio': 1.1989611503371977e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:34:59,594] Trial 529 finished with value: 0.021496329865672997 and parameters: {'alpha': 549354.3161307819, 'l1_ratio': 0.00010570234843744909}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:00,015] Trial 530 finished with value: 0.0573562107936072 and parameters: {'alpha': 1224634.62917119, 'l1_ratio': 3.139147955530725e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:00,348] Trial 487 finished with value: -0.7063156177657314 and parameters: {'alpha': 1547.9005779787826, 'l1_ratio': 5.142530512505028e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:00,574] Trial 532 finished with value: -0.009217972097849803 and parameters: {'alpha': 124889.83307851477, 'l1_ratio': 0.0040556054890337695}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.395e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:02,122] Trial 460 finished with value: -1.3292932151410315 and parameters: {'alpha': 75.52724797828196, 'l1_ratio': 2.731843394731231e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.079e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.920e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.291e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.124e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.493e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.002e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.848e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.639e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:35,531] Trial 497 finished with value: -2.6200135749718725 and parameters: {'alpha': 0.7120926025506353, 'l1_ratio': 1.2418621863556773e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:35,714] Trial 535 finished with value: -3.856508958557434 and parameters: {'alpha': 3.0054381257936804e-10, 'l1_ratio': 1.3558468542378038e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:35,944] Trial 536 finished with value: -0.009217972097849803 and parameters: {'alpha': 1266137660.676369, 'l1_ratio': 0.00020996475487397915}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.426e-02, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:38,431] Trial 537 finished with value: -3.804348648526064 and parameters: {'alpha': 8.030314288779597e-07, 'l1_ratio': 4.940354467666931e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:38,743] Trial 538 finished with value: -0.012090286486683347 and parameters: {'alpha': 59479252.60842997, 'l1_ratio': 3.665630143312516e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:39,314] Trial 539 finished with value: 0.062238482666346906 and parameters: {'alpha': 360844.27543671225, 'l1_ratio': 1.0913801205660666e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:39,672] Trial 540 finished with value: -3.8565088263395206 and parameters: {'alpha': 2.0658268123358822e-10, 'l1_ratio': 5.490069041773446e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.386e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:40,099] Trial 541 finished with value: 0.025277094845222114 and parameters: {'alpha': 3266593.486856816, 'l1_ratio': 3.5956871827418956e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:40,451] Trial 542 finished with value: 0.05615270369138092 and parameters: {'alpha': 822808.0754427635, 'l1_ratio': 1.0234478312644331e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:40,599] Trial 543 finished with value: -0.010803151600464078 and parameters: {'alpha': 174520117.03068566, 'l1_ratio': 2.4200748902341418e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:40,735] Trial 544 finished with value: 0.007434156676620396 and parameters: {'alpha': 102049.32758097374, 'l1_ratio': 5.500630201681948e-05}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:41,121] Trial 545 finished with value: 0.05609101362475977 and parameters: {'alpha': 285815.0722783678, 'l1_ratio': 8.291945393344673e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:41,235] Trial 526 finished with value: -3.249101188130747 and parameters: {'alpha': 1.1671831133233899, 'l1_ratio': 0.006668297480291647}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:41,261] Trial 546 finished with value: -0.009217972097849803 and parameters: {'alpha': 1754840.3792869078, 'l1_ratio': 0.0006182473723013237}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:41,521] Trial 547 finished with value: -0.00948539361285842 and parameters: {'alpha': 840703602.963212, 'l1_ratio': 1.2642107505918148e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.959e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:43,415] Trial 504 finished with value: -2.1290905117745327 and parameters: {'alpha': 0.31488669640791817, 'l1_ratio': 2.927035467818232e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:43,759] Trial 550 finished with value: -3.856510820435966 and parameters: {'alpha': 1.6236685561557367e-09, 'l1_ratio': 1.5872398026072183e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:45,003] Trial 551 finished with value: -0.013528735589933727 and parameters: {'alpha': 62035.131356339974, 'l1_ratio': 6.29953553257089e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:45,204] Trial 552 finished with value: 0.0030145969129963257 and parameters: {'alpha': 7080676.092786947, 'l1_ratio': 5.355734061305861e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:45,543] Trial 553 finished with value: 0.06772559513389409 and parameters: {'alpha': 622103.8427165771, 'l1_ratio': 6.660163306884752e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:45,847] Trial 554 finished with value: 0.06560994130408475 and parameters: {'alpha': 819663.9887251214, 'l1_ratio': 3.76727355063387e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:46,229] Trial 555 finished with value: 0.04022441724584406 and parameters: {'alpha': 188922.4871054352, 'l1_ratio': 2.408834665294993e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:46,460] Trial 556 finished with value: -0.007679075664762558 and parameters: {'alpha': 3066499.9641298107, 'l1_ratio': 4.499549102968111e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:46,630] Trial 557 finished with value: -0.009217972097849803 and parameters: {'alpha': 485640.9605449955, 'l1_ratio': 0.023809607391479214}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.412e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.727e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:48,686] Trial 517 finished with value: -2.645223257905801 and parameters: {'alpha': 0.7340916944451691, 'l1_ratio': 6.104531638487321e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:50,204] Trial 558 finished with value: -2.4862648185865455 and parameters: {'alpha': 0.0008378072126027074, 'l1_ratio': 7.112231041189234e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:53,529] Trial 560 finished with value: -0.36950307368681995 and parameters: {'alpha': 3712.1277129312048, 'l1_ratio': 2.701195819704829e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:53,706] Trial 561 finished with value: 0.0509979718271509 and parameters: {'alpha': 1524673.9035641742, 'l1_ratio': 2.994331552529949e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:54,329] Trial 520 finished with value: -2.9745389500247152 and parameters: {'alpha': 2.349169145466603, 'l1_ratio': 1.9879684595525157e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:54,770] Trial 562 finished with value: -0.03295281481604332 and parameters: {'alpha': 42387.03350263645, 'l1_ratio': 5.493541809177532e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:56,286] Trial 563 finished with value: -0.07421848504097332 and parameters: {'alpha': 21480.33675423882, 'l1_ratio': 4.906254456403412e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:35:57,894] Trial 534 finished with value: -2.4942124279458318 and parameters: {'alpha': 0.48329549800776506, 'l1_ratio': 0.0004745967812133771}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:58,230] Trial 566 finished with value: -0.009217972097849803 and parameters: {'alpha': 246556.62736090322, 'l1_ratio': 0.149972088614398}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:59,455] Trial 565 finished with value: -2.4237774529122444 and parameters: {'alpha': 5.019296300511984e-06, 'l1_ratio': 0.00013673399353977312}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:35:59,680] Trial 568 finished with value: -0.004598378485706951 and parameters: {'alpha': 11643144.763142964, 'l1_ratio': 2.4803832221341215e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:00,008] Trial 569 finished with value: 0.06561282244708862 and parameters: {'alpha': 821832.6525115632, 'l1_ratio': 1.1571294897382334e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:00,193] Trial 570 finished with value: -0.009217972097849803 and parameters: {'alpha': 3864928759.845976, 'l1_ratio': 0.1540319013718619}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.453e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:00,641] Trial 531 finished with value: -3.0363478326103666 and parameters: {'alpha': 0.09112404067350034, 'l1_ratio': 2.2154315931423453e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:01,114] Trial 572 finished with value: 0.015231120165538367 and parameters: {'alpha': 4523410.1926043, 'l1_ratio': 1.5073304832932891e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:01,560] Trial 573 finished with value: 0.02689726212502097 and parameters: {'alpha': 139096.3390689615, 'l1_ratio': 1.4710458545917275e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:01,853] Trial 564 finished with value: -4.0544427499776585 and parameters: {'alpha': 0.008213181157754495, 'l1_ratio': 2.233205968172677e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:02,034] Trial 574 finished with value: 0.06525570984745539 and parameters: {'alpha': 424836.9454627105, 'l1_ratio': 2.4319866444728116e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:02,259] Trial 575 finished with value: -3.8565089383989184 and parameters: {'alpha': 1.320096168128359e-10, 'l1_ratio': 0.8504228757282415}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:02,648] Trial 576 finished with value: 0.0493145336716078 and parameters: {'alpha': 1607910.063338122, 'l1_ratio': 4.1888893060800875e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:02,716] Trial 577 finished with value: -0.010564015136056204 and parameters: {'alpha': 1388752.4528034965, 'l1_ratio': 0.0002784899720601834}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:03,075] Trial 579 finished with value: -0.010914263873883981 and parameters: {'alpha': 28030940.70010654, 'l1_ratio': 1.1243826460440884e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:03,294] Trial 578 finished with value: 0.0676758596183797 and parameters: {'alpha': 549644.1557558044, 'l1_ratio': 7.187694111293082e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:03,679] Trial 580 finished with value: 0.06286904947894827 and parameters: {'alpha': 371827.0554838093, 'l1_ratio': 9.387932889438068e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:03,791] Trial 581 finished with value: 0.05967211959288957 and parameters: {'alpha': 324222.6874836408, 'l1_ratio': 7.916734509566124e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:05,569] Trial 582 finished with value: -0.0015721886208833007 and parameters: {'alpha': 78557.8686005455, 'l1_ratio': 8.237791800929302e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:05,964] Trial 584 finished with value: 0.022301922143658448 and parameters: {'alpha': 3581984.0088312756, 'l1_ratio': 1.5245767995726027e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:06,389] Trial 585 finished with value: 0.06732852838602572 and parameters: {'alpha': 693703.1139380501, 'l1_ratio': 4.816225302092514e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:07,688] Trial 571 finished with value: -0.7833152184738257 and parameters: {'alpha': 1067.876402197469, 'l1_ratio': 0.00019400688082243925}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:08,352] Trial 587 finished with value: 0.013419649955010956 and parameters: {'alpha': 105698.22237973321, 'l1_ratio': 2.5328007920558915e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:09,511] Trial 583 finished with value: -0.11676439868682693 and parameters: {'alpha': 13679.026704512802, 'l1_ratio': 6.194549489690716e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:09,925] Trial 589 finished with value: -3.8566072560928055 and parameters: {'alpha': 2.2248631373643956e-08, 'l1_ratio': 1.7643835155266137e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.370e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.148e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:13,621] Trial 533 finished with value: -2.896756076871162 and parameters: {'alpha': 1.1088111142614883, 'l1_ratio': 3.3658155874078607e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:13,843] Trial 591 finished with value: -0.009217972097849803 and parameters: {'alpha': 1977487.5580619674, 'l1_ratio': 0.0021741695283601257}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:14,544] Trial 592 finished with value: 0.045573154801193096 and parameters: {'alpha': 212269.89140271136, 'l1_ratio': 1.0328379467467116e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:14,876] Trial 593 finished with value: 0.06530792479409679 and parameters: {'alpha': 839793.6653380785, 'l1_ratio': 3.4404100726132623e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:15,151] Trial 594 finished with value: -0.00243325726865525 and parameters: {'alpha': 6569362.931729194, 'l1_ratio': 5.1553815910940415e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e-02, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:17,679] Trial 595 finished with value: -0.036068403386039706 and parameters: {'alpha': 39940.36564891217, 'l1_ratio': 2.2581836822229279e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:17,883] Trial 596 finished with value: -0.009217972097849803 and parameters: {'alpha': 679355.782382644, 'l1_ratio': 0.0015685727427185259}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:18,332] Trial 597 finished with value: 0.04163188204790728 and parameters: {'alpha': 192752.60062768497, 'l1_ratio': 2.130173238075511e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:26,594] Trial 598 finished with value: -0.19228850912590256 and parameters: {'alpha': 8274.490218840752, 'l1_ratio': 4.882904765972721e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.026e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.502e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.767e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.454e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:45,527] Trial 567 finished with value: -4.404367112297588 and parameters: {'alpha': 0.07875082523557787, 'l1_ratio': 0.027449560514975747}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.690e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.917e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:48,022] Trial 600 finished with value: -1.0955496622278462 and parameters: {'alpha': 3.1753264189885306e-05, 'l1_ratio': 1.0057605908243532e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:48,158] Trial 601 finished with value: 0.03272407500741511 and parameters: {'alpha': 2596545.201180113, 'l1_ratio': 1.5071953681438396e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.681e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:52,019] Trial 549 finished with value: -2.617015163722853 and parameters: {'alpha': 0.139317473200655, 'l1_ratio': 6.593759545264233e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:52,322] Trial 603 finished with value: -0.009217972097849803 and parameters: {'alpha': 1063126.1119229915, 'l1_ratio': 0.006887020393023676}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:52,906] Trial 604 finished with value: 0.06209205716051547 and parameters: {'alpha': 358492.75586318097, 'l1_ratio': 4.14613876336953e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.503e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:54,480] Trial 548 finished with value: -1.691530463226754 and parameters: {'alpha': 27.150720095146827, 'l1_ratio': 1.6245196175199465e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:54,953] Trial 606 finished with value: -0.008906777329853047 and parameters: {'alpha': 17671748.33736217, 'l1_ratio': 1.2408042311559594e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.158e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:55,662] Trial 559 finished with value: -3.536570648096907 and parameters: {'alpha': 0.05880544241644197, 'l1_ratio': 7.406394819188019e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:56,393] Trial 608 finished with value: -0.004170501574910094 and parameters: {'alpha': 74658.15605092545, 'l1_ratio': 9.565227620322976e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:56,569] Trial 609 finished with value: 0.041323491884920016 and parameters: {'alpha': 2041991.1675673781, 'l1_ratio': 1.5723807407256373e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:36:58,174] Trial 607 finished with value: -3.9062124509510108 and parameters: {'alpha': 1.6784539368729474e-07, 'l1_ratio': 0.0010539074252188785}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:36:59,793] Trial 610 finished with value: -3.652875216210403 and parameters: {'alpha': 1.3593388796610111e-06, 'l1_ratio': 9.46842210792857e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:00,631] Trial 611 finished with value: -3.6461938841021695 and parameters: {'alpha': 1.3913895436516381e-06, 'l1_ratio': 2.627589999284903e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:00,863] Trial 613 finished with value: -0.009217972097849803 and parameters: {'alpha': 6902814377.637282, 'l1_ratio': 6.253431756368884e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:00,940] Trial 612 finished with value: 0.03180108595833379 and parameters: {'alpha': 154371.82196245345, 'l1_ratio': 2.8577399540563443e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:03,450] Trial 614 finished with value: -2.098713418303518 and parameters: {'alpha': 0.00032446792538079857, 'l1_ratio': 3.472911797647129e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.081e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:05,846] Trial 616 finished with value: -2.6327569759644387 and parameters: {'alpha': 0.0009202838710259666, 'l1_ratio': 0.004274740360124768}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:06,008] Trial 617 finished with value: 0.05673319406855715 and parameters: {'alpha': 593294.0226926997, 'l1_ratio': 1.6133210126276665e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:06,146] Trial 618 finished with value: 0.007159067288787309 and parameters: {'alpha': 6030578.030900633, 'l1_ratio': 2.5524529830493403e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:06,283] Trial 619 finished with value: 0.043314600457022734 and parameters: {'alpha': 1386756.0792494188, 'l1_ratio': 7.880181114680596e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.368e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:07,318] Trial 586 finished with value: -3.4730550830200606 and parameters: {'alpha': 0.061735112774122046, 'l1_ratio': 2.800413409916408e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:08,167] Trial 621 finished with value: 0.05992501172099788 and parameters: {'alpha': 327403.35512073606, 'l1_ratio': 1.0006587540818014e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.655e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:11,241] Trial 588 finished with value: -4.099029153452535 and parameters: {'alpha': 0.038536077219858925, 'l1_ratio': 1.0274169057756709e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:12,678] Trial 623 finished with value: -0.037896495610930524 and parameters: {'alpha': 38587.57497834759, 'l1_ratio': 8.423543202930479e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:12,865] Trial 624 finished with value: 0.019817040713173067 and parameters: {'alpha': 3706703.3058841815, 'l1_ratio': 7.030039919469421e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.095e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.916e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.344e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:21,532] Trial 590 finished with value: -2.637214249993943 and parameters: {'alpha': 6.306478920507872, 'l1_ratio': 3.990048733137087e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:22,027] Trial 626 finished with value: 0.034031538481568556 and parameters: {'alpha': 162085.07907399582, 'l1_ratio': 3.406002829757436e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:22,169] Trial 627 finished with value: -0.009437856161261063 and parameters: {'alpha': 1543907954.6132028, 'l1_ratio': 1.7346942905536574e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:22,488] Trial 628 finished with value: 0.06735263088966832 and parameters: {'alpha': 690243.8171935923, 'l1_ratio': 8.567883135699332e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:22,751] Trial 629 finished with value: 0.05848896398903395 and parameters: {'alpha': 1174625.8944886108, 'l1_ratio': 1.165214805596144e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:22,972] Trial 630 finished with value: -0.010360798196813533 and parameters: {'alpha': 268724966.0592064, 'l1_ratio': 4.941055565724647e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:23,222] Trial 631 finished with value: -0.009217972097849803 and parameters: {'alpha': 103621318.83708133, 'l1_ratio': 3.0453220838708534e-05}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.281e-02, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:26,089] Trial 632 finished with value: -2.7610978027140005 and parameters: {'alpha': 0.0017117836240833927, 'l1_ratio': 1.2753099572124894e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.221e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:29,743] Trial 599 finished with value: -1.6216000547095688 and parameters: {'alpha': 31.11036560473565, 'l1_ratio': 1.630129532703883e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:32,751] Trial 634 finished with value: -2.1458537093221777 and parameters: {'alpha': 8.375667157381547e-06, 'l1_ratio': 2.4229319631763343e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:33,088] Trial 635 finished with value: 0.06235952090050878 and parameters: {'alpha': 363601.62425985804, 'l1_ratio': 6.303074402866827e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.516e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.580e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.592e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.996e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+00, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:54,024] Trial 636 finished with value: -4.049903091492712 and parameters: {'alpha': 0.01474436938455753, 'l1_ratio': 1.825155066526878e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:54,168] Trial 637 finished with value: -0.005214816190266906 and parameters: {'alpha': 12229520.23377186, 'l1_ratio': 5.435316443280455e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:54,788] Trial 638 finished with value: 0.0018506953404470543 and parameters: {'alpha': 84045.66426402757, 'l1_ratio': 6.884987135191337e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:55,928] Trial 602 finished with value: -2.521749437720533 and parameters: {'alpha': 7.617222960686523, 'l1_ratio': 8.876235211110487e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:56,112] Trial 640 finished with value: -0.011638278908979319 and parameters: {'alpha': 32560997.245567862, 'l1_ratio': 3.1013464552833437e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.804e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:37:56,969] Trial 605 finished with value: -1.5734144394235068 and parameters: {'alpha': 34.48777214583079, 'l1_ratio': 7.19649850340111e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:58,544] Trial 622 finished with value: -0.7485723384835185 and parameters: {'alpha': 1376.4209006968324, 'l1_ratio': 9.884815486150136e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:59,580] Trial 642 finished with value: -0.08643377886403125 and parameters: {'alpha': 18475.28989213977, 'l1_ratio': 2.885100592567636e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:37:59,844] Trial 644 finished with value: 0.034216647447407156 and parameters: {'alpha': 2508006.2465144354, 'l1_ratio': 2.408577039760694e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:00,464] Trial 643 finished with value: -0.06493343927014335 and parameters: {'alpha': 24450.490219560572, 'l1_ratio': 4.525699714658377e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:00,796] Trial 646 finished with value: 0.06780042128378143 and parameters: {'alpha': 576583.831687363, 'l1_ratio': 4.30846460650383e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:01,700] Trial 645 finished with value: -1.1516978267623865 and parameters: {'alpha': 2.6372152566680146e-05, 'l1_ratio': 5.03193094730574e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:02,112] Trial 648 finished with value: 0.045816680688859544 and parameters: {'alpha': 213578.49498798745, 'l1_ratio': 1.8801289147616631e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:38:03,182] Trial 615 finished with value: -1.487222096882296 and parameters: {'alpha': 42.53976878692022, 'l1_ratio': 1.7707921949342059e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:03,594] Trial 650 finished with value: -0.01221590627424285 and parameters: {'alpha': 692803.1165454942, 'l1_ratio': 0.00046889699584155804}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:38:03,949] Trial 651 finished with value: -0.0017747281221190219 and parameters: {'alpha': 1341555.9053986354, 'l1_ratio': 9.787076113145122e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:04,053] Trial 620 finished with value: -2.8301098032944463 and parameters: {'alpha': 4.532668165437068, 'l1_ratio': 0.00013827335767645238}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:04,276] Trial 652 finished with value: 0.008958681956708644 and parameters: {'alpha': 5710899.799096033, 'l1_ratio': 6.290794527141923e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:04,397] Trial 649 finished with value: -1.0565822454623708 and parameters: {'alpha': 7.9575540398708e-05, 'l1_ratio': 1.2002831270923453e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:04,544] Trial 653 finished with value: 0.012559358356002304 and parameters: {'alpha': 4974538.992894221, 'l1_ratio': 7.943856102121624e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:05,147] Trial 654 finished with value: 0.02591354027748875 and parameters: {'alpha': 136268.6090952207, 'l1_ratio': 1.5195335998946535e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:05,425] Trial 657 finished with value: -0.009217972097849803 and parameters: {'alpha': 4228.412897838658, 'l1_ratio': 0.7852682824785563}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:05,525] Trial 655 finished with value: 0.02379442231587085 and parameters: {'alpha': 130405.4791713331, 'l1_ratio': 3.9806531883488146e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:05,862] Trial 659 finished with value: 0.06419178225577293 and parameters: {'alpha': 399907.48246608925, 'l1_ratio': 1.0713735432661043e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:05,912] Trial 658 finished with value: 0.06288492914744355 and parameters: {'alpha': 371996.82247296924, 'l1_ratio': 5.241282470087495e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:06,220] Trial 660 finished with value: 0.0020353254909192264 and parameters: {'alpha': 1848085.5893135413, 'l1_ratio': 3.611038685218168e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:06,551] Trial 662 finished with value: 0.06163302915310165 and parameters: {'alpha': 834334.2941378149, 'l1_ratio': 3.5707571117560656e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:07,444] Trial 656 finished with value: -1.8775914859175724 and parameters: {'alpha': 9.807979745783507e-06, 'l1_ratio': 0.3725740843735455}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:09,208] Trial 663 finished with value: -2.0635882948369737 and parameters: {'alpha': 9.880165450556249e-06, 'l1_ratio': 3.9909555478075634e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:09,328] Trial 664 finished with value: -0.0158061924468675 and parameters: {'alpha': 59304.02976422873, 'l1_ratio': 3.561272869582793e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:09,476] Trial 661 finished with value: -1.5820862941976896 and parameters: {'alpha': 1.972549622871489e-05, 'l1_ratio': 1.4651285452317641e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:09,645] Trial 666 finished with value: -0.011754622212772533 and parameters: {'alpha': 85494935.37339528, 'l1_ratio': 1.5030228281441668e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:09,843] Trial 667 finished with value: 0.0433186789156789 and parameters: {'alpha': 1926184.884623726, 'l1_ratio': 9.686995151857837e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:10,354] Trial 669 finished with value: 0.06780194858557094 and parameters: {'alpha': 600396.4513063359, 'l1_ratio': 2.557085295318428e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:10,759] Trial 670 finished with value: -0.0043654884386508845 and parameters: {'alpha': 11434277.351340199, 'l1_ratio': 3.538957469362936e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:38:11,215] Trial 671 finished with value: 0.04410045452275513 and parameters: {'alpha': 225156.49421754087, 'l1_ratio': 1.1816455727111935e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:12,177] Trial 665 finished with value: -3.909880291604207 and parameters: {'alpha': 1.8672304450027568e-07, 'l1_ratio': 1.6367881269174044e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:12,744] Trial 672 finished with value: -3.8594410504361347 and parameters: {'alpha': 7.318227692494015e-08, 'l1_ratio': 1.926798685721978e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:12,951] Trial 674 finished with value: -3.856517694500507 and parameters: {'alpha': 6.508219435716996e-09, 'l1_ratio': 2.1437102567677975e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:13,266] Trial 675 finished with value: 0.057543605997596114 and parameters: {'alpha': 1214487.3667045839, 'l1_ratio': 5.6327615922617674e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:13,406] Trial 676 finished with value: -0.009580037523620355 and parameters: {'alpha': 936512600.589864, 'l1_ratio': 1.8017369955871532e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:13,783] Trial 677 finished with value: 0.06755761949101875 and parameters: {'alpha': 537644.3994665967, 'l1_ratio': 3.073294902505463e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.533e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:38:14,105] Trial 625 finished with value: -1.1400713217148624 and parameters: {'alpha': 303.85366151622196, 'l1_ratio': 2.201229005498525e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:14,235] Trial 673 finished with value: -1.2213922138305016 and parameters: {'alpha': 0.00012341049793372923, 'l1_ratio': 2.311315613675242e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:14,539] Trial 679 finished with value: 0.018494765804547748 and parameters: {'alpha': 4021737.084951364, 'l1_ratio': 9.748304755339967e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.931e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:38:33,747] Trial 633 finished with value: -2.9128516051585023 and parameters: {'alpha': 3.336567909087728, 'l1_ratio': 2.5522129083187684e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:34,114] Trial 682 finished with value: -0.009852874979431695 and parameters: {'alpha': 306589216.2359208, 'l1_ratio': 1.8850201917457467e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e+00, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:38:36,219] Trial 683 finished with value: -0.018757181068662903 and parameters: {'alpha': 55943.71997959377, 'l1_ratio': 3.7776788377137914e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:36,704] Trial 684 finished with value: 0.04823559436028676 and parameters: {'alpha': 227365.74662671302, 'l1_ratio': 6.696741582512486e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.816e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.401e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:38:57,084] Trial 647 finished with value: -1.2229196583572925 and parameters: {'alpha': 160.86801452748125, 'l1_ratio': 1.661618694596944e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:57,238] Trial 686 finished with value: 0.06384345995635483 and parameters: {'alpha': 915837.6307977763, 'l1_ratio': 6.887844981060242e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:38:57,392] Trial 687 finished with value: 0.03613796768762245 and parameters: {'alpha': 2372694.0213735127, 'l1_ratio': 1.5055673121285324e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.065e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.705e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:10,134] Trial 668 finished with value: -1.0052004396541712 and parameters: {'alpha': 597.8108667402591, 'l1_ratio': 1.862786382249514e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:11,339] Trial 689 finished with value: -3.9288219103737823 and parameters: {'alpha': 5.24680820352311e-07, 'l1_ratio': 3.784641831223981e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:11,663] Trial 639 finished with value: -1.1927043374642607 and parameters: {'alpha': 207.40849518609508, 'l1_ratio': 8.519195834970493e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:11,861] Trial 690 finished with value: 0.01512376732410666 and parameters: {'alpha': 109384.5814651178, 'l1_ratio': 4.28100388940201e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:12,641] Trial 691 finished with value: 0.011777005667766368 and parameters: {'alpha': 102309.11890872224, 'l1_ratio': 3.610049041213284e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:14,407] Trial 678 finished with value: -2.9460601263751207 and parameters: {'alpha': 3.5606069098004327, 'l1_ratio': 0.0002436310200870508}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:14,991] Trial 694 finished with value: 0.06613987038569828 and parameters: {'alpha': 453227.94797601586, 'l1_ratio': 2.79137873933449e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:15,395] Trial 641 finished with value: -1.174944591842728 and parameters: {'alpha': 237.80596767630777, 'l1_ratio': 1.3463245179509696e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:15,615] Trial 696 finished with value: -0.009217972097849803 and parameters: {'alpha': 44986318.205731705, 'l1_ratio': 4.992644530527582e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:17,282] Trial 692 finished with value: -4.021748510574682 and parameters: {'alpha': 0.007203356942077462, 'l1_ratio': 6.644239937475821e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:21,145] Trial 693 finished with value: -4.195358256946409 and parameters: {'alpha': 0.006480372189022248, 'l1_ratio': 0.002209223931804206}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:23,341] Trial 695 finished with value: -0.11751864180565767 and parameters: {'alpha': 13591.16886766134, 'l1_ratio': 6.60805856099324e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:23,344] Trial 697 finished with value: -4.039802979014861 and parameters: {'alpha': 0.00755454272174655, 'l1_ratio': 2.328814455776443e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:23,629] Trial 699 finished with value: 0.06148052210098217 and parameters: {'alpha': 1034494.89251067, 'l1_ratio': 2.3928250662267415e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:24,017] Trial 701 finished with value: 0.06260661696773362 and parameters: {'alpha': 981751.5010278242, 'l1_ratio': 1.0513887389977588e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:24,352] Trial 703 finished with value: -3.856509155747166 and parameters: {'alpha': 3.9744729570482204e-10, 'l1_ratio': 0.08021280881225508}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:24,677] Trial 702 finished with value: 0.05499298606800548 and parameters: {'alpha': 275909.94025652437, 'l1_ratio': 3.8510503852029657e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:25,001] Trial 705 finished with value: 0.023579861441464327 and parameters: {'alpha': 3416110.4817743967, 'l1_ratio': 1.1163578011526356e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:26,096] Trial 700 finished with value: -2.3615008108221422 and parameters: {'alpha': 0.0006863723365617584, 'l1_ratio': 4.1646430312329327e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:26,306] Trial 707 finished with value: 0.0019357809551980114 and parameters: {'alpha': 7818399.756161381, 'l1_ratio': 1.2404881555868422e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:28,897] Trial 704 finished with value: -2.214858635165176 and parameters: {'alpha': 0.0005009890177851524, 'l1_ratio': 1.44217842813845e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:28,932] Trial 698 finished with value: -0.2243273956115254 and parameters: {'alpha': 7053.314849778544, 'l1_ratio': 2.2741020932697864e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:29,276] Trial 710 finished with value: 0.063489433085551 and parameters: {'alpha': 384257.28613881336, 'l1_ratio': 5.972190398438478e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:30,960] Trial 711 finished with value: -0.04853426582844685 and parameters: {'alpha': 31819.849266323126, 'l1_ratio': 4.556289064754292e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e+00, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:32,115] Trial 709 finished with value: -3.310212587540685 and parameters: {'alpha': 0.003420494027268122, 'l1_ratio': 5.871354373467709e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.326e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:33,734] Trial 681 finished with value: -1.1743827756682352 and parameters: {'alpha': 239.31559990809487, 'l1_ratio': 3.581129997061531e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:34,168] Trial 714 finished with value: 0.03714208520780249 and parameters: {'alpha': 2304850.5970788775, 'l1_ratio': 2.483677285372198e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:35,895] Trial 680 finished with value: -2.2018186765201837 and parameters: {'alpha': 0.22100820077121988, 'l1_ratio': 9.33303401777033e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:36,044] Trial 716 finished with value: -0.008994363703110056 and parameters: {'alpha': 14680367.376317356, 'l1_ratio': 3.0632187832383955e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:50,112] Trial 688 finished with value: -0.9152876686244391 and parameters: {'alpha': 830.7003151973863, 'l1_ratio': 3.6588306091444805e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:50,296] Trial 718 finished with value: -0.009217972097849803 and parameters: {'alpha': 228166.21947525913, 'l1_ratio': 0.017165240834140005}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.051e-02, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:50,515] Trial 719 finished with value: 0.06730513578268822 and parameters: {'alpha': 696105.5849181149, 'l1_ratio': 8.848606783950805e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:50,697] Trial 720 finished with value: -3.8565164254888487 and parameters: {'alpha': 5.606460079089386e-09, 'l1_ratio': 1.0574375237346318e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:50,963] Trial 721 finished with value: -0.014402210569089524 and parameters: {'alpha': 84635.07889846791, 'l1_ratio': 0.0028677479638927863}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.951e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:53,357] Trial 722 finished with value: -2.6094478492551385 and parameters: {'alpha': 0.0013095402325378623, 'l1_ratio': 4.742939179894337e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:53,553] Trial 723 finished with value: 0.04634305097225803 and parameters: {'alpha': 1760756.7905746882, 'l1_ratio': 1.4983493582881703e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:53,825] Trial 724 finished with value: 0.06669892095057299 and parameters: {'alpha': 476617.04505630076, 'l1_ratio': 1.4830406889372715e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:53,970] Trial 685 finished with value: -1.2405008049308965 and parameters: {'alpha': 138.37760725730797, 'l1_ratio': 6.528874726656731e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:54,008] Trial 725 finished with value: 0.01841093719596835 and parameters: {'alpha': 174320.62319905075, 'l1_ratio': 0.0001328925663804323}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:54,247] Trial 727 finished with value: 0.024767668010808947 and parameters: {'alpha': 3288217.217566733, 'l1_ratio': 1.3799030404757628e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:54,451] Trial 728 finished with value: -0.009217972097849803 and parameters: {'alpha': 7428560519.36143, 'l1_ratio': 0.0003824835096024094}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:54,670] Trial 726 finished with value: 0.046508707452959874 and parameters: {'alpha': 217379.10502910608, 'l1_ratio': 2.4885745149473613e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:54,909] Trial 729 finished with value: 0.06269038000418407 and parameters: {'alpha': 977706.8388188331, 'l1_ratio': 1.0410638980195143e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.924e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:39:55,191] Trial 730 finished with value: 0.060300889806239676 and parameters: {'alpha': 1091180.3830703422, 'l1_ratio': 1.0239233018824343e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:55,407] Trial 732 finished with value: -0.018714000116836365 and parameters: {'alpha': 37281.29798574179, 'l1_ratio': 0.0015787460913061196}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:55,573] Trial 733 finished with value: -0.009217972097849803 and parameters: {'alpha': 7231522.0661079725, 'l1_ratio': 0.0010796617970646948}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:55,765] Trial 734 finished with value: 0.061914431703370486 and parameters: {'alpha': 516598.24743527616, 'l1_ratio': 8.088723702820207e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:55,879] Trial 715 finished with value: -0.45878813321623807 and parameters: {'alpha': 3071.2143606382233, 'l1_ratio': 1.006641527664561e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:56,020] Trial 735 finished with value: -0.010745808505082999 and parameters: {'alpha': 23940516.861500725, 'l1_ratio': 1.039139450579677e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:56,378] Trial 737 finished with value: -0.005784153762230182 and parameters: {'alpha': 73116.07256757819, 'l1_ratio': 0.0008599587492745498}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:56,790] Trial 738 finished with value: 0.04655839593219383 and parameters: {'alpha': 1700582.250785689, 'l1_ratio': 5.786401527196423e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:57,278] Trial 731 finished with value: -0.029899209890623224 and parameters: {'alpha': 44958.899566480824, 'l1_ratio': 1.0171098127941806e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:57,305] Trial 739 finished with value: 0.05942604868168725 and parameters: {'alpha': 323103.82091349975, 'l1_ratio': 2.6266623513148176e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:57,423] Trial 736 finished with value: 0.004858522952673787 and parameters: {'alpha': 89191.51720313368, 'l1_ratio': 1.1290045977129533e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:57,844] Trial 742 finished with value: 0.015446326145384104 and parameters: {'alpha': 4489542.071380486, 'l1_ratio': 5.693973867157587e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:58,075] Trial 740 finished with value: 0.05915658203928894 and parameters: {'alpha': 317955.34855219716, 'l1_ratio': 5.375513872184803e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:58,487] Trial 743 finished with value: 0.06781944374257205 and parameters: {'alpha': 607823.1043501357, 'l1_ratio': 2.433950716905669e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:58,508] Trial 744 finished with value: -0.05840791546531273 and parameters: {'alpha': 17.909081141248826, 'l1_ratio': 0.5520246964645561}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:58,939] Trial 746 finished with value: 0.0652537819223773 and parameters: {'alpha': 843143.4662808758, 'l1_ratio': 2.9632525441798916e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:58,940] Trial 745 finished with value: 0.0652906203878656 and parameters: {'alpha': 841007.8047306647, 'l1_ratio': 2.546002985299213e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:59,213] Trial 747 finished with value: -0.009356341351271094 and parameters: {'alpha': 2501735871.4926353, 'l1_ratio': 1.5932518549961602e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:59,245] Trial 748 finished with value: -0.009256090840063033 and parameters: {'alpha': 9082087676.441992, 'l1_ratio': 2.359023500689071e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:59,546] Trial 741 finished with value: -1.056139808705176 and parameters: {'alpha': 7.895317243577837e-05, 'l1_ratio': 7.111088963001208e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:39:59,758] Trial 751 finished with value: 0.030899655432141977 and parameters: {'alpha': 2762723.273399582, 'l1_ratio': 1.9744317716105955e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:00,380] Trial 713 finished with value: -0.5410724181633141 and parameters: {'alpha': 2431.0694317723987, 'l1_ratio': 2.5769379638560824e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:01,601] Trial 753 finished with value: 0.022047664228859582 and parameters: {'alpha': 125808.39540851224, 'l1_ratio': 4.0930769511867677e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:01,750] Trial 754 finished with value: -0.009217972097849803 and parameters: {'alpha': 1867376.6507762165, 'l1_ratio': 0.008878685851909618}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:04,246] Trial 752 finished with value: -3.463584016437961 and parameters: {'alpha': 0.0020174786833321266, 'l1_ratio': 0.0071792300079837395}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:04,555] Trial 756 finished with value: 0.04744082753302673 and parameters: {'alpha': 222736.5549281018, 'l1_ratio': 3.1258362181229856e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:04,715] Trial 757 finished with value: -0.00422926946155359 and parameters: {'alpha': 11335180.651895111, 'l1_ratio': 1.6066969677437894e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e-02, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:06,363] Trial 758 finished with value: -0.1246907362642549 and parameters: {'alpha': 12649.41594175431, 'l1_ratio': 4.199143478628295e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:06,705] Trial 759 finished with value: 0.0663542012680588 and parameters: {'alpha': 497132.6114752118, 'l1_ratio': 8.953047341638516e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.396e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.246e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.649e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.905e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.529e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:16,448] Trial 706 finished with value: -2.336045203015708 and parameters: {'alpha': 0.3549787186151418, 'l1_ratio': 0.0006089865285543189}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.697e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:26,067] Trial 717 finished with value: -3.058098583510229 and parameters: {'alpha': 1.6214176343819908, 'l1_ratio': 0.0003108527901115663}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.048e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.128e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.302e-02, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:29,703] Trial 762 finished with value: -3.5381438058890016 and parameters: {'alpha': 1.976418878274425e-06, 'l1_ratio': 1.1639980715664856e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:30,013] Trial 763 finished with value: 0.011987797639505526 and parameters: {'alpha': 5083478.669751582, 'l1_ratio': 1.5909576948300816e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:30,307] Trial 764 finished with value: -0.009754780308130298 and parameters: {'alpha': 580041770.0625664, 'l1_ratio': 2.0163223319102777e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:30,918] Trial 708 finished with value: -2.1722702239353566 and parameters: {'alpha': 0.3731209112956914, 'l1_ratio': 4.846872461809842e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:31,167] Trial 766 finished with value: -0.009217972097849803 and parameters: {'alpha': 1420906.4419955413, 'l1_ratio': 0.013559197702324168}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:31,421] Trial 767 finished with value: -3.856510013635244 and parameters: {'alpha': 1.0503300745047056e-09, 'l1_ratio': 3.817411984086354e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:31,932] Trial 768 finished with value: 0.0668825400686071 and parameters: {'alpha': 486013.6534077861, 'l1_ratio': 5.8474611284804165e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:32,332] Trial 769 finished with value: -3.8565089953397322 and parameters: {'alpha': 3.2668331038584156e-10, 'l1_ratio': 4.201227181560583e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:32,702] Trial 770 finished with value: 0.03211252445830822 and parameters: {'alpha': 155460.00049201673, 'l1_ratio': 7.106868500409712e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:33,033] Trial 771 finished with value: 0.03562334407474684 and parameters: {'alpha': 2408236.8879267364, 'l1_ratio': 2.174666988125224e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:35,469] Trial 765 finished with value: -1.6912518560541971 and parameters: {'alpha': 0.00013611991236980346, 'l1_ratio': 3.825308332476178e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:35,580] Trial 712 finished with value: -2.156402209161921 and parameters: {'alpha': 0.24402869612523756, 'l1_ratio': 2.0250117845666242e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:35,892] Trial 773 finished with value: -0.011844028560026754 and parameters: {'alpha': 36043209.52611733, 'l1_ratio': 1.9429318293706993e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:36,006] Trial 774 finished with value: 0.054377024714121425 and parameters: {'alpha': 635823.7351677846, 'l1_ratio': 1.868055349072455e-05}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e-02, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:36,467] Trial 776 finished with value: 0.04667266527631272 and parameters: {'alpha': 246295.34883764642, 'l1_ratio': 1.3889513701615529e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:36,492] Trial 775 finished with value: 0.06720399409877546 and parameters: {'alpha': 705987.5658731627, 'l1_ratio': 3.0062369336574125e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:36,777] Trial 777 finished with value: -0.01084905614053929 and parameters: {'alpha': 163220413.21199265, 'l1_ratio': 4.861911238270823e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:38,838] Trial 779 finished with value: -0.0701325501703473 and parameters: {'alpha': 22705.27136996797, 'l1_ratio': 3.925793649261029e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:39,599] Trial 780 finished with value: 0.012759820126681013 and parameters: {'alpha': 104329.76329066891, 'l1_ratio': 3.0551847394791835e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:39,973] Trial 781 finished with value: 0.052055573619819016 and parameters: {'alpha': 1463181.0853444387, 'l1_ratio': 1.4706220341235832e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:40,133] Trial 782 finished with value: -0.010080961058516339 and parameters: {'alpha': 369900907.5537123, 'l1_ratio': 1.0424964246797843e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:40,371] Trial 783 finished with value: -3.8566729236904886 and parameters: {'alpha': 3.253729869050204e-08, 'l1_ratio': 0.000209033955450476}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.239e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:40,609] Trial 750 finished with value: -3.2658155342718542 and parameters: {'alpha': 0.2806447990012812, 'l1_ratio': 0.020575259522941345}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:41,023] Trial 785 finished with value: -3.85659038906476 and parameters: {'alpha': 1.0040361272907678e-08, 'l1_ratio': 0.0410510892723691}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:41,250] Trial 778 finished with value: -1.999108868370215 and parameters: {'alpha': 0.00023931057645605578, 'l1_ratio': 4.8428436556797394e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:41,432] Trial 786 finished with value: -0.003238153595457168 and parameters: {'alpha': 10583099.558422538, 'l1_ratio': 1.3463603045550343e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:41,647] Trial 787 finished with value: -0.00929626479446847 and parameters: {'alpha': 3719233925.799338, 'l1_ratio': 7.461786665979889e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:41,805] Trial 788 finished with value: -0.009217972097849803 and parameters: {'alpha': 3902672.969334523, 'l1_ratio': 0.013771407420871691}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:42,019] Trial 790 finished with value: 0.04961184858276302 and parameters: {'alpha': 242261.80415420103, 'l1_ratio': 2.3740649617090815e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:43,267] Trial 791 finished with value: -0.02458584207048098 and parameters: {'alpha': 49874.02053314193, 'l1_ratio': 5.708449854510694e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:43,634] Trial 792 finished with value: 0.06764772719137835 and parameters: {'alpha': 547528.4209935254, 'l1_ratio': 1.6150441990230892e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:46,904] Trial 755 finished with value: -3.657981750855377 and parameters: {'alpha': 0.23066298754726858, 'l1_ratio': 0.03054482621878648}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:47,104] Trial 794 finished with value: 0.0359388004999488 and parameters: {'alpha': 407569.0600921986, 'l1_ratio': 7.494562445880486e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:47,405] Trial 795 finished with value: -0.01146424949299226 and parameters: {'alpha': 106160208.31634973, 'l1_ratio': 1.6490925045206917e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:47,703] Trial 796 finished with value: 0.05071145778628942 and parameters: {'alpha': 1537446.3810764484, 'l1_ratio': 1.8925644019128425e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:47,850] Trial 797 finished with value: -3.856511346167558 and parameters: {'alpha': 1.997265199967777e-09, 'l1_ratio': 2.3276942172319455e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.207e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:49,874] Trial 749 finished with value: -4.265550432341362 and parameters: {'alpha': 0.03436355916208976, 'l1_ratio': 2.2716910696164788e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:40:57,206] Trial 772 finished with value: -4.357624612471747 and parameters: {'alpha': 0.017396158548084493, 'l1_ratio': 2.4847909292610375e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:40:57,481] Trial 800 finished with value: 0.04950545989620595 and parameters: {'alpha': 235263.69695564164, 'l1_ratio': 1.3503022016432518e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.012e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.812e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:11,248] Trial 760 finished with value: -2.959848836848348 and parameters: {'alpha': 1.8644216796025568, 'l1_ratio': 1.457821196177146e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:11,747] Trial 784 finished with value: -4.591421073477399 and parameters: {'alpha': 0.01968901697743409, 'l1_ratio': 4.843662345459469e-05}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.129e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:11,952] Trial 803 finished with value: 0.06329638343410675 and parameters: {'alpha': 947283.4541690624, 'l1_ratio': 6.622830713525069e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:12,626] Trial 804 finished with value: -0.004429316559375803 and parameters: {'alpha': 74273.65817772987, 'l1_ratio': 7.975474210509958e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.763e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:24,784] Trial 761 finished with value: -2.855052690281041 and parameters: {'alpha': 1.0025096856287439, 'l1_ratio': 1.5152699287490367e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:25,032] Trial 806 finished with value: -0.009563811075147552 and parameters: {'alpha': 982415731.8729794, 'l1_ratio': 1.034986467193955e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.908e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.449e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:32,842] Trial 807 finished with value: -0.2166252935312896 and parameters: {'alpha': 7315.29614387632, 'l1_ratio': 3.021506334200679e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.979e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:39,106] Trial 805 finished with value: -0.6693675987371486 and parameters: {'alpha': 1712.6329531646431, 'l1_ratio': 3.0100050168646504e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:39,496] Trial 809 finished with value: 0.02207940800741411 and parameters: {'alpha': 3603778.3342736, 'l1_ratio': 1.5075017624065384e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:39,850] Trial 810 finished with value: -3.8565137013615365 and parameters: {'alpha': 3.6708698969308817e-09, 'l1_ratio': 7.065130245607659e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:47,398] Trial 789 finished with value: -1.3072607923043178 and parameters: {'alpha': 85.27081337192388, 'l1_ratio': 1.737336427305315e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.220e-01, tolerance: 1.853e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:50,978] Trial 793 finished with value: -2.4050455408475635 and parameters: {'alpha': 9.095169870639973, 'l1_ratio': 1.8389539944031077e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:50,980] Trial 801 finished with value: -2.542433466999074 and parameters: {'alpha': 7.372800414675411, 'l1_ratio': 8.212629011773439e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:51,424] Trial 814 finished with value: -0.009217972097849803 and parameters: {'alpha': 423992.9449224749, 'l1_ratio': 0.0041718448102631926}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:51,539] Trial 813 finished with value: 0.06751629707846596 and parameters: {'alpha': 531183.3693614481, 'l1_ratio': 9.613412315470086e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:52,043] Trial 816 finished with value: 0.04865368444102417 and parameters: {'alpha': 1641164.7113946134, 'l1_ratio': 4.0455229660843606e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:52,336] Trial 817 finished with value: 0.0037435247825089446 and parameters: {'alpha': 129691.0017510039, 'l1_ratio': 0.0005060501212783179}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:54,138] Trial 798 finished with value: -2.4602484497410897 and parameters: {'alpha': 8.373517361426398, 'l1_ratio': 1.0436777891929025e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:54,337] Trial 819 finished with value: -0.009217972097849803 and parameters: {'alpha': 204000.72032298282, 'l1_ratio': 0.003999453650374852}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:54,581] Trial 820 finished with value: -0.009551431053265688 and parameters: {'alpha': 19325780.66903566, 'l1_ratio': 4.663729090679152e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:55,944] Trial 821 finished with value: -3.859475959404803 and parameters: {'alpha': 7.498778601773383e-08, 'l1_ratio': 2.8993955544494155e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:56,085] Trial 822 finished with value: -0.009217972097849803 and parameters: {'alpha': 5791482.964838903, 'l1_ratio': 0.0011173595964003827}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.676e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:41:56,423] Trial 823 finished with value: 0.06271085591436631 and parameters: {'alpha': 959468.7705347142, 'l1_ratio': 2.898927246893588e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:56,468] Trial 799 finished with value: -1.9222656966848854 and parameters: {'alpha': 18.438989026833728, 'l1_ratio': 1.2830958329155039e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:57,308] Trial 825 finished with value: -0.06449258636045958 and parameters: {'alpha': 24310.8547025797, 'l1_ratio': 3.979977027142796e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:57,624] Trial 826 finished with value: 0.030828949050089927 and parameters: {'alpha': 2762858.4254861963, 'l1_ratio': 3.402773937936016e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:58,362] Trial 824 finished with value: -0.03682834172747074 and parameters: {'alpha': 39366.833193836894, 'l1_ratio': 4.1087655580673626e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:58,667] Trial 828 finished with value: -0.009217972097849803 and parameters: {'alpha': 151938.44777051295, 'l1_ratio': 0.15115042644720963}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:41:59,745] Trial 827 finished with value: -3.9276168127704825 and parameters: {'alpha': 4.1948651374502446e-07, 'l1_ratio': 4.7058245020921845e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.707e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:00,031] Trial 830 finished with value: -3.8567362069977604 and parameters: {'alpha': 4.8934329452918445e-08, 'l1_ratio': 1.0371942638150739e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:01,692] Trial 831 finished with value: -3.920520438773569 and parameters: {'alpha': 2.717766256931225e-07, 'l1_ratio': 3.919968385234505e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:02,041] Trial 832 finished with value: -0.009217972097849803 and parameters: {'alpha': 493291.11715000443, 'l1_ratio': 0.03728514932770237}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:07,729] Trial 833 finished with value: -2.1050259432554146 and parameters: {'alpha': 0.000331449530842874, 'l1_ratio': 3.026616282654061e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:07,927] Trial 834 finished with value: -0.009217972097849803 and parameters: {'alpha': 1681876.8884245362, 'l1_ratio': 0.0022054684614002686}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:08,256] Trial 835 finished with value: 0.06443302594996266 and parameters: {'alpha': 882681.2562062718, 'l1_ratio': 1.0379037665080659e-07}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.460e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:11,516] Trial 836 finished with value: -2.2289625542521767 and parameters: {'alpha': 7.121350780898321e-06, 'l1_ratio': 5.744409025235225e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:11,767] Trial 837 finished with value: -0.009217972097849803 and parameters: {'alpha': 6884933.103329185, 'l1_ratio': 0.0003089245896306685}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.140e-01, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:12,974] Trial 838 finished with value: 0.0038064561836220014 and parameters: {'alpha': 87355.38894265142, 'l1_ratio': 5.9226409516460464e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:13,255] Trial 839 finished with value: -0.009217972097849803 and parameters: {'alpha': 57613795.688766435, 'l1_ratio': 0.22185311161450635}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:13,432] Trial 840 finished with value: 0.05193834726501356 and parameters: {'alpha': 267720.28312104417, 'l1_ratio': 4.530362966034403e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.563e-02, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:13,864] Trial 841 finished with value: 0.06782344961987212 and parameters: {'alpha': 589303.0631451209, 'l1_ratio': 1.813041020414431e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:14,248] Trial 842 finished with value: 0.030849761790359437 and parameters: {'alpha': 2766768.8824616075, 'l1_ratio': 1.9239875418108632e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:14,793] Trial 843 finished with value: 0.058948313738047875 and parameters: {'alpha': 1153601.6498903655, 'l1_ratio': 2.0844225620253105e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.771e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:15,469] Trial 844 finished with value: 0.04999461369903346 and parameters: {'alpha': 238391.77405404174, 'l1_ratio': 1.5547576941493196e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:15,663] Trial 845 finished with value: -0.0036708333706761964 and parameters: {'alpha': 10903446.527965408, 'l1_ratio': 3.017668066359702e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:16,000] Trial 846 finished with value: -3.8565181483139472 and parameters: {'alpha': 6.7438228247354875e-09, 'l1_ratio': 0.009478688888453839}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:16,303] Trial 847 finished with value: -0.009217972097849803 and parameters: {'alpha': 10644.322528287581, 'l1_ratio': 0.08593908652460201}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:16,610] Trial 848 finished with value: -3.856511259388286 and parameters: {'alpha': 1.9355982264779088e-09, 'l1_ratio': 1.3403890631807616e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+00, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:20,025] Trial 849 finished with value: -2.3915171558898733 and parameters: {'alpha': 0.0007440416102248691, 'l1_ratio': 7.105009044844942e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:20,279] Trial 850 finished with value: -0.00692624055324927 and parameters: {'alpha': 72144.97206223302, 'l1_ratio': 6.043913961097328e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:20,488] Trial 851 finished with value: -0.009217972097849803 and parameters: {'alpha': 2737857994.9208865, 'l1_ratio': 0.2616690276241866}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:20,977] Trial 852 finished with value: 0.06760340794521631 and parameters: {'alpha': 539875.4104141656, 'l1_ratio': 1.0129894646215944e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.350e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:23,020] Trial 802 finished with value: -1.9733002217574251 and parameters: {'alpha': 17.058093196898064, 'l1_ratio': 6.913864023335713e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:23,375] Trial 854 finished with value: 0.04169354682393012 and parameters: {'alpha': 2020066.5796943873, 'l1_ratio': 4.206763914776309e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:24,579] Trial 855 finished with value: 0.03139116442244139 and parameters: {'alpha': 153012.49881867995, 'l1_ratio': 2.4031606791040955e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:25,052] Trial 856 finished with value: 0.06444846198984133 and parameters: {'alpha': 875393.0313702784, 'l1_ratio': 2.0404415387566078e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:25,532] Trial 857 finished with value: 0.004252928542723855 and parameters: {'alpha': 3662731.2487712204, 'l1_ratio': 9.35407268694882e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.379e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.192e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.453e-01, tolerance: 1.853e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.439e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:34,880] Trial 808 finished with value: -1.9549727998461444 and parameters: {'alpha': 17.535479038496433, 'l1_ratio': 4.173379086761114e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:35,386] Trial 859 finished with value: 0.06012895691538082 and parameters: {'alpha': 330033.27480039845, 'l1_ratio': 5.923029679680738e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:38,370] Trial 860 finished with value: -1.1273392237513125 and parameters: {'alpha': 3.6333584737037876e-05, 'l1_ratio': 0.025260586321238326}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.906e-01, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:41,310] Trial 861 finished with value: -0.05009593891305001 and parameters: {'alpha': 30977.414825316948, 'l1_ratio': 8.411072088093823e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:41,573] Trial 862 finished with value: 0.0582342082904825 and parameters: {'alpha': 1186286.0853016626, 'l1_ratio': 1.4798996874580397e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.607e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:47,282] Trial 811 finished with value: -2.564371554991166 and parameters: {'alpha': 7.118474663574928, 'l1_ratio': 6.975211504643403e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.323e-01, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.033e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:42:53,410] Trial 815 finished with value: -1.4977123447046004 and parameters: {'alpha': 38.96261088509538, 'l1_ratio': 0.00016588353117751386}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:53,794] Trial 865 finished with value: -3.85651032049242 and parameters: {'alpha': 6.466103534820147e-10, 'l1_ratio': 0.7060880725752188}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:54,535] Trial 866 finished with value: 0.06310667159217342 and parameters: {'alpha': 376057.0951408124, 'l1_ratio': 1.7045574731366736e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:55,092] Trial 867 finished with value: -3.8566763696443283 and parameters: {'alpha': 3.4854435284450186e-08, 'l1_ratio': 2.2143140812234427e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:42:57,288] Trial 868 finished with value: 0.022588599367966904 and parameters: {'alpha': 127210.81480450911, 'l1_ratio': 3.586643860442694e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.227e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:43:01,495] Trial 818 finished with value: -1.8431827724812277 and parameters: {'alpha': 20.892201907370143, 'l1_ratio': 3.7907725326092186e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:01,964] Trial 853 finished with value: -0.6032788369671954 and parameters: {'alpha': 2049.8397930826227, 'l1_ratio': 3.453647785847728e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:43:04,231] Trial 812 finished with value: -1.453499155794816 and parameters: {'alpha': 46.71559280759034, 'l1_ratio': 6.248596999849199e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:04,709] Trial 872 finished with value: -0.009217972097849803 and parameters: {'alpha': 7545093.99703769, 'l1_ratio': 0.0061687861752260376}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:05,023] Trial 871 finished with value: -3.4675642039465493 and parameters: {'alpha': 2.524891468606996e-06, 'l1_ratio': 8.352029833067894e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:05,253] Trial 873 finished with value: 0.03990716644314881 and parameters: {'alpha': 2127674.724891388, 'l1_ratio': 7.301034706115636e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:05,578] Trial 874 finished with value: 0.04331978777133146 and parameters: {'alpha': 1918815.4327242118, 'l1_ratio': 7.51238454203677e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.264e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.852e-01, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.117e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:43:14,319] Trial 829 finished with value: -1.01002418633323 and parameters: {'alpha': 586.3831109319399, 'l1_ratio': 1.6172335186047338e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:14,594] Trial 877 finished with value: 0.06676630857331667 and parameters: {'alpha': 610527.7388149714, 'l1_ratio': 1.1703388524368892e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:14,846] Trial 878 finished with value: -0.009355613210299799 and parameters: {'alpha': 1653285107.3348975, 'l1_ratio': 1.0899456066459686e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:14,996] Trial 879 finished with value: -0.009217972097849803 and parameters: {'alpha': 146563.67526697883, 'l1_ratio': 0.06523965934336724}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:15,224] Trial 880 finished with value: -3.856509149659195 and parameters: {'alpha': 4.3634950820066404e-10, 'l1_ratio': 2.00562073470478e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:15,502] Trial 870 finished with value: -0.478948907222473 and parameters: {'alpha': 2895.7712346268113, 'l1_ratio': 1.1330059517714833e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:18,905] Trial 882 finished with value: -3.7935302656411913 and parameters: {'alpha': 8.360936445357051e-07, 'l1_ratio': 3.1615711657411844e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.717e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.337e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.115e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:43:31,667] Trial 858 finished with value: -1.5502857336735045 and parameters: {'alpha': 36.35862295518713, 'l1_ratio': 1.9287110759837353e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:31,869] Trial 884 finished with value: -0.011909890337946613 and parameters: {'alpha': 35603100.35694211, 'l1_ratio': 2.327467645672153e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:32,088] Trial 885 finished with value: -0.00993943246511734 and parameters: {'alpha': 393650590.1569659, 'l1_ratio': 5.3940076530745726e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+00, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.320e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:43:39,773] Trial 869 finished with value: -0.8207421463586927 and parameters: {'alpha': 1117.9046981620024, 'l1_ratio': 9.928859515764586e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:43,937] Trial 887 finished with value: -2.0183553196280424 and parameters: {'alpha': 1.0833115749234173e-05, 'l1_ratio': 5.217826326981102e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:44,583] Trial 888 finished with value: 0.06307880733553861 and parameters: {'alpha': 375543.51735248545, 'l1_ratio': 5.36801903983023e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:45,249] Trial 889 finished with value: -0.02197012574915676 and parameters: {'alpha': 54009.81583800131, 'l1_ratio': 1.5816898561018075e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:45,620] Trial 890 finished with value: 0.06545037616412197 and parameters: {'alpha': 831569.3894803834, 'l1_ratio': 1.1730242504664348e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.383e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.601e+00, tolerance: 1.853e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.992e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:43:51,498] Trial 864 finished with value: -1.12781679169275 and parameters: {'alpha': 328.0808101846841, 'l1_ratio': 2.7950502294113393e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:51,696] Trial 863 finished with value: -2.9664075035069306 and parameters: {'alpha': 2.4625175200284892, 'l1_ratio': 1.5700774807097838e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:51,864] Trial 892 finished with value: -0.01170467585264634 and parameters: {'alpha': 4680887.559246782, 'l1_ratio': 3.625466093551415e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:52,044] Trial 893 finished with value: 0.013719882603268951 and parameters: {'alpha': 4771555.381970951, 'l1_ratio': 7.614249952432061e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:52,275] Trial 894 finished with value: -0.010081333422450989 and parameters: {'alpha': 21328275.744898513, 'l1_ratio': 1.856291184328934e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:52,555] Trial 895 finished with value: 0.05427531514010808 and parameters: {'alpha': 270650.4594865274, 'l1_ratio': 2.1803025381771586e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:53,072] Trial 897 finished with value: -0.010880113850970504 and parameters: {'alpha': 157197302.39682984, 'l1_ratio': 5.98078978407752e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:53,735] Trial 898 finished with value: -0.009217972097849803 and parameters: {'alpha': 939708.5610215265, 'l1_ratio': 0.0007179374663967828}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:53,824] Trial 896 finished with value: 0.05423778446371741 and parameters: {'alpha': 269519.0391037122, 'l1_ratio': 1.0405831061631151e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:43:56,840] Trial 891 finished with value: -0.26388203853707765 and parameters: {'alpha': 5933.9338742228965, 'l1_ratio': 3.235708250049072e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:58,121] Trial 901 finished with value: -0.002203569507449784 and parameters: {'alpha': 77586.26217579657, 'l1_ratio': 3.5616060274655905e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:43:58,679] Trial 902 finished with value: 0.049320936892275936 and parameters: {'alpha': 1577631.606113688, 'l1_ratio': 3.862991720008397e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:00,012] Trial 900 finished with value: -0.10477618379870816 and parameters: {'alpha': 15245.04213617963, 'l1_ratio': 3.783688277941332e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:00,391] Trial 904 finished with value: 0.06782500274716922 and parameters: {'alpha': 591502.2556822066, 'l1_ratio': 4.281123036956463e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:00,970] Trial 905 finished with value: 0.06770680126304192 and parameters: {'alpha': 554517.3253424932, 'l1_ratio': 3.447475392833299e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:01,083] Trial 899 finished with value: -3.9612035834977526 and parameters: {'alpha': 0.0064810943791546345, 'l1_ratio': 3.8395715382166044e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:01,479] Trial 906 finished with value: 0.06759656087457315 and parameters: {'alpha': 660937.9034491106, 'l1_ratio': 4.1353871504342054e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:01,636] Trial 907 finished with value: 0.06773388745738058 and parameters: {'alpha': 559442.8449015366, 'l1_ratio': 4.689393389762774e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:01,771] Trial 903 finished with value: -0.06640159108281203 and parameters: {'alpha': 23934.09166839857, 'l1_ratio': 2.9304778719237346e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:02,013] Trial 910 finished with value: -3.856512187186924 and parameters: {'alpha': 2.5949042576757595e-09, 'l1_ratio': 1.801556495831835e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:02,317] Trial 911 finished with value: 0.04024731464814905 and parameters: {'alpha': 2106846.4577415125, 'l1_ratio': 2.636247136646136e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:03,255] Trial 912 finished with value: 0.029980039429822452 and parameters: {'alpha': 148452.94198558177, 'l1_ratio': 3.188635210995049e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:03,406] Trial 913 finished with value: -3.856601465962975 and parameters: {'alpha': 1.825653327229542e-08, 'l1_ratio': 2.0731114417102835e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:03,907] Trial 914 finished with value: -0.006963183008445746 and parameters: {'alpha': 14248800.310397528, 'l1_ratio': 3.9535131481624017e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:07,477] Trial 915 finished with value: -3.8574920487568747 and parameters: {'alpha': 6.53047698545877e-07, 'l1_ratio': 5.703816888825376e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:07,624] Trial 916 finished with value: -0.01198992249725809 and parameters: {'alpha': 68312639.31960261, 'l1_ratio': 1.478934563897817e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.001e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.259e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:09,171] Trial 883 finished with value: -5.7071227862070675 and parameters: {'alpha': 0.0035843859638819233, 'l1_ratio': 0.9944356385977237}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:09,435] Trial 918 finished with value: -0.009217972097849803 and parameters: {'alpha': 254827.1048313333, 'l1_ratio': 0.47014053101955794}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:09,916] Trial 919 finished with value: 0.0606569084634645 and parameters: {'alpha': 1074585.2750093048, 'l1_ratio': 4.700902746671249e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:10,882] Trial 917 finished with value: -1.8820007410726134 and parameters: {'alpha': 0.00018017507684450036, 'l1_ratio': 5.095500027752721e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:11,834] Trial 920 finished with value: -0.00532218937206456 and parameters: {'alpha': 72954.93824208919, 'l1_ratio': 2.986724648753053e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:12,005] Trial 921 finished with value: 0.026023245522313092 and parameters: {'alpha': 136572.55052461982, 'l1_ratio': 2.3929180365677277e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:15,055] Trial 923 finished with value: -1.062323507343052 and parameters: {'alpha': 8.766301056272218e-05, 'l1_ratio': 1.3746649323080464e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:15,352] Trial 924 finished with value: -0.009276086751182522 and parameters: {'alpha': 5992893302.041708, 'l1_ratio': 1.031148060833746e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:15,703] Trial 925 finished with value: 0.024541727970398736 and parameters: {'alpha': 3341663.80797718, 'l1_ratio': 2.1099692094160665e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:16,232] Trial 926 finished with value: 0.06674291370435363 and parameters: {'alpha': 478694.3794108058, 'l1_ratio': 4.12193255404006e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.004e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:17,165] Trial 875 finished with value: -2.9659815496148427 and parameters: {'alpha': 2.1920848980463035, 'l1_ratio': 7.014521028894429e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.613e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:18,411] Trial 876 finished with value: -1.1234027024599635 and parameters: {'alpha': 336.89526002150984, 'l1_ratio': 1.0460592181669445e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:18,586] Trial 927 finished with value: -3.924831610605324 and parameters: {'alpha': 3.380401882370758e-07, 'l1_ratio': 0.00019014836642222056}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:18,801] Trial 929 finished with value: -0.009217972097849803 and parameters: {'alpha': 8595295.082876913, 'l1_ratio': 0.012111135971946217}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:19,107] Trial 930 finished with value: 0.05862123456157168 and parameters: {'alpha': 1168615.2088791102, 'l1_ratio': 2.364282993842866e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:19,390] Trial 928 finished with value: -3.9260915868586728 and parameters: {'alpha': 3.682719426179258e-07, 'l1_ratio': 2.1508622041101392e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:19,954] Trial 932 finished with value: 0.06303060395786027 and parameters: {'alpha': 374654.89342552447, 'l1_ratio': 7.487524663406007e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:20,217] Trial 933 finished with value: 0.06531920102607298 and parameters: {'alpha': 426611.7955911855, 'l1_ratio': 8.334879723431823e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:20,451] Trial 934 finished with value: -3.8565087219756946 and parameters: {'alpha': 1.3241574884341454e-10, 'l1_ratio': 1.0007607754773631e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:20,833] Trial 936 finished with value: -0.009894171013769956 and parameters: {'alpha': 483897680.8400638, 'l1_ratio': 4.5927372483422603e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:21,276] Trial 937 finished with value: -0.009217972097849803 and parameters: {'alpha': 2933899.371210397, 'l1_ratio': 0.0003800127592831307}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:21,666] Trial 938 finished with value: 0.057371754516054106 and parameters: {'alpha': 1225895.810848569, 'l1_ratio': 1.0459147192723736e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:22,134] Trial 931 finished with value: -1.8630652211136285 and parameters: {'alpha': 1.484682420332642e-05, 'l1_ratio': 2.134912329174616e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:22,401] Trial 940 finished with value: -0.009217972097849803 and parameters: {'alpha': 38680.78942425301, 'l1_ratio': 0.16009964419194972}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:22,658] Trial 941 finished with value: 0.03826541596734997 and parameters: {'alpha': 178448.91473300892, 'l1_ratio': 2.5817620359923864e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:22,970] Trial 942 finished with value: 0.01844999768577364 and parameters: {'alpha': 774625.6929629906, 'l1_ratio': 7.868613531604831e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:23,361] Trial 943 finished with value: 0.013696847628009823 and parameters: {'alpha': 4775368.375716864, 'l1_ratio': 1.1898116028975216e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:23,583] Trial 935 finished with value: -1.1762931457844514 and parameters: {'alpha': 2.4695678797662163e-05, 'l1_ratio': 1.0238610667874086e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.678e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:25,396] Trial 945 finished with value: 0.013325587447280038 and parameters: {'alpha': 105499.9951660625, 'l1_ratio': 3.4632519217081e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.485e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:27,803] Trial 881 finished with value: -3.4394767078561004 and parameters: {'alpha': 0.06337059872805333, 'l1_ratio': 3.4629141201575313e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:28,086] Trial 947 finished with value: 0.038442321148996594 and parameters: {'alpha': 1481055.144575554, 'l1_ratio': 9.840755595140107e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.271e-03, tolerance: 1.698e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:29,778] Trial 946 finished with value: -2.4413134647766883 and parameters: {'alpha': 0.0007800743189634179, 'l1_ratio': 9.827125712466427e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:30,173] Trial 949 finished with value: 0.05520012249805687 and parameters: {'alpha': 278355.6821329897, 'l1_ratio': 1.544004324638378e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:31,488] Trial 948 finished with value: -2.30489102367763 and parameters: {'alpha': 0.00047548074480915513, 'l1_ratio': 0.004117719499481992}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:33,577] Trial 951 finished with value: -0.027900591671790043 and parameters: {'alpha': 46740.87268411092, 'l1_ratio': 4.615352097109438e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:33,768] Trial 950 finished with value: -0.22896690318017457 and parameters: {'alpha': 6834.741219889998, 'l1_ratio': 2.4780208298727276e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:33,879] Trial 952 finished with value: 0.053532856085704274 and parameters: {'alpha': 641065.1590973198, 'l1_ratio': 1.9879584507378205e-05}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:34,030] Trial 953 finished with value: -3.8565149654379183 and parameters: {'alpha': 4.5635728727166724e-09, 'l1_ratio': 0.0008946416084412728}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:34,151] Trial 954 finished with value: -0.006539628733857124 and parameters: {'alpha': 13693454.66563096, 'l1_ratio': 1.7390483668710933e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:34,323] Trial 955 finished with value: 0.035702159124010834 and parameters: {'alpha': 2235759.4762640633, 'l1_ratio': 1.3752810750030735e-06}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:34,479] Trial 956 finished with value: 0.030569092190128933 and parameters: {'alpha': 2788650.0566522647, 'l1_ratio': 6.408609676739605e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:34,868] Trial 957 finished with value: 0.032056800608920945 and parameters: {'alpha': 155227.89796768187, 'l1_ratio': 1.561451721186734e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:35,076] Trial 959 finished with value: -0.009217972097849803 and parameters: {'alpha': 436184.32108471694, 'l1_ratio': 0.001701493243459475}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:36,831] Trial 958 finished with value: -1.0458076023711498 and parameters: {'alpha': 6.080734346415218e-05, 'l1_ratio': 1.555061032735683e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.446e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:42,904] Trial 886 finished with value: -3.206632881234374 and parameters: {'alpha': 0.0770415805539375, 'l1_ratio': 5.145280539095894e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:43,261] Trial 962 finished with value: -0.009217972097849803 and parameters: {'alpha': 1124948.7232151537, 'l1_ratio': 0.002897155880311559}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:44,055] Trial 963 finished with value: 0.0026287219591663766 and parameters: {'alpha': 85345.88887175072, 'l1_ratio': 3.0094105628087945e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:44,272] Trial 964 finished with value: 0.0021698091950368426 and parameters: {'alpha': 7719783.427194563, 'l1_ratio': 2.1007333748349696e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:44,940] Trial 965 finished with value: 0.05764090943131195 and parameters: {'alpha': 301083.06969317567, 'l1_ratio': 9.917548900666107e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:45,370] Trial 966 finished with value: 0.06732544512897569 and parameters: {'alpha': 689068.9546323022, 'l1_ratio': 4.757523470608801e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:45,563] Trial 967 finished with value: -0.009217972097849803 and parameters: {'alpha': 588255036.7069148, 'l1_ratio': 5.3784626765604944e-05}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.560e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.163e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.854e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:50,436] Trial 909 finished with value: -4.528176557264837 and parameters: {'alpha': 0.028284283775128066, 'l1_ratio': 2.2998161757105506e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:50,609] Trial 969 finished with value: -3.856508725655939 and parameters: {'alpha': 1.3503132259219638e-10, 'l1_ratio': 2.674513295141442e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:50,733] Trial 970 finished with value: -0.009217972097849803 and parameters: {'alpha': 26510096.887690067, 'l1_ratio': 2.3631883169766507e-05}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.914e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:51,577] Trial 971 finished with value: -0.084012369881667 and parameters: {'alpha': 16116.512739958778, 'l1_ratio': 3.881823128464679e-05}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.730e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:44:56,895] Trial 922 finished with value: -4.670671359014525 and parameters: {'alpha': 0.026737629377944546, 'l1_ratio': 2.0777257746675373e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:44:57,292] Trial 973 finished with value: 0.013220608472089834 and parameters: {'alpha': 168902.32277014246, 'l1_ratio': 0.0001696197549818444}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:01,182] Trial 974 finished with value: -2.9269744047326665 and parameters: {'alpha': 0.002289950230855458, 'l1_ratio': 6.581601509449686e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:01,350] Trial 975 finished with value: 0.020587780578999865 and parameters: {'alpha': 3685693.596008961, 'l1_ratio': 3.9142792069344155e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:01,549] Trial 976 finished with value: -0.011645508978348929 and parameters: {'alpha': 93472458.2193142, 'l1_ratio': 1.8785296445465037e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:01,724] Trial 977 finished with value: 0.05756464393790813 and parameters: {'alpha': 1207661.244907791, 'l1_ratio': 1.4938502896567408e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:02,056] Trial 978 finished with value: 0.06240991663298301 and parameters: {'alpha': 363707.9354489641, 'l1_ratio': 3.0728826768803466e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.424e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:06,830] Trial 979 finished with value: -4.14081073560539 and parameters: {'alpha': 0.006682023083260408, 'l1_ratio': 0.0012159673401584514}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:06,992] Trial 980 finished with value: -0.009217972097849803 and parameters: {'alpha': 3062809056.732158, 'l1_ratio': 0.10678080756114476}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.361e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:09,498] Trial 981 finished with value: -0.03086651020375386 and parameters: {'alpha': 44124.04293411918, 'l1_ratio': 1.1003459598533115e-09}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.364e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:09,892] Trial 908 finished with value: -3.4742756952437706 and parameters: {'alpha': 0.06167685924119784, 'l1_ratio': 2.177026867698545e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:10,046] Trial 982 finished with value: -3.8565984071561044 and parameters: {'alpha': 1.6147394689118218e-08, 'l1_ratio': 6.2297552046162716e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:10,309] Trial 983 finished with value: 0.013535488787800013 and parameters: {'alpha': 754411.1827047182, 'l1_ratio': 0.00010190168824665528}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:10,376] Trial 984 finished with value: 0.03908606854089317 and parameters: {'alpha': 1660629.5649245507, 'l1_ratio': 6.074461327721324e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.117e-03, tolerance: 2.114e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:10,872] Trial 986 finished with value: 0.024476569276882798 and parameters: {'alpha': 132614.3353323277, 'l1_ratio': 8.281827811650566e-07}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:13,290] Trial 985 finished with value: -3.9079335962349453 and parameters: {'alpha': 1.7666528117772447e-07, 'l1_ratio': 1.0967151039905745e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:13,582] Trial 988 finished with value: -0.009217972097849803 and parameters: {'alpha': 6626066.257812156, 'l1_ratio': 0.006065705467377334}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:13,909] Trial 989 finished with value: -0.018437024641349848 and parameters: {'alpha': 238.27287020019725, 'l1_ratio': 0.4071354932392661}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:14,269] Trial 990 finished with value: 0.05355081587503604 and parameters: {'alpha': 264187.9007861193, 'l1_ratio': 6.217136745732852e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:14,442] Trial 991 finished with value: 0.03535230668767453 and parameters: {'alpha': 2426876.4414239624, 'l1_ratio': 2.634615442864488e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:14,698] Trial 992 finished with value: 0.06779852739167373 and parameters: {'alpha': 575893.1357008656, 'l1_ratio': 4.605297063661372e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:14,961] Trial 993 finished with value: 0.06678127272198257 and parameters: {'alpha': 480594.08942924556, 'l1_ratio': 6.866416757526416e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.473e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.847e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:26,217] Trial 961 finished with value: -1.4117717939630363 and parameters: {'alpha': 0.4770230149963652, 'l1_ratio': 0.23418125347867325}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.316e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.083e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:29,341] Trial 944 finished with value: -3.2861858117059044 and parameters: {'alpha': 0.07182217006225336, 'l1_ratio': 4.310364978787253e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:31,605] Trial 996 finished with value: -0.010664288990733387 and parameters: {'alpha': 65649.45360063005, 'l1_ratio': 5.487485811974064e-10}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:32,000] Trial 997 finished with value: 0.03829561513502289 and parameters: {'alpha': 178338.69793763352, 'l1_ratio': 2.419692979797228e-08}. Best is trial 110 with value: 0.0678263814712522.\n",
      "[I 2023-06-16 17:45:32,164] Trial 998 finished with value: -0.009217972097849803 and parameters: {'alpha': 1261012.5074117326, 'l1_ratio': 0.0005226974972467654}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.610e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.949e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:39,205] Trial 939 finished with value: -2.679795242518315 and parameters: {'alpha': 0.13122495219373798, 'l1_ratio': 1.5630919699982776e-06}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.143e+00, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.065e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:43,146] Trial 960 finished with value: -1.0237480932363896 and parameters: {'alpha': 553.9034790869065, 'l1_ratio': 6.243807453162445e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.984e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.056e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:45:49,387] Trial 968 finished with value: -2.7401153651520653 and parameters: {'alpha': 0.7743936363354075, 'l1_ratio': 0.00012626288553179796}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.655e-03, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.652e-02, tolerance: 1.698e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.936e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.327e-03, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:46:03,178] Trial 972 finished with value: -2.8972240820716415 and parameters: {'alpha': 0.1052244817525334, 'l1_ratio': 5.838944723204594e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e-03, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.505e-02, tolerance: 2.114e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+00, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:46:13,874] Trial 987 finished with value: -1.0249740095733502 and parameters: {'alpha': 550.9983362374744, 'l1_ratio': 4.6491157101832785e-08}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-01, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:46:15,693] Trial 994 finished with value: -2.9616417447103562 and parameters: {'alpha': 2.634606068052656, 'l1_ratio': 4.291026326464676e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:46:23,213] Trial 995 finished with value: -2.306773338494873 and parameters: {'alpha': 0.1903240545984744, 'l1_ratio': 4.6107446128351667e-10}. Best is trial 110 with value: 0.0678263814712522.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.120e-02, tolerance: 1.853e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:46:27,130] Trial 999 finished with value: -2.9566478775141696 and parameters: {'alpha': 1.6719153479054807, 'l1_ratio': 1.3101746079665354e-09}. Best is trial 110 with value: 0.0678263814712522.\n",
      "0.0678263814712522 {'alpha': 599317.8637732802, 'l1_ratio': 3.8775241987070284e-10}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1e10, log=True)\n",
    "\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 1e-10, 1, log=True)\n",
    "\n",
    "\n",
    "    clf = ElasticNet(max_iter=100000, alpha=alpha, l1_ratio=l1_ratio, random_state=0)\n",
    "\n",
    "    # n_ft = trial.suggest_int('n_ft', 1, 10, log=True)\n",
    "    # clf = RFE(Ridge(max_iter=100000, alpha=alpha, solver=solver), n_features_to_select=n_ft)\n",
    "\n",
    "    estimator = utils.Utils(ionizable_train)\n",
    "    return estimator.cross_value_score(clf)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "trial = study.best_trial\n",
    "print(trial.value, trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T21:46:27.204889319Z",
     "start_time": "2023-06-16T21:24:08.935861258Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      "\tR2\t\t\t\t:\t 0.18285002467498468 \n",
      "\tCV train\t\t:\t -0.10492005464320557 \n",
      "\tCustom CV train\t:\t 0.0678263814712522 \n",
      "\tQ2\t\t\t\t:\t 0.18906383224788048\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          -0.0010098328195528028,
          -0.011296077930571117,
          0.034777071152314355,
          -1.5024784592876343,
          -1.174953364767386,
          -2.108642797494871,
          0.00400445733287047,
          -3.8565105649207716,
          2.920127999291866E-4,
          -0.019875470650102756,
          -2.0843483848884956,
          -3.8622711760459767,
          -1.2141451954744273,
          -3.8565087398318605,
          -3.8565186549481343,
          -2.3736023802198605,
          -4.291153282973293,
          -0.0632773861484754,
          -0.009217972097849803,
          -0.009258465945957361,
          -0.009418227616481664,
          -3.4891438028075594,
          -2.2860388668434224,
          -2.3450855727979247,
          -2.848030811338504,
          -0.0716903103210248,
          -2.9522591851309383,
          -2.509483538204112,
          -0.004422367170267967,
          -1.4193516341799033,
          -0.010017020368572993,
          0.053483421678251264,
          0.0028281042727549277,
          -0.01152397956182701,
          -0.009665043638839244,
          0.06709256597835896,
          0.05606006278211684,
          -0.2116932215842501,
          -0.011920350903106058,
          0.06055107847553017,
          0.061120846503111746,
          -0.01193016511916234,
          -0.012010942818341697,
          -0.749977810626106,
          0.06755068102388358,
          -0.3103462290001178,
          -0.3744606573161654,
          0.059313164684552944,
          0.05988551720749913,
          0.04662710001505984,
          -0.24865949529351672,
          -0.3071428742533792,
          -0.004352549004563315,
          0.06767113932168241,
          -0.1891757340660971,
          -0.8927149418235852,
          -0.0036700574250639515,
          -1.0594168357147604,
          0.06739632915842601,
          0.05173789120382203,
          0.004764086813811279,
          0.06458728720319788,
          -1.049391892799418,
          -0.039970666754965335,
          -0.010555762082375075,
          -0.9658585566189066,
          0.05186496864246518,
          -0.8980096909468468,
          0.06486554423830242,
          -0.009252045369155137,
          0.018568375371639873,
          -1.062841830869715,
          -1.120893135009286,
          -0.9431159668735857,
          -0.034455324889440885,
          0.039488303572486706,
          0.061936775982102565,
          -1.1892095211668674,
          0.0628522986208756,
          0.011464609478371357,
          0.018066119277764876,
          -0.08209855471301182,
          -0.05219260802873497,
          0.06393904448241639,
          -0.06788886302574804,
          0.065288257183639,
          0.01862053876158254,
          -0.011635918281038826,
          0.06675781582660363,
          0.01528527573150218,
          0.06603014340316053,
          0.06762778057154828,
          -0.009397523390874038,
          -0.001707924848566041,
          -0.011731681643030475,
          -0.009378037323975278,
          0.01663931074431387,
          0.030130495553588005,
          0.06751056380775496,
          0.0650887442290415,
          0.006865262284968569,
          0.005424151545247151,
          0.061860974130556134,
          0.005478138283521912,
          0.03351486961304784,
          0.06725570483150851,
          0.04011910370843145,
          0.06765808915511118,
          0.06666825662806293,
          0.06689716407261097,
          0.0678263814712522,
          -4.71635992446003E-4,
          -0.1118245938511458,
          -0.0022392503507592623,
          -0.1502162227418399,
          -0.0956114276068016,
          0.04873390439254891,
          0.03814175248281145,
          -0.14577967094752578,
          0.06656657149620615,
          -0.4950352118702635,
          -0.047359414997742356,
          -0.03819220577713197,
          0.04664272400132711,
          0.04179998252501416,
          0.045092424965616905,
          0.04258817725725328,
          0.049314478703218256,
          0.06253537541689258,
          0.06715820581992653,
          0.06546476451671239,
          0.008221554007407983,
          0.005443660724919567,
          -0.011699196056889663,
          0.0022643079444099787,
          -0.011253999138743068,
          -0.01603520973293678,
          -0.011343310839840415,
          0.06780476579517958,
          0.06351852397421998,
          0.06757983271686896,
          -0.014262720205582799,
          0.03062104941890072,
          -0.5609011574664348,
          0.06721653008962063,
          0.010069598429232532,
          0.031280966137334776,
          0.04097216835750309,
          0.06634018270602911,
          0.030004774330175676,
          0.027878290597069404,
          -0.5422579400127361,
          0.06575955526327182,
          0.06624910922817058,
          -0.02769039089174456,
          -0.037574396691252475,
          -0.00916782114115274,
          0.054950728036399665,
          0.061762084454942134,
          0.06472674857944194,
          -0.4583543150513079,
          -0.48317710968910316,
          0.0678027470673765,
          0.013469461490132914,
          0.03875188398138122,
          0.054235279935850866,
          -0.004937071126575747,
          0.06773802635952912,
          0.06701205047376646,
          0.06684030568206482,
          0.044384441396601394,
          0.019796676385155032,
          0.018619395657449116,
          0.0676990994901681,
          -2.205071679466721,
          0.0381744655522119,
          0.05671934762068587,
          -0.0096251742061364,
          0.06738170941147592,
          0.06609626948702026,
          -0.0050926533649281085,
          0.04819089455760713,
          0.05304899840624958,
          -0.06314772536992282,
          -1.2439018590588569,
          0.006188575629748024,
          -1.2857689183117536,
          -0.00925366310666198,
          0.06704430991620595,
          0.06499402488703121,
          0.032925997583604184,
          0.04655476000905571,
          0.06774181491062851,
          0.005870480715862454,
          0.06715926339601042,
          0.055539066809278115,
          0.055474140044195853,
          0.04156672260589467,
          0.0627775642438183,
          -2.386777295269801,
          0.06743955248946583,
          -1.322908746371077,
          0.014808796199520025,
          0.007357871525452124,
          0.06748480871888733,
          -1.1936936088140095,
          -2.056786421069551,
          -1.3531876272624346,
          0.06723164218051303,
          0.06621136694866418,
          0.032878972870139335,
          0.025202077329751882,
          0.06750190252652825,
          -3.995476640182349,
          0.05613737453175749,
          0.04903260118881162,
          -0.030615174152583784,
          0.06754843568481798,
          0.06716305176974213,
          0.035349988719423076,
          -4.020301925183382,
          0.05598254986558038,
          0.06627025405276506,
          -4.653994723081402,
          -0.005498260369548887,
          0.020746588801133486,
          0.025755474564641483,
          0.06322369248224617,
          0.06769686436414861,
          0.06049946090792113,
          0.05035739541059022,
          0.025213069410493356,
          0.06435606684759314,
          0.005573295763270554,
          0.05283613973776639,
          0.04285559288121247,
          0.06689390335033236,
          0.06345733481983007,
          0.06531312643067884,
          0.061651767030180195,
          0.051242599174389,
          -2.521012105618737,
          -0.02134734600064514,
          0.06536752804548755,
          -0.010268640469267898,
          0.006664388026633161,
          0.04459366201433427,
          0.03928612639754062,
          0.06763625448616406,
          0.06754337797408543,
          0.06779154264611753,
          -2.941302403658604,
          0.029509313669957054,
          0.06526006638258612,
          0.03974564397488715,
          0.03950327176777069,
          0.05616639502708428,
          0.05447990440038367,
          0.025043745142014944,
          0.05550796530396651,
          0.012800221330007392,
          0.0012154546008110723,
          -2.96666313131891,
          0.06774087483612168,
          0.014852741457029084,
          -0.047043522527560055,
          -2.3072048082820835,
          0.015769379800835665,
          -0.14561478455909269,
          0.06461815577237547,
          -2.906876927587524,
          0.034354959678820074,
          -2.9530121248178696,
          0.05997954457463606,
          -0.010734881007073982,
          0.0511378317390608,
          0.027327985730783582,
          -2.9393004344805855,
          -2.1259741143170707,
          -0.010830839637583245,
          0.06087897608658236,
          -2.8172848464718965,
          0.035932259295867186,
          -0.005944530557091099,
          -0.009217972097849803,
          -3.8565095310430473,
          -0.00925808569102767,
          -2.271378086814556,
          -0.009217972097849803,
          0.06749411490038111,
          4.15710194904569E-4,
          -0.055134100081222916,
          -0.07809410734638977,
          -0.08962784659522512,
          0.05125205592076543,
          0.04972367987756284,
          0.05577006246650192,
          0.05188722051282298,
          0.06775034581243906,
          0.023441759463068812,
          0.012081509721192226,
          -1.6571260901920233,
          0.06778130649800351,
          0.009407951778563314,
          -0.0021335894559217916,
          0.0670648870593858,
          0.062363604921894,
          -0.011968741685072448,
          0.062258881046092375,
          0.06140575906281535,
          0.06307900359625562,
          0.043531707973517055,
          0.0504801934384882,
          0.0449052820896468,
          0.04788089869925779,
          -0.0065857992675054655,
          0.06123407254126038,
          -2.7061523645716186,
          0.027972959858348617,
          0.009400479685411689,
          0.026098724511859277,
          0.009591557642149287,
          -2.5547493174474365,
          0.0659898016920774,
          0.0661812284605835,
          -1.5546271480109182,
          -1.0457939007251043,
          -0.01447482353917077,
          -0.9757832329417666,
          0.02729459656321061,
          -3.015016805584427,
          -0.010065809556867089,
          0.04420842955744934,
          0.06772441423516821,
          0.06779857336800184,
          0.004738513232801426,
          -3.0573084196422715,
          -0.009377325043385213,
          -0.22526513023480754,
          -0.03738561422404244,
          0.06744931892083927,
          0.04711964859490373,
          0.024720980205670113,
          0.06706028859380464,
          -1.5129594514238147,
          0.03785038092882753,
          0.058494925003515975,
          0.0268697582140676,
          -0.011443369787502192,
          -0.02218686269643544,
          0.06674926761567727,
          0.06251171335026107,
          0.04250552359550186,
          0.004267501841302017,
          0.04363509602935319,
          0.06614674706710166,
          -0.009217972097849803,
          0.002682976528344113,
          -0.006272942676783096,
          -0.014202463370378485,
          -0.10148130352149227,
          0.029861300233720505,
          -0.99093011157342,
          -3.812844944122106,
          -3.4865591587046687,
          -0.3289637820932618,
          0.06043884659487094,
          0.06369336263617487,
          -0.24741134911746107,
          -0.5545477043699476,
          0.01948067508666551,
          -1.098308688396379,
          -0.00930671069659413,
          0.03911083239600729,
          0.06633662517506933,
          -2.776076304159275,
          -3.9095951653776946,
          0.04813483878548278,
          -0.03763626142808781,
          0.048348241391149384,
          -0.009217972097849803,
          0.01100996136086363,
          0.0676784710079004,
          -1.0795001980240702,
          0.024043994239420496,
          0.06627345640233928,
          -2.3734388060720617,
          -2.520041608103117,
          0.06505388638010097,
          -0.011808558077662198,
          -0.012039014456542318,
          -0.9651920818141498,
          -2.6826485468794075,
          0.030196272732689915,
          0.06054981529297173,
          -1.2492640516069002,
          -0.009217972097849803,
          -0.011177771670721018,
          0.05463485378829162,
          0.041007951824639455,
          0.0115140760707824,
          0.06729030474603541,
          -2.075909625374493,
          -0.05598310108416593,
          0.02429772829315761,
          -1.9015554824740308,
          -1.1489700480909593,
          0.052331560696828316,
          -0.009217972097849803,
          0.06227251620201905,
          -3.8565971637355303,
          -0.02965861677429941,
          -0.012094370014468373,
          0.06702759076179787,
          0.03215594908124808,
          -1.1892207977496903,
          0.03668681776346805,
          -2.332210398078947,
          0.06272861216106596,
          -0.0024502253407719574,
          -1.2580534118058782,
          -0.010697005443094154,
          -5.224886763923742E-4,
          0.057910724677580516,
          0.02101124804522055,
          0.06443432381836274,
          0.05494583111374055,
          0.05120406801835168,
          0.015179651945153805,
          0.06685977318427812,
          0.015183994833419071,
          -1.8618654202358904,
          -0.028525046300526286,
          -0.11781290388652332,
          0.06713303457139574,
          -0.009217972097849803,
          0.04272496307476459,
          -2.072129881443962,
          0.04547466215294379,
          -1.3483461200425082,
          0.0042304031062859,
          -3.2126983457601037,
          -0.010294357298468912,
          -0.010449208152439105,
          0.06550164142943715,
          -3.8444103250397106,
          0.05395410647818329,
          -2.6374744836504695,
          -0.009217972097849803,
          0.018914246302112803,
          0.0029989241880887065,
          -0.009366016733535284,
          -0.598258864216003,
          0.053828267436091294,
          0.027590027161764546,
          -3.8565107258913005,
          -2.141307810730809,
          -0.8475648925072825,
          0.06529819675263977,
          -0.05637380550222859,
          -1.3292932151410315,
          0.0678217023743668,
          0.04501693242181778,
          0.03798566934471089,
          0.005989635487906431,
          0.06761445039995151,
          -0.19750785017350614,
          0.05902823232568496,
          0.047905128611978744,
          -0.02480473352668644,
          0.06780265020542853,
          -4.693147912007717,
          0.06718517417223113,
          0.03163401727998157,
          -0.002520861989748583,
          0.019825881842120936,
          0.022363581882165213,
          -4.437839704758244,
          -0.011400653881949552,
          0.06594509647882045,
          0.06264698879013857,
          0.020661465598849738,
          -4.04181818083688,
          0.0482957657900962,
          -0.008667368941879064,
          0.0628955913585096,
          -0.012117586358537213,
          -0.7063156177657314,
          -0.012144019450377389,
          0.04468994497676737,
          -3.509704656462726,
          -1.1030348522872775,
          0.05456090623941656,
          0.06308997380368771,
          -2.058187506107567,
          0.013094340173658292,
          -0.005591525401734391,
          -2.6200135749718725,
          -0.1079719992850997,
          -1.0642165529773686,
          -0.009217972097849803,
          0.046403039493297604,
          0.06767661962862233,
          0.03822997259531687,
          -2.1290905117745327,
          -3.8566049104202405,
          0.0632331793734429,
          0.06490656017780742,
          -0.009217972097849803,
          0.004724179522971476,
          -0.2936167166012854,
          0.02204196785743695,
          0.043669543600947845,
          0.06506919577839676,
          -0.011024297409506648,
          -0.009217972097849803,
          -0.006225843202229631,
          -2.645223257905801,
          -3.868971170395043,
          -0.009217972097849803,
          -2.9745389500247152,
          0.0642955348188945,
          -3.3148879680948284,
          -1.0629150264013554,
          0.019742055855544078,
          -0.05351067875792318,
          -3.249101188130747,
          -0.0066217683501080815,
          -0.003292867936953825,
          0.021496329865672997,
          0.0573562107936072,
          -3.0363478326103666,
          -0.009217972097849803,
          -2.896756076871162,
          -2.4942124279458318,
          -3.856508958557434,
          -0.009217972097849803,
          -3.804348648526064,
          -0.012090286486683347,
          0.062238482666346906,
          -3.8565088263395206,
          0.025277094845222114,
          0.05615270369138092,
          -0.010803151600464078,
          0.007434156676620396,
          0.05609101362475977,
          -0.009217972097849803,
          -0.00948539361285842,
          -1.691530463226754,
          -2.617015163722853,
          -3.856510820435966,
          -0.013528735589933727,
          0.0030145969129963257,
          0.06772559513389409,
          0.06560994130408475,
          0.04022441724584406,
          -0.007679075664762558,
          -0.009217972097849803,
          -2.4862648185865455,
          -3.536570648096907,
          -0.36950307368681995,
          0.0509979718271509,
          -0.03295281481604332,
          -0.07421848504097332,
          -4.0544427499776585,
          -2.4237774529122444,
          -0.009217972097849803,
          -4.404367112297588,
          -0.004598378485706951,
          0.06561282244708862,
          -0.009217972097849803,
          -0.7833152184738257,
          0.015231120165538367,
          0.02689726212502097,
          0.06525570984745539,
          -3.8565089383989184,
          0.0493145336716078,
          -0.010564015136056204,
          0.0676758596183797,
          -0.010914263873883981,
          0.06286904947894827,
          0.05967211959288957,
          -0.0015721886208833007,
          -0.11676439868682693,
          0.022301922143658448,
          0.06732852838602572,
          -3.4730550830200606,
          0.013419649955010956,
          -4.099029153452535,
          -3.8566072560928055,
          -2.637214249993943,
          -0.009217972097849803,
          0.045573154801193096,
          0.06530792479409679,
          -0.00243325726865525,
          -0.036068403386039706,
          -0.009217972097849803,
          0.04163188204790728,
          -0.19228850912590256,
          -1.6216000547095688,
          -1.0955496622278462,
          0.03272407500741511,
          -2.521749437720533,
          -0.009217972097849803,
          0.06209205716051547,
          -1.5734144394235068,
          -0.008906777329853047,
          -3.9062124509510108,
          -0.004170501574910094,
          0.041323491884920016,
          -3.652875216210403,
          -3.6461938841021695,
          0.03180108595833379,
          -0.009217972097849803,
          -2.098713418303518,
          -1.487222096882296,
          -2.6327569759644387,
          0.05673319406855715,
          0.007159067288787309,
          0.043314600457022734,
          -2.8301098032944463,
          0.05992501172099788,
          -0.7485723384835185,
          -0.037896495610930524,
          0.019817040713173067,
          -1.1400713217148624,
          0.034031538481568556,
          -0.009437856161261063,
          0.06735263088966832,
          0.05848896398903395,
          -0.010360798196813533,
          -0.009217972097849803,
          -2.7610978027140005,
          -2.9128516051585023,
          -2.1458537093221777,
          0.06235952090050878,
          -4.049903091492712,
          -0.005214816190266906,
          0.0018506953404470543,
          -1.1927043374642607,
          -0.011638278908979319,
          -1.174944591842728,
          -0.08643377886403125,
          -0.06493343927014335,
          0.034216647447407156,
          -1.1516978267623865,
          0.06780042128378143,
          -1.2229196583572925,
          0.045816680688859544,
          -1.0565822454623708,
          -0.01221590627424285,
          -0.0017747281221190219,
          0.008958681956708644,
          0.012559358356002304,
          0.02591354027748875,
          0.02379442231587085,
          -1.8775914859175724,
          -0.009217972097849803,
          0.06288492914744355,
          0.06419178225577293,
          0.0020353254909192264,
          -1.5820862941976896,
          0.06163302915310165,
          -2.0635882948369737,
          -0.0158061924468675,
          -3.909880291604207,
          -0.011754622212772533,
          0.0433186789156789,
          -1.0052004396541712,
          0.06780194858557094,
          -0.0043654884386508845,
          0.04410045452275513,
          -3.8594410504361347,
          -1.2213922138305016,
          -3.856517694500507,
          0.057543605997596114,
          -0.009580037523620355,
          0.06755761949101875,
          -2.9460601263751207,
          0.018494765804547748,
          -2.2018186765201837,
          -1.1743827756682352,
          -0.009852874979431695,
          -0.018757181068662903,
          0.04823559436028676,
          -1.2405008049308965,
          0.06384345995635483,
          0.03613796768762245,
          -0.9152876686244391,
          -3.9288219103737823,
          0.01512376732410666,
          0.011777005667766368,
          -4.021748510574682,
          -4.195358256946409,
          0.06613987038569828,
          -0.11751864180565767,
          -0.009217972097849803,
          -4.039802979014861,
          -0.2243273956115254,
          0.06148052210098217,
          -2.3615008108221422,
          0.06260661696773362,
          0.05499298606800548,
          -3.856509155747166,
          -2.214858635165176,
          0.023579861441464327,
          -2.336045203015708,
          0.0019357809551980114,
          -2.1722702239353566,
          -3.310212587540685,
          0.063489433085551,
          -0.04853426582844685,
          -2.156402209161921,
          -0.5410724181633141,
          0.03714208520780249,
          -0.45878813321623807,
          -0.008994363703110056,
          -3.058098583510229,
          -0.009217972097849803,
          0.06730513578268822,
          -3.8565164254888487,
          -0.014402210569089524,
          -2.6094478492551385,
          0.04634305097225803,
          0.06669892095057299,
          0.01841093719596835,
          0.046508707452959874,
          0.024767668010808947,
          -0.009217972097849803,
          0.06269038000418407,
          0.060300889806239676,
          -0.029899209890623224,
          -0.018714000116836365,
          -0.009217972097849803,
          0.061914431703370486,
          -0.010745808505082999,
          0.004858522952673787,
          -0.005784153762230182,
          0.04655839593219383,
          0.05942604868168725,
          0.05915658203928894,
          -1.056139808705176,
          0.015446326145384104,
          0.06781944374257205,
          -0.05840791546531273,
          0.0652906203878656,
          0.0652537819223773,
          -0.009356341351271094,
          -0.009256090840063033,
          -4.265550432341362,
          -3.2658155342718542,
          0.030899655432141977,
          -3.463584016437961,
          0.022047664228859582,
          -0.009217972097849803,
          -3.657981750855377,
          0.04744082753302673,
          -0.00422926946155359,
          -0.1246907362642549,
          0.0663542012680588,
          -2.959848836848348,
          -2.855052690281041,
          -3.5381438058890016,
          0.011987797639505526,
          -0.009754780308130298,
          -1.6912518560541971,
          -0.009217972097849803,
          -3.856510013635244,
          0.0668825400686071,
          -3.8565089953397322,
          0.03211252445830822,
          0.03562334407474684,
          -4.357624612471747,
          -0.011844028560026754,
          0.054377024714121425,
          0.06720399409877546,
          0.04667266527631272,
          -0.01084905614053929,
          -1.999108868370215,
          -0.0701325501703473,
          0.012759820126681013,
          0.052055573619819016,
          -0.010080961058516339,
          -3.8566729236904886,
          -4.591421073477399,
          -3.85659038906476,
          -0.003238153595457168,
          -0.00929626479446847,
          -0.009217972097849803,
          -1.3072607923043178,
          0.04961184858276302,
          -0.02458584207048098,
          0.06764772719137835,
          -2.4050455408475635,
          0.0359388004999488,
          -0.01146424949299226,
          0.05071145778628942,
          -3.856511346167558,
          -2.4602484497410897,
          -1.9222656966848854,
          0.04950545989620595,
          -2.542433466999074,
          -1.9733002217574251,
          0.06329638343410675,
          -0.004429316559375803,
          -0.6693675987371486,
          -0.009563811075147552,
          -0.2166252935312896,
          -1.9549727998461444,
          0.02207940800741411,
          -3.8565137013615365,
          -2.564371554991166,
          -1.453499155794816,
          0.06751629707846596,
          -0.009217972097849803,
          -1.4977123447046004,
          0.04865368444102417,
          0.0037435247825089446,
          -1.8431827724812277,
          -0.009217972097849803,
          -0.009551431053265688,
          -3.859475959404803,
          -0.009217972097849803,
          0.06271085591436631,
          -0.03682834172747074,
          -0.06449258636045958,
          0.030828949050089927,
          -3.9276168127704825,
          -0.009217972097849803,
          -1.01002418633323,
          -3.8567362069977604,
          -3.920520438773569,
          -0.009217972097849803,
          -2.1050259432554146,
          -0.009217972097849803,
          0.06443302594996266,
          -2.2289625542521767,
          -0.009217972097849803,
          0.0038064561836220014,
          -0.009217972097849803,
          0.05193834726501356,
          0.06782344961987212,
          0.030849761790359437,
          0.058948313738047875,
          0.04999461369903346,
          -0.0036708333706761964,
          -3.8565181483139472,
          -0.009217972097849803,
          -3.856511259388286,
          -2.3915171558898733,
          -0.00692624055324927,
          -0.009217972097849803,
          0.06760340794521631,
          -0.6032788369671954,
          0.04169354682393012,
          0.03139116442244139,
          0.06444846198984133,
          0.004252928542723855,
          -1.5502857336735045,
          0.06012895691538082,
          -1.1273392237513125,
          -0.05009593891305001,
          0.0582342082904825,
          -2.9664075035069306,
          -1.12781679169275,
          -3.85651032049242,
          0.06310667159217342,
          -3.8566763696443283,
          0.022588599367966904,
          -0.8207421463586927,
          -0.478948907222473,
          -3.4675642039465493,
          -0.009217972097849803,
          0.03990716644314881,
          0.04331978777133146,
          -2.9659815496148427,
          -1.1234027024599635,
          0.06676630857331667,
          -0.009355613210299799,
          -0.009217972097849803,
          -3.856509149659195,
          -3.4394767078561004,
          -3.7935302656411913,
          -5.7071227862070675,
          -0.011909890337946613,
          -0.00993943246511734,
          -3.206632881234374,
          -2.0183553196280424,
          0.06307880733553861,
          -0.02197012574915676,
          0.06545037616412197,
          -0.26388203853707765,
          -0.01170467585264634,
          0.013719882603268951,
          -0.010081333422450989,
          0.05427531514010808,
          0.05423778446371741,
          -0.010880113850970504,
          -0.009217972097849803,
          -3.9612035834977526,
          -0.10477618379870816,
          -0.002203569507449784,
          0.049320936892275936,
          -0.06640159108281203,
          0.06782500274716922,
          0.06770680126304192,
          0.06759656087457315,
          0.06773388745738058,
          -3.4742756952437706,
          -4.528176557264837,
          -3.856512187186924,
          0.04024731464814905,
          0.029980039429822452,
          -3.856601465962975,
          -0.006963183008445746,
          -3.8574920487568747,
          -0.01198992249725809,
          -1.8820007410726134,
          -0.009217972097849803,
          0.0606569084634645,
          -0.00532218937206456,
          0.026023245522313092,
          -4.670671359014525,
          -1.062323507343052,
          -0.009276086751182522,
          0.024541727970398736,
          0.06674291370435363,
          -3.924831610605324,
          -3.9260915868586728,
          -0.009217972097849803,
          0.05862123456157168,
          -1.8630652211136285,
          0.06303060395786027,
          0.06531920102607298,
          -3.8565087219756946,
          -1.1762931457844514,
          -0.009894171013769956,
          -0.009217972097849803,
          0.057371754516054106,
          -2.679795242518315,
          -0.009217972097849803,
          0.03826541596734997,
          0.01844999768577364,
          0.013696847628009823,
          -3.2861858117059044,
          0.013325587447280038,
          -2.4413134647766883,
          0.038442321148996594,
          -2.30489102367763,
          0.05520012249805687,
          -0.22896690318017457,
          -0.027900591671790043,
          0.053532856085704274,
          -3.8565149654379183,
          -0.006539628733857124,
          0.035702159124010834,
          0.030569092190128933,
          0.032056800608920945,
          -1.0458076023711498,
          -0.009217972097849803,
          -1.0237480932363896,
          -1.4117717939630363,
          -0.009217972097849803,
          0.0026287219591663766,
          0.0021698091950368426,
          0.05764090943131195,
          0.06732544512897569,
          -0.009217972097849803,
          -2.7401153651520653,
          -3.856508725655939,
          -0.009217972097849803,
          -0.084012369881667,
          -2.8972240820716415,
          0.013220608472089834,
          -2.9269744047326665,
          0.020587780578999865,
          -0.011645508978348929,
          0.05756464393790813,
          0.06240991663298301,
          -4.14081073560539,
          -0.009217972097849803,
          -0.03086651020375386,
          -3.8565984071561044,
          0.013535488787800013,
          0.03908606854089317,
          -3.9079335962349453,
          0.024476569276882798,
          -1.0249740095733502,
          -0.009217972097849803,
          -0.018437024641349848,
          0.05355081587503604,
          0.03535230668767453,
          0.06779852739167373,
          0.06678127272198257,
          -2.9616417447103562,
          -2.306773338494873,
          -0.010664288990733387,
          0.03829561513502289,
          -0.009217972097849803,
          -2.9566478775141696
         ],
         "type": "scatter"
        },
        {
         "name": "Best Value",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          -0.0010098328195528028,
          -0.0010098328195528028,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.034777071152314355,
          0.053483421678251264,
          0.053483421678251264,
          0.053483421678251264,
          0.053483421678251264,
          0.06709256597835896,
          0.06709256597835896,
          0.06709256597835896,
          0.06709256597835896,
          0.06709256597835896,
          0.06709256597835896,
          0.06709256597835896,
          0.06709256597835896,
          0.06709256597835896,
          0.06755068102388358,
          0.06755068102388358,
          0.06755068102388358,
          0.06755068102388358,
          0.06755068102388358,
          0.06755068102388358,
          0.06755068102388358,
          0.06755068102388358,
          0.06755068102388358,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.06767113932168241,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522,
          0.0678263814712522
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        },
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"1cd03118-c3df-49a9-8901-da6efddff727\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1cd03118-c3df-49a9-8901-da6efddff727\")) {                    Plotly.newPlot(                        \"1cd03118-c3df-49a9-8901-da6efddff727\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999],\"y\":[-0.0010098328195528028,-0.011296077930571117,0.034777071152314355,-1.5024784592876343,-1.174953364767386,-2.108642797494871,0.00400445733287047,-3.8565105649207716,0.0002920127999291866,-0.019875470650102756,-2.0843483848884956,-3.8622711760459767,-1.2141451954744273,-3.8565087398318605,-3.8565186549481343,-2.3736023802198605,-4.291153282973293,-0.0632773861484754,-0.009217972097849803,-0.009258465945957361,-0.009418227616481664,-3.4891438028075594,-2.2860388668434224,-2.3450855727979247,-2.848030811338504,-0.0716903103210248,-2.9522591851309383,-2.509483538204112,-0.004422367170267967,-1.4193516341799033,-0.010017020368572993,0.053483421678251264,0.0028281042727549277,-0.01152397956182701,-0.009665043638839244,0.06709256597835896,0.05606006278211684,-0.2116932215842501,-0.011920350903106058,0.06055107847553017,0.061120846503111746,-0.01193016511916234,-0.012010942818341697,-0.749977810626106,0.06755068102388358,-0.3103462290001178,-0.3744606573161654,0.059313164684552944,0.05988551720749913,0.04662710001505984,-0.24865949529351672,-0.3071428742533792,-0.004352549004563315,0.06767113932168241,-0.1891757340660971,-0.8927149418235852,-0.0036700574250639515,-1.0594168357147604,0.06739632915842601,0.05173789120382203,0.004764086813811279,0.06458728720319788,-1.049391892799418,-0.039970666754965335,-0.010555762082375075,-0.9658585566189066,0.05186496864246518,-0.8980096909468468,0.06486554423830242,-0.009252045369155137,0.018568375371639873,-1.062841830869715,-1.120893135009286,-0.9431159668735857,-0.034455324889440885,0.039488303572486706,0.061936775982102565,-1.1892095211668674,0.0628522986208756,0.011464609478371357,0.018066119277764876,-0.08209855471301182,-0.05219260802873497,0.06393904448241639,-0.06788886302574804,0.065288257183639,0.01862053876158254,-0.011635918281038826,0.06675781582660363,0.01528527573150218,0.06603014340316053,0.06762778057154828,-0.009397523390874038,-0.001707924848566041,-0.011731681643030475,-0.009378037323975278,0.01663931074431387,0.030130495553588005,0.06751056380775496,0.0650887442290415,0.006865262284968569,0.005424151545247151,0.061860974130556134,0.005478138283521912,0.03351486961304784,0.06725570483150851,0.04011910370843145,0.06765808915511118,0.06666825662806293,0.06689716407261097,0.0678263814712522,-0.000471635992446003,-0.1118245938511458,-0.0022392503507592623,-0.1502162227418399,-0.0956114276068016,0.04873390439254891,0.03814175248281145,-0.14577967094752578,0.06656657149620615,-0.4950352118702635,-0.047359414997742356,-0.03819220577713197,0.04664272400132711,0.04179998252501416,0.045092424965616905,0.04258817725725328,0.049314478703218256,0.06253537541689258,0.06715820581992653,0.06546476451671239,0.008221554007407983,0.005443660724919567,-0.011699196056889663,0.0022643079444099787,-0.011253999138743068,-0.01603520973293678,-0.011343310839840415,0.06780476579517958,0.06351852397421998,0.06757983271686896,-0.014262720205582799,0.03062104941890072,-0.5609011574664348,0.06721653008962063,0.010069598429232532,0.031280966137334776,0.04097216835750309,0.06634018270602911,0.030004774330175676,0.027878290597069404,-0.5422579400127361,0.06575955526327182,0.06624910922817058,-0.02769039089174456,-0.037574396691252475,-0.00916782114115274,0.054950728036399665,0.061762084454942134,0.06472674857944194,-0.4583543150513079,-0.48317710968910316,0.0678027470673765,0.013469461490132914,0.03875188398138122,0.054235279935850866,-0.004937071126575747,0.06773802635952912,0.06701205047376646,0.06684030568206482,0.044384441396601394,0.019796676385155032,0.018619395657449116,0.0676990994901681,-2.205071679466721,0.0381744655522119,0.05671934762068587,-0.0096251742061364,0.06738170941147592,0.06609626948702026,-0.0050926533649281085,0.04819089455760713,0.05304899840624958,-0.06314772536992282,-1.2439018590588569,0.006188575629748024,-1.2857689183117536,-0.00925366310666198,0.06704430991620595,0.06499402488703121,0.032925997583604184,0.04655476000905571,0.06774181491062851,0.005870480715862454,0.06715926339601042,0.055539066809278115,0.055474140044195853,0.04156672260589467,0.0627775642438183,-2.386777295269801,0.06743955248946583,-1.322908746371077,0.014808796199520025,0.007357871525452124,0.06748480871888733,-1.1936936088140095,-2.056786421069551,-1.3531876272624346,0.06723164218051303,0.06621136694866418,0.032878972870139335,0.025202077329751882,0.06750190252652825,-3.995476640182349,0.05613737453175749,0.04903260118881162,-0.030615174152583784,0.06754843568481798,0.06716305176974213,0.035349988719423076,-4.020301925183382,0.05598254986558038,0.06627025405276506,-4.653994723081402,-0.005498260369548887,0.020746588801133486,0.025755474564641483,0.06322369248224617,0.06769686436414861,0.06049946090792113,0.05035739541059022,0.025213069410493356,0.06435606684759314,0.005573295763270554,0.05283613973776639,0.04285559288121247,0.06689390335033236,0.06345733481983007,0.06531312643067884,0.061651767030180195,0.051242599174389,-2.521012105618737,-0.02134734600064514,0.06536752804548755,-0.010268640469267898,0.006664388026633161,0.04459366201433427,0.03928612639754062,0.06763625448616406,0.06754337797408543,0.06779154264611753,-2.941302403658604,0.029509313669957054,0.06526006638258612,0.03974564397488715,0.03950327176777069,0.05616639502708428,0.05447990440038367,0.025043745142014944,0.05550796530396651,0.012800221330007392,0.0012154546008110723,-2.96666313131891,0.06774087483612168,0.014852741457029084,-0.047043522527560055,-2.3072048082820835,0.015769379800835665,-0.14561478455909269,0.06461815577237547,-2.906876927587524,0.034354959678820074,-2.9530121248178696,0.05997954457463606,-0.010734881007073982,0.0511378317390608,0.027327985730783582,-2.9393004344805855,-2.1259741143170707,-0.010830839637583245,0.06087897608658236,-2.8172848464718965,0.035932259295867186,-0.005944530557091099,-0.009217972097849803,-3.8565095310430473,-0.00925808569102767,-2.271378086814556,-0.009217972097849803,0.06749411490038111,0.000415710194904569,-0.055134100081222916,-0.07809410734638977,-0.08962784659522512,0.05125205592076543,0.04972367987756284,0.05577006246650192,0.05188722051282298,0.06775034581243906,0.023441759463068812,0.012081509721192226,-1.6571260901920233,0.06778130649800351,0.009407951778563314,-0.0021335894559217916,0.0670648870593858,0.062363604921894,-0.011968741685072448,0.062258881046092375,0.06140575906281535,0.06307900359625562,0.043531707973517055,0.0504801934384882,0.0449052820896468,0.04788089869925779,-0.0065857992675054655,0.06123407254126038,-2.7061523645716186,0.027972959858348617,0.009400479685411689,0.026098724511859277,0.009591557642149287,-2.5547493174474365,0.0659898016920774,0.0661812284605835,-1.5546271480109182,-1.0457939007251043,-0.01447482353917077,-0.9757832329417666,0.02729459656321061,-3.015016805584427,-0.010065809556867089,0.04420842955744934,0.06772441423516821,0.06779857336800184,0.004738513232801426,-3.0573084196422715,-0.009377325043385213,-0.22526513023480754,-0.03738561422404244,0.06744931892083927,0.04711964859490373,0.024720980205670113,0.06706028859380464,-1.5129594514238147,0.03785038092882753,0.058494925003515975,0.0268697582140676,-0.011443369787502192,-0.02218686269643544,0.06674926761567727,0.06251171335026107,0.04250552359550186,0.004267501841302017,0.04363509602935319,0.06614674706710166,-0.009217972097849803,0.002682976528344113,-0.006272942676783096,-0.014202463370378485,-0.10148130352149227,0.029861300233720505,-0.99093011157342,-3.812844944122106,-3.4865591587046687,-0.3289637820932618,0.06043884659487094,0.06369336263617487,-0.24741134911746107,-0.5545477043699476,0.01948067508666551,-1.098308688396379,-0.00930671069659413,0.03911083239600729,0.06633662517506933,-2.776076304159275,-3.9095951653776946,0.04813483878548278,-0.03763626142808781,0.048348241391149384,-0.009217972097849803,0.01100996136086363,0.0676784710079004,-1.0795001980240702,0.024043994239420496,0.06627345640233928,-2.3734388060720617,-2.520041608103117,0.06505388638010097,-0.011808558077662198,-0.012039014456542318,-0.9651920818141498,-2.6826485468794075,0.030196272732689915,0.06054981529297173,-1.2492640516069002,-0.009217972097849803,-0.011177771670721018,0.05463485378829162,0.041007951824639455,0.0115140760707824,0.06729030474603541,-2.075909625374493,-0.05598310108416593,0.02429772829315761,-1.9015554824740308,-1.1489700480909593,0.052331560696828316,-0.009217972097849803,0.06227251620201905,-3.8565971637355303,-0.02965861677429941,-0.012094370014468373,0.06702759076179787,0.03215594908124808,-1.1892207977496903,0.03668681776346805,-2.332210398078947,0.06272861216106596,-0.0024502253407719574,-1.2580534118058782,-0.010697005443094154,-0.0005224886763923742,0.057910724677580516,0.02101124804522055,0.06443432381836274,0.05494583111374055,0.05120406801835168,0.015179651945153805,0.06685977318427812,0.015183994833419071,-1.8618654202358904,-0.028525046300526286,-0.11781290388652332,0.06713303457139574,-0.009217972097849803,0.04272496307476459,-2.072129881443962,0.04547466215294379,-1.3483461200425082,0.0042304031062859,-3.2126983457601037,-0.010294357298468912,-0.010449208152439105,0.06550164142943715,-3.8444103250397106,0.05395410647818329,-2.6374744836504695,-0.009217972097849803,0.018914246302112803,0.0029989241880887065,-0.009366016733535284,-0.598258864216003,0.053828267436091294,0.027590027161764546,-3.8565107258913005,-2.141307810730809,-0.8475648925072825,0.06529819675263977,-0.05637380550222859,-1.3292932151410315,0.0678217023743668,0.04501693242181778,0.03798566934471089,0.005989635487906431,0.06761445039995151,-0.19750785017350614,0.05902823232568496,0.047905128611978744,-0.02480473352668644,0.06780265020542853,-4.693147912007717,0.06718517417223113,0.03163401727998157,-0.002520861989748583,0.019825881842120936,0.022363581882165213,-4.437839704758244,-0.011400653881949552,0.06594509647882045,0.06264698879013857,0.020661465598849738,-4.04181818083688,0.0482957657900962,-0.008667368941879064,0.0628955913585096,-0.012117586358537213,-0.7063156177657314,-0.012144019450377389,0.04468994497676737,-3.509704656462726,-1.1030348522872775,0.05456090623941656,0.06308997380368771,-2.058187506107567,0.013094340173658292,-0.005591525401734391,-2.6200135749718725,-0.1079719992850997,-1.0642165529773686,-0.009217972097849803,0.046403039493297604,0.06767661962862233,0.03822997259531687,-2.1290905117745327,-3.8566049104202405,0.0632331793734429,0.06490656017780742,-0.009217972097849803,0.004724179522971476,-0.2936167166012854,0.02204196785743695,0.043669543600947845,0.06506919577839676,-0.011024297409506648,-0.009217972097849803,-0.006225843202229631,-2.645223257905801,-3.868971170395043,-0.009217972097849803,-2.9745389500247152,0.0642955348188945,-3.3148879680948284,-1.0629150264013554,0.019742055855544078,-0.05351067875792318,-3.249101188130747,-0.0066217683501080815,-0.003292867936953825,0.021496329865672997,0.0573562107936072,-3.0363478326103666,-0.009217972097849803,-2.896756076871162,-2.4942124279458318,-3.856508958557434,-0.009217972097849803,-3.804348648526064,-0.012090286486683347,0.062238482666346906,-3.8565088263395206,0.025277094845222114,0.05615270369138092,-0.010803151600464078,0.007434156676620396,0.05609101362475977,-0.009217972097849803,-0.00948539361285842,-1.691530463226754,-2.617015163722853,-3.856510820435966,-0.013528735589933727,0.0030145969129963257,0.06772559513389409,0.06560994130408475,0.04022441724584406,-0.007679075664762558,-0.009217972097849803,-2.4862648185865455,-3.536570648096907,-0.36950307368681995,0.0509979718271509,-0.03295281481604332,-0.07421848504097332,-4.0544427499776585,-2.4237774529122444,-0.009217972097849803,-4.404367112297588,-0.004598378485706951,0.06561282244708862,-0.009217972097849803,-0.7833152184738257,0.015231120165538367,0.02689726212502097,0.06525570984745539,-3.8565089383989184,0.0493145336716078,-0.010564015136056204,0.0676758596183797,-0.010914263873883981,0.06286904947894827,0.05967211959288957,-0.0015721886208833007,-0.11676439868682693,0.022301922143658448,0.06732852838602572,-3.4730550830200606,0.013419649955010956,-4.099029153452535,-3.8566072560928055,-2.637214249993943,-0.009217972097849803,0.045573154801193096,0.06530792479409679,-0.00243325726865525,-0.036068403386039706,-0.009217972097849803,0.04163188204790728,-0.19228850912590256,-1.6216000547095688,-1.0955496622278462,0.03272407500741511,-2.521749437720533,-0.009217972097849803,0.06209205716051547,-1.5734144394235068,-0.008906777329853047,-3.9062124509510108,-0.004170501574910094,0.041323491884920016,-3.652875216210403,-3.6461938841021695,0.03180108595833379,-0.009217972097849803,-2.098713418303518,-1.487222096882296,-2.6327569759644387,0.05673319406855715,0.007159067288787309,0.043314600457022734,-2.8301098032944463,0.05992501172099788,-0.7485723384835185,-0.037896495610930524,0.019817040713173067,-1.1400713217148624,0.034031538481568556,-0.009437856161261063,0.06735263088966832,0.05848896398903395,-0.010360798196813533,-0.009217972097849803,-2.7610978027140005,-2.9128516051585023,-2.1458537093221777,0.06235952090050878,-4.049903091492712,-0.005214816190266906,0.0018506953404470543,-1.1927043374642607,-0.011638278908979319,-1.174944591842728,-0.08643377886403125,-0.06493343927014335,0.034216647447407156,-1.1516978267623865,0.06780042128378143,-1.2229196583572925,0.045816680688859544,-1.0565822454623708,-0.01221590627424285,-0.0017747281221190219,0.008958681956708644,0.012559358356002304,0.02591354027748875,0.02379442231587085,-1.8775914859175724,-0.009217972097849803,0.06288492914744355,0.06419178225577293,0.0020353254909192264,-1.5820862941976896,0.06163302915310165,-2.0635882948369737,-0.0158061924468675,-3.909880291604207,-0.011754622212772533,0.0433186789156789,-1.0052004396541712,0.06780194858557094,-0.0043654884386508845,0.04410045452275513,-3.8594410504361347,-1.2213922138305016,-3.856517694500507,0.057543605997596114,-0.009580037523620355,0.06755761949101875,-2.9460601263751207,0.018494765804547748,-2.2018186765201837,-1.1743827756682352,-0.009852874979431695,-0.018757181068662903,0.04823559436028676,-1.2405008049308965,0.06384345995635483,0.03613796768762245,-0.9152876686244391,-3.9288219103737823,0.01512376732410666,0.011777005667766368,-4.021748510574682,-4.195358256946409,0.06613987038569828,-0.11751864180565767,-0.009217972097849803,-4.039802979014861,-0.2243273956115254,0.06148052210098217,-2.3615008108221422,0.06260661696773362,0.05499298606800548,-3.856509155747166,-2.214858635165176,0.023579861441464327,-2.336045203015708,0.0019357809551980114,-2.1722702239353566,-3.310212587540685,0.063489433085551,-0.04853426582844685,-2.156402209161921,-0.5410724181633141,0.03714208520780249,-0.45878813321623807,-0.008994363703110056,-3.058098583510229,-0.009217972097849803,0.06730513578268822,-3.8565164254888487,-0.014402210569089524,-2.6094478492551385,0.04634305097225803,0.06669892095057299,0.01841093719596835,0.046508707452959874,0.024767668010808947,-0.009217972097849803,0.06269038000418407,0.060300889806239676,-0.029899209890623224,-0.018714000116836365,-0.009217972097849803,0.061914431703370486,-0.010745808505082999,0.004858522952673787,-0.005784153762230182,0.04655839593219383,0.05942604868168725,0.05915658203928894,-1.056139808705176,0.015446326145384104,0.06781944374257205,-0.05840791546531273,0.0652906203878656,0.0652537819223773,-0.009356341351271094,-0.009256090840063033,-4.265550432341362,-3.2658155342718542,0.030899655432141977,-3.463584016437961,0.022047664228859582,-0.009217972097849803,-3.657981750855377,0.04744082753302673,-0.00422926946155359,-0.1246907362642549,0.0663542012680588,-2.959848836848348,-2.855052690281041,-3.5381438058890016,0.011987797639505526,-0.009754780308130298,-1.6912518560541971,-0.009217972097849803,-3.856510013635244,0.0668825400686071,-3.8565089953397322,0.03211252445830822,0.03562334407474684,-4.357624612471747,-0.011844028560026754,0.054377024714121425,0.06720399409877546,0.04667266527631272,-0.01084905614053929,-1.999108868370215,-0.0701325501703473,0.012759820126681013,0.052055573619819016,-0.010080961058516339,-3.8566729236904886,-4.591421073477399,-3.85659038906476,-0.003238153595457168,-0.00929626479446847,-0.009217972097849803,-1.3072607923043178,0.04961184858276302,-0.02458584207048098,0.06764772719137835,-2.4050455408475635,0.0359388004999488,-0.01146424949299226,0.05071145778628942,-3.856511346167558,-2.4602484497410897,-1.9222656966848854,0.04950545989620595,-2.542433466999074,-1.9733002217574251,0.06329638343410675,-0.004429316559375803,-0.6693675987371486,-0.009563811075147552,-0.2166252935312896,-1.9549727998461444,0.02207940800741411,-3.8565137013615365,-2.564371554991166,-1.453499155794816,0.06751629707846596,-0.009217972097849803,-1.4977123447046004,0.04865368444102417,0.0037435247825089446,-1.8431827724812277,-0.009217972097849803,-0.009551431053265688,-3.859475959404803,-0.009217972097849803,0.06271085591436631,-0.03682834172747074,-0.06449258636045958,0.030828949050089927,-3.9276168127704825,-0.009217972097849803,-1.01002418633323,-3.8567362069977604,-3.920520438773569,-0.009217972097849803,-2.1050259432554146,-0.009217972097849803,0.06443302594996266,-2.2289625542521767,-0.009217972097849803,0.0038064561836220014,-0.009217972097849803,0.05193834726501356,0.06782344961987212,0.030849761790359437,0.058948313738047875,0.04999461369903346,-0.0036708333706761964,-3.8565181483139472,-0.009217972097849803,-3.856511259388286,-2.3915171558898733,-0.00692624055324927,-0.009217972097849803,0.06760340794521631,-0.6032788369671954,0.04169354682393012,0.03139116442244139,0.06444846198984133,0.004252928542723855,-1.5502857336735045,0.06012895691538082,-1.1273392237513125,-0.05009593891305001,0.0582342082904825,-2.9664075035069306,-1.12781679169275,-3.85651032049242,0.06310667159217342,-3.8566763696443283,0.022588599367966904,-0.8207421463586927,-0.478948907222473,-3.4675642039465493,-0.009217972097849803,0.03990716644314881,0.04331978777133146,-2.9659815496148427,-1.1234027024599635,0.06676630857331667,-0.009355613210299799,-0.009217972097849803,-3.856509149659195,-3.4394767078561004,-3.7935302656411913,-5.7071227862070675,-0.011909890337946613,-0.00993943246511734,-3.206632881234374,-2.0183553196280424,0.06307880733553861,-0.02197012574915676,0.06545037616412197,-0.26388203853707765,-0.01170467585264634,0.013719882603268951,-0.010081333422450989,0.05427531514010808,0.05423778446371741,-0.010880113850970504,-0.009217972097849803,-3.9612035834977526,-0.10477618379870816,-0.002203569507449784,0.049320936892275936,-0.06640159108281203,0.06782500274716922,0.06770680126304192,0.06759656087457315,0.06773388745738058,-3.4742756952437706,-4.528176557264837,-3.856512187186924,0.04024731464814905,0.029980039429822452,-3.856601465962975,-0.006963183008445746,-3.8574920487568747,-0.01198992249725809,-1.8820007410726134,-0.009217972097849803,0.0606569084634645,-0.00532218937206456,0.026023245522313092,-4.670671359014525,-1.062323507343052,-0.009276086751182522,0.024541727970398736,0.06674291370435363,-3.924831610605324,-3.9260915868586728,-0.009217972097849803,0.05862123456157168,-1.8630652211136285,0.06303060395786027,0.06531920102607298,-3.8565087219756946,-1.1762931457844514,-0.009894171013769956,-0.009217972097849803,0.057371754516054106,-2.679795242518315,-0.009217972097849803,0.03826541596734997,0.01844999768577364,0.013696847628009823,-3.2861858117059044,0.013325587447280038,-2.4413134647766883,0.038442321148996594,-2.30489102367763,0.05520012249805687,-0.22896690318017457,-0.027900591671790043,0.053532856085704274,-3.8565149654379183,-0.006539628733857124,0.035702159124010834,0.030569092190128933,0.032056800608920945,-1.0458076023711498,-0.009217972097849803,-1.0237480932363896,-1.4117717939630363,-0.009217972097849803,0.0026287219591663766,0.0021698091950368426,0.05764090943131195,0.06732544512897569,-0.009217972097849803,-2.7401153651520653,-3.856508725655939,-0.009217972097849803,-0.084012369881667,-2.8972240820716415,0.013220608472089834,-2.9269744047326665,0.020587780578999865,-0.011645508978348929,0.05756464393790813,0.06240991663298301,-4.14081073560539,-0.009217972097849803,-0.03086651020375386,-3.8565984071561044,0.013535488787800013,0.03908606854089317,-3.9079335962349453,0.024476569276882798,-1.0249740095733502,-0.009217972097849803,-0.018437024641349848,0.05355081587503604,0.03535230668767453,0.06779852739167373,0.06678127272198257,-2.9616417447103562,-2.306773338494873,-0.010664288990733387,0.03829561513502289,-0.009217972097849803,-2.9566478775141696],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999],\"y\":[-0.0010098328195528028,-0.0010098328195528028,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.034777071152314355,0.053483421678251264,0.053483421678251264,0.053483421678251264,0.053483421678251264,0.06709256597835896,0.06709256597835896,0.06709256597835896,0.06709256597835896,0.06709256597835896,0.06709256597835896,0.06709256597835896,0.06709256597835896,0.06709256597835896,0.06755068102388358,0.06755068102388358,0.06755068102388358,0.06755068102388358,0.06755068102388358,0.06755068102388358,0.06755068102388358,0.06755068102388358,0.06755068102388358,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.06767113932168241,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522,0.0678263814712522],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('1cd03118-c3df-49a9-8901-da6efddff727');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/Documents/Cours/Stage/QSAR/code/wrapper/utils.py:228: UserWarning:\n",
      "\n",
      "color is redundantly defined by the 'color' keyword argument and the fmt string \"--k\" (-> color='k'). The keyword argument will take precedence.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_utils.display_score(ElasticNet(**study.best_params, random_state=0, max_iter=100000), X_ionizable_train, y_ionizable_train, X_ionizable_test, y_ionizable_test)\n",
    "display(plot_optimization_history(study))\n",
    "\n",
    "rr = ElasticNet(**study.best_params, random_state=0, max_iter=100000).fit(X_ionizable_train, y_ionizable_train)\n",
    "y_ionizable_train_pred = rr.predict(X_ionizable_train)\n",
    "y_ionizable_test_pred = rr.predict(X_ionizable_test)\n",
    "\n",
    "test_utils.display_graph(rr, X_ionizable_train, X_ionizable_test, y_ionizable_train, y_ionizable_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T21:47:56.000978100Z",
     "start_time": "2023-06-16T21:47:54.158191224Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neutral"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 3 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      "\tR2\t\t\t\t:\t 0.8022398748819561 \n",
      "\tCV train\t\t:\t -3.4799038254012253 \n",
      "\tCustom CV train\t:\t 0.20509966980571148 \n",
      "\tQ2\t\t\t\t:\t 0.305519013381093\n"
     ]
    }
   ],
   "source": [
    "test_utils = utils.Utils(neutral_train)\n",
    "test_utils.create_cv_folds(display=True)\n",
    "test_utils.display_score(ElasticNet(max_iter=100000, random_state=0), X_neutral_train, y_neutral_train, X_neutral_test, y_neutral_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T22:21:55.555808696Z",
     "start_time": "2023-06-16T22:21:46.872384007Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:52:39,182] A new study created in memory with name: no-name-ddded9b1-14de-40fa-9992-f98b855c82ee\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96b7353f173d40968371d1e842f4eed5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:52:39,822] Trial 0 finished with value: 0.04185889286312716 and parameters: {'alpha': 5510540.877761282, 'l1_ratio': 1.2795697450371319e-06}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:39,852] Trial 7 finished with value: -0.0010605577384500038 and parameters: {'alpha': 195346514.1972969, 'l1_ratio': 0.04601298513437113}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:39,860] Trial 6 finished with value: 0.005525064164305686 and parameters: {'alpha': 394521017.216104, 'l1_ratio': 1.323701874815849e-10}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:39,881] Trial 5 finished with value: -0.0010605577384500038 and parameters: {'alpha': 28112695.13793499, 'l1_ratio': 0.32389752101433833}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:40,219] Trial 8 finished with value: 0.001811440483309057 and parameters: {'alpha': 68182898.12990662, 'l1_ratio': 7.073786436856081e-07}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:40,230] Trial 9 finished with value: -0.00068001739412434 and parameters: {'alpha': 2890034067.3254886, 'l1_ratio': 6.900680829655471e-08}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:40,239] Trial 11 finished with value: -0.0010605577384500038 and parameters: {'alpha': 3832278180.0949283, 'l1_ratio': 2.4991308677935248e-05}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:40,523] Trial 4 finished with value: -6.377504418091352 and parameters: {'alpha': 1.7502054802078436e-09, 'l1_ratio': 1.0972637816898442e-06}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:41,476] Trial 15 finished with value: -6.37670327168661 and parameters: {'alpha': 3.1377058993965455e-09, 'l1_ratio': 0.309154687664757}. Best is trial 0 with value: 0.04185889286312716.\n",
      "[I 2023-06-16 17:52:41,683] Trial 16 finished with value: 0.34733821447233987 and parameters: {'alpha': 1337.2766790535482, 'l1_ratio': 0.025440283613126096}. Best is trial 16 with value: 0.34733821447233987.\n",
      "[I 2023-06-16 17:52:42,572] Trial 3 finished with value: -0.5363355045738799 and parameters: {'alpha': 342.19536611094827, 'l1_ratio': 0.004537099270949176}. Best is trial 16 with value: 0.34733821447233987.\n",
      "[I 2023-06-16 17:52:43,203] Trial 1 finished with value: -4.556141085210168 and parameters: {'alpha': 5.432912835709472e-06, 'l1_ratio': 5.015344871105396e-10}. Best is trial 16 with value: 0.34733821447233987.\n",
      "[I 2023-06-16 17:52:44,258] Trial 13 finished with value: -4.943861883637893 and parameters: {'alpha': 2.6720935454207717e-06, 'l1_ratio': 4.0858955810721173e-07}. Best is trial 16 with value: 0.34733821447233987.\n",
      "[I 2023-06-16 17:52:44,784] Trial 17 finished with value: 0.29833901251330636 and parameters: {'alpha': 107.60782698596766, 'l1_ratio': 0.0019064437346418758}. Best is trial 16 with value: 0.34733821447233987.\n",
      "[I 2023-06-16 17:52:45,734] Trial 19 finished with value: -0.1672768597513836 and parameters: {'alpha': 5083.737763233948, 'l1_ratio': 0.0002505508893410208}. Best is trial 16 with value: 0.34733821447233987.\n",
      "[I 2023-06-16 17:52:46,304] Trial 20 finished with value: -0.1531371814969191 and parameters: {'alpha': 6272.95543103128, 'l1_ratio': 0.00013471165194825206}. Best is trial 16 with value: 0.34733821447233987.\n",
      "[I 2023-06-16 17:52:47,719] Trial 18 finished with value: -0.3869641883759509 and parameters: {'alpha': 774.4274291191766, 'l1_ratio': 0.0007581911878468654}. Best is trial 16 with value: 0.34733821447233987.\n",
      "[I 2023-06-16 17:52:48,539] Trial 21 finished with value: 0.3680755838201387 and parameters: {'alpha': 88.85878429508344, 'l1_ratio': 0.000640817253158596}. Best is trial 21 with value: 0.3680755838201387.\n",
      "[I 2023-06-16 17:52:50,973] Trial 23 finished with value: -0.28003087700164947 and parameters: {'alpha': 8.728608740997382, 'l1_ratio': 0.005003902599928242}. Best is trial 21 with value: 0.3680755838201387.\n",
      "[I 2023-06-16 17:52:58,007] Trial 12 finished with value: -7.05237384750848 and parameters: {'alpha': 3.2203710872955835e-06, 'l1_ratio': 0.7280398786115732}. Best is trial 21 with value: 0.3680755838201387.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.338e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.270e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.759e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.478e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.753e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:25,438] Trial 14 finished with value: -28.867062176205362 and parameters: {'alpha': 0.00020740916573971783, 'l1_ratio': 2.323015260030801e-05}. Best is trial 21 with value: 0.3680755838201387.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.214e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.145e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.031e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.020e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:27,822] Trial 25 finished with value: -2.2941343178001117 and parameters: {'alpha': 0.7463157468574784, 'l1_ratio': 0.01781926752521281}. Best is trial 21 with value: 0.3680755838201387.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+00, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.780e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:36,782] Trial 22 finished with value: -3.6359617206807724 and parameters: {'alpha': 0.8525489853414565, 'l1_ratio': 0.00319614952951355}. Best is trial 21 with value: 0.3680755838201387.\n",
      "[I 2023-06-16 17:53:36,913] Trial 30 finished with value: -0.0010605577384500038 and parameters: {'alpha': 284697.10167625843, 'l1_ratio': 0.04887197372542054}. Best is trial 21 with value: 0.3680755838201387.\n",
      "[I 2023-06-16 17:53:37,127] Trial 31 finished with value: 0.3908832395967129 and parameters: {'alpha': 84120.40223220184, 'l1_ratio': 0.0007296078173795299}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:37,244] Trial 32 finished with value: 0.3658143794300082 and parameters: {'alpha': 120449.4803231262, 'l1_ratio': 0.00031454234288492896}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:37,468] Trial 33 finished with value: 0.3467178921411273 and parameters: {'alpha': 272711.0808511501, 'l1_ratio': 0.00021533166696750496}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:37,612] Trial 34 finished with value: 0.288763879989727 and parameters: {'alpha': 725942.6791941335, 'l1_ratio': 5.634772443955599e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:37,766] Trial 35 finished with value: 0.3670076115350656 and parameters: {'alpha': 69994.59621270723, 'l1_ratio': 0.0004946174913213638}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:37,952] Trial 36 finished with value: 0.23199617155396005 and parameters: {'alpha': 1495973.716570805, 'l1_ratio': 8.57207599106448e-06}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:38,245] Trial 37 finished with value: -0.0010605577384500038 and parameters: {'alpha': 9024652.966403836, 'l1_ratio': 0.0008085067434971796}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:38,514] Trial 38 finished with value: 0.3577379763114123 and parameters: {'alpha': 57118.08661605683, 'l1_ratio': 0.0004516246158457568}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:39,506] Trial 39 finished with value: 0.09692673582930245 and parameters: {'alpha': 16790.64052501094, 'l1_ratio': 7.926338317338915e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:39,627] Trial 40 finished with value: -0.0010605577384500038 and parameters: {'alpha': 3092004.871095934, 'l1_ratio': 0.0007056649303995909}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:39,768] Trial 41 finished with value: -0.038389114641729706 and parameters: {'alpha': 53792.449316294056, 'l1_ratio': 0.006209220266488123}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:40,362] Trial 26 finished with value: -6.388418192872282 and parameters: {'alpha': 0.09078976032581196, 'l1_ratio': 0.02570685928692276}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.652e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:44,926] Trial 24 finished with value: -2.9647179020028624 and parameters: {'alpha': 0.8931945568488115, 'l1_ratio': 0.006903363631241203}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.636e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:45,266] Trial 10 finished with value: -47.7799506531394 and parameters: {'alpha': 0.00202889072632785, 'l1_ratio': 1.7133621393147743e-08}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:45,303] Trial 44 finished with value: -0.0010605577384500038 and parameters: {'alpha': 14385938.83794468, 'l1_ratio': 0.0013712827742717942}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:45,482] Trial 45 finished with value: -0.018974292403799553 and parameters: {'alpha': 25107926.12272051, 'l1_ratio': 6.0121802206186e-06}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:47,246] Trial 2 finished with value: 0.13304626685445076 and parameters: {'alpha': 56.69610257750751, 'l1_ratio': 1.9980572294552968e-07}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:47,450] Trial 48 finished with value: 0.35431601950369895 and parameters: {'alpha': 85207.9635001852, 'l1_ratio': 0.00030853316573589717}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:50,067] Trial 47 finished with value: 0.29523684643277764 and parameters: {'alpha': 75.3264164810384, 'l1_ratio': 0.00025304030203132205}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:50,578] Trial 50 finished with value: 0.2678834315470247 and parameters: {'alpha': 46371.66096827384, 'l1_ratio': 4.368709571373668e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:51,139] Trial 49 finished with value: 0.37776970439194246 and parameters: {'alpha': 131.63088536656701, 'l1_ratio': 0.0003919860014668137}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.871e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:53:51,850] Trial 52 finished with value: -0.05508669816306636 and parameters: {'alpha': 2528.926783392821, 'l1_ratio': 0.001736951215675495}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:51,876] Trial 27 finished with value: -13.313498850449138 and parameters: {'alpha': 0.01282922653135522, 'l1_ratio': 0.020042761664238885}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:53:54,277] Trial 51 finished with value: 0.042471059771781894 and parameters: {'alpha': 393.9931427286672, 'l1_ratio': 0.0006017579087561553}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.587e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:54:00,317] Trial 53 finished with value: 0.36888696671365306 and parameters: {'alpha': 147.23115540565377, 'l1_ratio': 0.00012412797079903407}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:54:03,859] Trial 28 finished with value: -2.230797338756729 and parameters: {'alpha': 0.8673408687057578, 'l1_ratio': 0.014087371885539537}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.602e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:54:04,151] Trial 54 finished with value: 0.2723437589816825 and parameters: {'alpha': 315.9715133877766, 'l1_ratio': 0.00011721593906275549}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.451e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.599e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.064e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.516e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.804e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.650e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.154e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:54:26,309] Trial 29 finished with value: -4.582994963374512 and parameters: {'alpha': 0.6800497733045031, 'l1_ratio': 0.0014128223639361774}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:54:32,484] Trial 42 finished with value: 0.34831932617976885 and parameters: {'alpha': 219.38928803475795, 'l1_ratio': 4.462170843289451e-06}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.899e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.131e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:54:47,686] Trial 46 finished with value: 0.18231821384449187 and parameters: {'alpha': 63.904178551715354, 'l1_ratio': 3.4120308876169145e-06}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:54:48,165] Trial 58 finished with value: -0.7227819766399415 and parameters: {'alpha': 15.362622899883226, 'l1_ratio': 3.21202364448417e-05}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.386e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:54:50,468] Trial 62 finished with value: -0.11518836904202583 and parameters: {'alpha': 7760.772883939106, 'l1_ratio': 9.152806240492854e-05}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.763e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.865e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:54:54,764] Trial 63 finished with value: -0.3010265279789981 and parameters: {'alpha': 2044.6818942787993, 'l1_ratio': 0.0001306316343031399}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:54:56,311] Trial 43 finished with value: 0.3260085302030584 and parameters: {'alpha': 107.4884033031009, 'l1_ratio': 4.7009861688912855e-06}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:54:56,666] Trial 65 finished with value: 0.3535323697115595 and parameters: {'alpha': 12053.610201792248, 'l1_ratio': 0.0026089497761917586}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.333e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.906e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:05,341] Trial 55 finished with value: -0.1950144908199293 and parameters: {'alpha': 30.869391838875142, 'l1_ratio': 5.12157688174787e-06}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:10,459] Trial 57 finished with value: -0.3991678134603547 and parameters: {'alpha': 22.867066892693, 'l1_ratio': 2.5553907521989524e-05}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.587e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.080e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:12,624] Trial 56 finished with value: 0.05740574481616367 and parameters: {'alpha': 47.94394592271137, 'l1_ratio': 5.338172717554284e-06}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.327e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:14,462] Trial 68 finished with value: -0.4183101585050731 and parameters: {'alpha': 1471.1256961402048, 'l1_ratio': 0.00041221651843240033}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:14,617] Trial 70 finished with value: 0.3822407393134572 and parameters: {'alpha': 125934.69733361395, 'l1_ratio': 0.00042931256397771604}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:14,716] Trial 67 finished with value: -0.1045350422466929 and parameters: {'alpha': 1162.2937414451671, 'l1_ratio': 2.2432594284663016e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:14,993] Trial 71 finished with value: -0.0010605577384500038 and parameters: {'alpha': 151235408.4072816, 'l1_ratio': 0.00022884300587310602}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:15,052] Trial 72 finished with value: -0.0010605577384500038 and parameters: {'alpha': 144900432.24564528, 'l1_ratio': 0.00018350872826099817}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:15,246] Trial 73 finished with value: -0.026658589695754742 and parameters: {'alpha': 324004.5673732487, 'l1_ratio': 0.0011395175080760268}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:15,341] Trial 74 finished with value: -0.044208983106783006 and parameters: {'alpha': 429665.6854292807, 'l1_ratio': 0.0007133755774019127}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:15,548] Trial 76 finished with value: -0.029189222159157868 and parameters: {'alpha': 5333942.732808656, 'l1_ratio': 5.858536610262979e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:15,742] Trial 77 finished with value: 0.381572671507201 and parameters: {'alpha': 19489.449028651128, 'l1_ratio': 0.0031221849166760862}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:16,055] Trial 78 finished with value: 0.3477962754609981 and parameters: {'alpha': 9343.004761841372, 'l1_ratio': 0.002826589388881519}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:16,226] Trial 79 finished with value: -0.004969353986447341 and parameters: {'alpha': 1448577.1911153838, 'l1_ratio': 0.0003328859436726092}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:16,477] Trial 80 finished with value: -0.026651632353653382 and parameters: {'alpha': 107579.42112675481, 'l1_ratio': 0.003473970168846252}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:17,309] Trial 69 finished with value: -0.285128456474994 and parameters: {'alpha': 1036.8213276369513, 'l1_ratio': 0.00038231062836168096}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:17,561] Trial 82 finished with value: 0.34080204859169383 and parameters: {'alpha': 14559.662531228474, 'l1_ratio': 0.001269778167582972}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.213e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.960e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:21,911] Trial 59 finished with value: -0.823907685501794 and parameters: {'alpha': 13.782078075278708, 'l1_ratio': 2.3958717060804282e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:22,085] Trial 84 finished with value: 0.02298819950806985 and parameters: {'alpha': 37820.93773675633, 'l1_ratio': 0.006679379988573178}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:26,535] Trial 75 finished with value: -0.8198661235186157 and parameters: {'alpha': 7.223873215059142, 'l1_ratio': 0.002517256348354065}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:27,334] Trial 86 finished with value: -0.14481321917325152 and parameters: {'alpha': 3628.7940509128925, 'l1_ratio': 0.0007413558039923775}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:27,505] Trial 87 finished with value: 0.13068527848200315 and parameters: {'alpha': 1217694.6479429847, 'l1_ratio': 8.071489203700646e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:27,770] Trial 88 finished with value: 0.3512225022663323 and parameters: {'alpha': 198166.1368598812, 'l1_ratio': 0.00015556123733174524}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:27,914] Trial 83 finished with value: -0.7391836454695707 and parameters: {'alpha': 3.55588029742087, 'l1_ratio': 0.008333159572267736}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:28,166] Trial 90 finished with value: 0.3559810191725759 and parameters: {'alpha': 63199.33586332063, 'l1_ratio': 0.00039202416333988696}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:28,216] Trial 89 finished with value: 0.35203064441057375 and parameters: {'alpha': 40854.42122867455, 'l1_ratio': 0.000516907204994078}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:28,450] Trial 91 finished with value: 0.3625855944780787 and parameters: {'alpha': 26286.26862310646, 'l1_ratio': 0.0012022778107536936}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.110e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:31,662] Trial 81 finished with value: -1.2335355099534155 and parameters: {'alpha': 6.102054648356167, 'l1_ratio': 0.001458075056308587}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:32,253] Trial 93 finished with value: -0.44443810725625693 and parameters: {'alpha': 543.3129045604468, 'l1_ratio': 0.0013416473796344158}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:33,445] Trial 92 finished with value: -0.07217422904168869 and parameters: {'alpha': 352.58020512579765, 'l1_ratio': 0.0010889149733139143}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:33,960] Trial 96 finished with value: 0.33947738340922007 and parameters: {'alpha': 5389.990069868625, 'l1_ratio': 0.004254413330193877}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:34,606] Trial 97 finished with value: 0.21260537226309803 and parameters: {'alpha': 22887.41257161362, 'l1_ratio': 0.00018467914924912316}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:34,854] Trial 98 finished with value: 0.3652722220298327 and parameters: {'alpha': 168281.5432907728, 'l1_ratio': 0.00046399426770877476}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:34,985] Trial 99 finished with value: 0.3550035178043038 and parameters: {'alpha': 133277.08790067036, 'l1_ratio': 0.00023589623922849802}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:35,196] Trial 100 finished with value: -0.039517366702175614 and parameters: {'alpha': 633385.3755839925, 'l1_ratio': 0.0005004102832230285}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:35,339] Trial 101 finished with value: -0.0010605577384500038 and parameters: {'alpha': 2433110.491406667, 'l1_ratio': 0.0008124830619059361}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:35,589] Trial 94 finished with value: 0.018694914887517993 and parameters: {'alpha': 339.4533833370637, 'l1_ratio': 0.0008986184297280898}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:35,632] Trial 102 finished with value: 0.37474724379759744 and parameters: {'alpha': 20829.157209543846, 'l1_ratio': 0.002493992961748124}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:35,911] Trial 103 finished with value: 0.3704373992139353 and parameters: {'alpha': 20187.759405845347, 'l1_ratio': 0.0023893851090550783}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:36,190] Trial 104 finished with value: 0.13932838641657563 and parameters: {'alpha': 3439.2324520769935, 'l1_ratio': 0.001916982746530511}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:36,365] Trial 105 finished with value: 0.2511817875374465 and parameters: {'alpha': 4445.001787860959, 'l1_ratio': 0.0022884876228507827}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:36,549] Trial 106 finished with value: 0.3287736007031428 and parameters: {'alpha': 7121.527906810234, 'l1_ratio': 0.0022191767976345476}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:36,650] Trial 107 finished with value: -0.0010605577384500038 and parameters: {'alpha': 542636.0360910111, 'l1_ratio': 0.008901150909336757}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:36,805] Trial 95 finished with value: 0.3221944029746541 and parameters: {'alpha': 241.3869483351922, 'l1_ratio': 0.0001930617426557083}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:37,012] Trial 108 finished with value: 0.3481441077308524 and parameters: {'alpha': 183053.89405146547, 'l1_ratio': 0.00011053513761200432}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:37,085] Trial 109 finished with value: -0.0010605577384500038 and parameters: {'alpha': 178669.7220500353, 'l1_ratio': 0.003984347141843174}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:37,283] Trial 110 finished with value: -0.0010605577384500038 and parameters: {'alpha': 162746.83320063123, 'l1_ratio': 0.0038611939806564685}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:37,492] Trial 111 finished with value: 0.3783518492640771 and parameters: {'alpha': 14784.598592361315, 'l1_ratio': 0.0039950227870534484}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:37,882] Trial 112 finished with value: 0.31374261085568006 and parameters: {'alpha': 20828.577844496693, 'l1_ratio': 0.0005901406905894741}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:38,148] Trial 113 finished with value: 0.21228341014974084 and parameters: {'alpha': 16436.449612989218, 'l1_ratio': 0.00032263551543586054}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:38,428] Trial 115 finished with value: 0.2804745490020909 and parameters: {'alpha': 1283.172156055585, 'l1_ratio': 0.009272841168956394}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.199e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:39,431] Trial 117 finished with value: -0.47163044432495105 and parameters: {'alpha': 157.88328488930287, 'l1_ratio': 0.013857463559234734}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:39,765] Trial 118 finished with value: 0.35839077804444514 and parameters: {'alpha': 51464.92340964207, 'l1_ratio': 0.0005015872151763606}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:40,444] Trial 116 finished with value: -0.5048988154050876 and parameters: {'alpha': 178.16141276351118, 'l1_ratio': 0.0058875090095646095}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:40,514] Trial 119 finished with value: -0.14350445948779378 and parameters: {'alpha': 817.3236940831865, 'l1_ratio': 0.005382455157761067}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.389e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:40,821] Trial 61 finished with value: -0.8090393640596804 and parameters: {'alpha': 13.965140251514697, 'l1_ratio': 2.9939163562168525e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:40,847] Trial 121 finished with value: -0.0010605577384500038 and parameters: {'alpha': 777150.6245415475, 'l1_ratio': 0.0019130390087257795}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:41,158] Trial 122 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1007160.4046837448, 'l1_ratio': 0.0016478310783315713}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:41,466] Trial 124 finished with value: -0.0010605577384500038 and parameters: {'alpha': 4374323.800712827, 'l1_ratio': 0.0008461242892543704}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:41,992] Trial 123 finished with value: -0.30394175946616264 and parameters: {'alpha': 2183.051928516242, 'l1_ratio': 0.0008504858285097522}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:42,107] Trial 126 finished with value: 0.35283101687987733 and parameters: {'alpha': 95571.60710589064, 'l1_ratio': 0.0002756467016184337}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:42,516] Trial 120 finished with value: -0.4378101463755378 and parameters: {'alpha': 716.0422636696703, 'l1_ratio': 0.002108740742454652}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:42,838] Trial 128 finished with value: 0.36794108153143656 and parameters: {'alpha': 32585.028132564166, 'l1_ratio': 0.0012176785625259347}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:43,278] Trial 129 finished with value: 0.08207235493431331 and parameters: {'alpha': 9439.470732689835, 'l1_ratio': 0.00039644771269843994}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:43,509] Trial 60 finished with value: -0.5036072850319684 and parameters: {'alpha': 20.025321206984046, 'l1_ratio': 2.1318782844041353e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:43,632] Trial 130 finished with value: 0.3118903859670107 and parameters: {'alpha': 62927.420233889774, 'l1_ratio': 0.0001156528215075068}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:43,661] Trial 114 finished with value: -0.17519887927090583 and parameters: {'alpha': 871.7498247996947, 'l1_ratio': 0.0003037864487519014}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:43,833] Trial 127 finished with value: -0.05615957710785413 and parameters: {'alpha': 10073.039589446971, 'l1_ratio': 6.569084948272796e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:43,990] Trial 132 finished with value: -0.0010605577384500038 and parameters: {'alpha': 436379.27434717986, 'l1_ratio': 0.00337663226914762}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:44,153] Trial 133 finished with value: 0.33851578256638154 and parameters: {'alpha': 27047.367777627922, 'l1_ratio': 0.0005986696641958942}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:44,258] Trial 131 finished with value: 0.2602572442895932 and parameters: {'alpha': 34061.154965657704, 'l1_ratio': 0.0001381845407170026}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:44,260] Trial 134 finished with value: -0.0010605577384500038 and parameters: {'alpha': 294166.7497682971, 'l1_ratio': 0.003293162515980942}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:44,530] Trial 135 finished with value: 0.3456439384026126 and parameters: {'alpha': 19578.653424246957, 'l1_ratio': 0.0011235948583327108}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:44,622] Trial 125 finished with value: -0.3246354726256288 and parameters: {'alpha': 2427.171540732478, 'l1_ratio': 0.0002740289591275357}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:44,979] Trial 140 finished with value: 0.351995099499227 and parameters: {'alpha': 90877.39256253639, 'l1_ratio': 0.0011814485481096157}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:45,162] Trial 138 finished with value: 0.005556555584037004 and parameters: {'alpha': 3767.712515430187, 'l1_ratio': 0.001212324017647933}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:45,462] Trial 137 finished with value: -0.1522378663928308 and parameters: {'alpha': 3069.0123012212416, 'l1_ratio': 0.0009664613523542656}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:45,567] Trial 139 finished with value: -0.03873383997661065 and parameters: {'alpha': 2885.6681394544576, 'l1_ratio': 0.0015287667703969068}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:45,886] Trial 143 finished with value: -0.0010605577384500038 and parameters: {'alpha': 2651696.1527336817, 'l1_ratio': 0.0005081966116992609}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:47,630] Trial 141 finished with value: 0.36928367884628077 and parameters: {'alpha': 72.84893039928438, 'l1_ratio': 0.0015638655915590333}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:48,365] Trial 145 finished with value: 0.355532710407048 and parameters: {'alpha': 79.73288821089392, 'l1_ratio': 0.0006861446817637038}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:49,234] Trial 147 finished with value: -0.037107573725934984 and parameters: {'alpha': 8836.05729371237, 'l1_ratio': 0.00016488256741878555}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:49,491] Trial 144 finished with value: 0.3667724152208821 and parameters: {'alpha': 91.11926663057848, 'l1_ratio': 0.0005794769763324722}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:49,868] Trial 136 finished with value: 0.2730060598405529 and parameters: {'alpha': 47.03932238984955, 'l1_ratio': 0.001137778487129326}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:50,591] Trial 142 finished with value: 0.33513466861540503 and parameters: {'alpha': 76.86643286992094, 'l1_ratio': 0.000529465014762002}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:50,955] Trial 148 finished with value: 0.3247610205631729 and parameters: {'alpha': 73.38006348368383, 'l1_ratio': 0.0026852302395184205}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:52,527] Trial 149 finished with value: 0.34588065171969645 and parameters: {'alpha': 43.17609424562973, 'l1_ratio': 0.002688046708858047}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:52,703] Trial 153 finished with value: 0.3657321705592671 and parameters: {'alpha': 92587.82035895679, 'l1_ratio': 0.0003892777360774665}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:53,357] Trial 152 finished with value: 0.25913671558486734 and parameters: {'alpha': 269.4279885519534, 'l1_ratio': 0.00035949129285135523}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:53,974] Trial 150 finished with value: 0.04885648884575574 and parameters: {'alpha': 37.38218043449719, 'l1_ratio': 0.00048461955186234634}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:54,212] Trial 66 finished with value: -0.99343224327207 and parameters: {'alpha': 11.588659414735126, 'l1_ratio': 1.3381245941514229e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:54,418] Trial 156 finished with value: -0.030994540740407046 and parameters: {'alpha': 68644.66035493548, 'l1_ratio': 0.0052221447987083084}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:54,816] Trial 158 finished with value: 0.3538209999098738 and parameters: {'alpha': 247721.3389810035, 'l1_ratio': 0.00023480635427212704}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:55,592] Trial 157 finished with value: 0.2598310953290473 and parameters: {'alpha': 38901.25012906366, 'l1_ratio': 8.363147423095932e-05}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.359e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:55:56,932] Trial 151 finished with value: 0.18134677358960452 and parameters: {'alpha': 26.424574592725296, 'l1_ratio': 0.0023626257489739247}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:57,029] Trial 146 finished with value: 0.30362271118233525 and parameters: {'alpha': 81.81324054980003, 'l1_ratio': 0.00018113252277343264}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:57,072] Trial 64 finished with value: -0.5062409973920476 and parameters: {'alpha': 19.998794351556022, 'l1_ratio': 1.73388769391352e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:57,206] Trial 161 finished with value: 0.3501653432404178 and parameters: {'alpha': 130750.28316857529, 'l1_ratio': 0.0007670412962672754}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:55:57,464] Trial 162 finished with value: -0.017202416998919594 and parameters: {'alpha': 400907.8822720092, 'l1_ratio': 0.000657061684829603}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:08,159] Trial 154 finished with value: -0.37534005564278944 and parameters: {'alpha': 21.615847202196928, 'l1_ratio': 0.00022964709731418048}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:08,337] Trial 166 finished with value: 0.3582790556449174 and parameters: {'alpha': 18867.77958941494, 'l1_ratio': 0.0016833907794568202}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.610e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.580e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:56:20,297] Trial 85 finished with value: -2.3058018169045007 and parameters: {'alpha': 3.4790388018054617, 'l1_ratio': 0.00015060288756523415}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:20,835] Trial 168 finished with value: 0.30124982096136704 and parameters: {'alpha': 26513.50287087884, 'l1_ratio': 0.0003709613124179066}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:21,067] Trial 169 finished with value: 0.20301131004074024 and parameters: {'alpha': 101230.11929695241, 'l1_ratio': 0.0016760012316504647}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:56:21,514] Trial 170 finished with value: 0.14065276314498584 and parameters: {'alpha': 7404.199763234204, 'l1_ratio': 0.0007459242649805135}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:21,708] Trial 171 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1272718.5164599326, 'l1_ratio': 0.004155630182664241}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:56:26,725] Trial 172 finished with value: -0.2894078697840549 and parameters: {'alpha': 520.3694127402341, 'l1_ratio': 0.0010065121246286147}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:27,655] Trial 160 finished with value: -1.8252612699741215 and parameters: {'alpha': 4.525659765467288, 'l1_ratio': 0.0007447986714275275}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:56:32,858] Trial 174 finished with value: -0.3492173021531805 and parameters: {'alpha': 1253.086583692121, 'l1_ratio': 0.0003739816732912438}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:33,159] Trial 175 finished with value: 0.3500412591431381 and parameters: {'alpha': 185986.84541146105, 'l1_ratio': 3.6713258483730004e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:33,326] Trial 176 finished with value: 0.3048540745735115 and parameters: {'alpha': 12138.526333328808, 'l1_ratio': 0.011994449888634021}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:33,508] Trial 177 finished with value: 0.3818461932174751 and parameters: {'alpha': 34536.19062545527, 'l1_ratio': 0.0015389045287171278}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:33,726] Trial 178 finished with value: 0.3896284409618738 and parameters: {'alpha': 42040.70266697128, 'l1_ratio': 0.0016486506364826131}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:33,939] Trial 179 finished with value: 0.3710697701596491 and parameters: {'alpha': 56594.807956740086, 'l1_ratio': 0.0017727336728261868}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:34,153] Trial 180 finished with value: -0.017820243431351652 and parameters: {'alpha': 56638.257152669015, 'l1_ratio': 0.007282304999332356}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:34,338] Trial 181 finished with value: 0.37175356318769315 and parameters: {'alpha': 24175.455112602765, 'l1_ratio': 0.0019588241485767686}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:34,601] Trial 182 finished with value: 0.3705285577316572 and parameters: {'alpha': 13702.555988934273, 'l1_ratio': 0.0037673394608115952}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:34,814] Trial 183 finished with value: 0.37682822015114387 and parameters: {'alpha': 12517.626857983607, 'l1_ratio': 0.004671093901508502}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:35,069] Trial 184 finished with value: 0.34532822898144727 and parameters: {'alpha': 5614.196747311555, 'l1_ratio': 0.004944165016845003}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:35,240] Trial 185 finished with value: 0.37480191800126444 and parameters: {'alpha': 18700.63759148169, 'l1_ratio': 0.0028397242174624886}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:35,390] Trial 186 finished with value: 0.3806475105830532 and parameters: {'alpha': 15817.06291067573, 'l1_ratio': 0.0038886963559232623}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:35,553] Trial 187 finished with value: 0.3682978154453476 and parameters: {'alpha': 12098.112177891484, 'l1_ratio': 0.009241684570950133}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:35,854] Trial 188 finished with value: 0.3310346434098887 and parameters: {'alpha': 13212.548876510322, 'l1_ratio': 0.010151327618851383}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:35,988] Trial 189 finished with value: 0.3522416920623915 and parameters: {'alpha': 6420.816848217714, 'l1_ratio': 0.019331830689317653}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:36,293] Trial 190 finished with value: 0.33216505887911424 and parameters: {'alpha': 2736.4113432378504, 'l1_ratio': 0.006853447297811297}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:36,456] Trial 191 finished with value: 0.3873802162918917 and parameters: {'alpha': 18302.55963866359, 'l1_ratio': 0.0042476874956852186}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:36,606] Trial 192 finished with value: 0.36902685081009734 and parameters: {'alpha': 17528.190035776857, 'l1_ratio': 0.006282117949273199}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:36,778] Trial 193 finished with value: 0.3575179303671192 and parameters: {'alpha': 31885.011714754866, 'l1_ratio': 0.0036305093927661877}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:36,998] Trial 194 finished with value: 0.38411576903085326 and parameters: {'alpha': 20658.93619634186, 'l1_ratio': 0.0031215390365422996}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:37,164] Trial 195 finished with value: 0.38649809322316253 and parameters: {'alpha': 18703.306538130964, 'l1_ratio': 0.004592128306303459}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:37,348] Trial 196 finished with value: 0.3426701338285076 and parameters: {'alpha': 41186.45031853129, 'l1_ratio': 0.0029841753343147256}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:56:37,683] Trial 197 finished with value: 0.3364528002325194 and parameters: {'alpha': 4173.807328537525, 'l1_ratio': 0.0053435028152952575}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:37,814] Trial 198 finished with value: 0.384515265816337 and parameters: {'alpha': 16912.417570912592, 'l1_ratio': 0.00399096611418203}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:37,949] Trial 199 finished with value: 0.3701833700500035 and parameters: {'alpha': 18115.48579259787, 'l1_ratio': 0.0027092005296639418}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:38,098] Trial 200 finished with value: 0.36037734448554243 and parameters: {'alpha': 17124.020359971608, 'l1_ratio': 0.0024528798404318533}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:38,226] Trial 201 finished with value: 0.10609570623436833 and parameters: {'alpha': 62782.39423695288, 'l1_ratio': 0.003191133823163129}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:38,344] Trial 202 finished with value: 0.3516965079984788 and parameters: {'alpha': 7657.6540072070775, 'l1_ratio': 0.005292235238856364}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:38,480] Trial 203 finished with value: -0.020503514590604177 and parameters: {'alpha': 26945.013307375066, 'l1_ratio': 0.014869626718664241}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:38,674] Trial 204 finished with value: 0.3634856967175586 and parameters: {'alpha': 1783.315585787383, 'l1_ratio': 0.02917632320828346}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:38,931] Trial 205 finished with value: 0.07243716670703293 and parameters: {'alpha': 59442.38941003473, 'l1_ratio': 0.003531703337881103}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:39,194] Trial 206 finished with value: 0.29821080032460895 and parameters: {'alpha': 5673.757864955455, 'l1_ratio': 0.002199620197934417}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:39,309] Trial 207 finished with value: -0.0010605577384500038 and parameters: {'alpha': 268561.7711368136, 'l1_ratio': 0.004608627868891412}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:39,558] Trial 208 finished with value: 0.3487129579288139 and parameters: {'alpha': 14194.597109607492, 'l1_ratio': 0.001666531167225596}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:39,959] Trial 209 finished with value: 0.3849679867732455 and parameters: {'alpha': 43972.065681069165, 'l1_ratio': 0.00197076874791605}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:40,369] Trial 210 finished with value: -0.04718108966268427 and parameters: {'alpha': 111606.6529766772, 'l1_ratio': 0.0026395749332858965}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:40,593] Trial 211 finished with value: 0.005770129346022945 and parameters: {'alpha': 34782.79994925826, 'l1_ratio': 0.007551379602546931}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:40,814] Trial 212 finished with value: 0.36315281115044307 and parameters: {'alpha': 13115.050938441404, 'l1_ratio': 0.003509497896078455}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:40,952] Trial 213 finished with value: 0.3072308141589738 and parameters: {'alpha': 62968.694435653146, 'l1_ratio': 0.0021624284726264324}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:41,109] Trial 214 finished with value: -0.0010605577384500038 and parameters: {'alpha': 374558.38420594233, 'l1_ratio': 0.010778302923528977}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:41,276] Trial 215 finished with value: 0.3394960987014462 and parameters: {'alpha': 5033.740715378149, 'l1_ratio': 0.0046027805415921365}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:41,495] Trial 216 finished with value: 0.38785195139828804 and parameters: {'alpha': 31575.874447793736, 'l1_ratio': 0.0021346547608987565}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:41,659] Trial 217 finished with value: 0.016420847223247992 and parameters: {'alpha': 134971.44433577626, 'l1_ratio': 0.0018579508200276915}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:41,831] Trial 218 finished with value: 0.38022693881944525 and parameters: {'alpha': 30828.04808342804, 'l1_ratio': 0.003116683538832313}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:42,005] Trial 219 finished with value: 0.14278732456041587 and parameters: {'alpha': 27930.228117868428, 'l1_ratio': 0.006924020177327376}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:42,143] Trial 220 finished with value: 0.3834241019800115 and parameters: {'alpha': 58744.165521601775, 'l1_ratio': 0.001470652597792812}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:42,228] Trial 167 finished with value: -1.7402102500550192 and parameters: {'alpha': 5.294901805578769, 'l1_ratio': 0.0003885143890641827}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:42,317] Trial 221 finished with value: -0.04840609472088445 and parameters: {'alpha': 81673.70326087432, 'l1_ratio': 0.003714467272026672}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:42,558] Trial 222 finished with value: 0.3665814618311129 and parameters: {'alpha': 62064.75666004919, 'l1_ratio': 0.0016585779722649218}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:42,629] Trial 223 finished with value: 0.38291946232542223 and parameters: {'alpha': 36111.5425449915, 'l1_ratio': 0.0014919387407310862}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:42,960] Trial 224 finished with value: -0.04284621608113456 and parameters: {'alpha': 203468.4374332819, 'l1_ratio': 0.0015553096371382733}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:43,040] Trial 225 finished with value: -0.0010605577384500038 and parameters: {'alpha': 687965.3115927901, 'l1_ratio': 0.0014340769428045088}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.099e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:56:43,304] Trial 226 finished with value: 0.36742075593809886 and parameters: {'alpha': 33234.484252009424, 'l1_ratio': 0.0011686877598502826}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:43,406] Trial 227 finished with value: 0.384787601956976 and parameters: {'alpha': 46899.62414998394, 'l1_ratio': 0.001086063085614065}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:43,615] Trial 228 finished with value: 0.35427686913525186 and parameters: {'alpha': 9053.618398963503, 'l1_ratio': 0.004641015646329513}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:43,737] Trial 229 finished with value: -0.025717535838595967 and parameters: {'alpha': 134331.82035686658, 'l1_ratio': 0.0028051898082143566}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:43,911] Trial 230 finished with value: -0.0012824841160302691 and parameters: {'alpha': 121234.07742649732, 'l1_ratio': 0.002169527322888223}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:43,968] Trial 231 finished with value: 0.3889306567982564 and parameters: {'alpha': 38112.58280027267, 'l1_ratio': 0.002006301322225858}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.161e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:56:44,345] Trial 232 finished with value: 0.3770858538601182 and parameters: {'alpha': 41751.76883732615, 'l1_ratio': 0.001062956180628936}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:44,921] Trial 233 finished with value: -0.1661683313187793 and parameters: {'alpha': 2822.3962594659847, 'l1_ratio': 0.001045726953056217}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:45,068] Trial 234 finished with value: -0.06431999676784868 and parameters: {'alpha': 3643.0615672255362, 'l1_ratio': 0.0010251019146101492}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:45,369] Trial 236 finished with value: -0.0010605577384500038 and parameters: {'alpha': 425520.7732307026, 'l1_ratio': 0.006823603749613736}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:45,387] Trial 235 finished with value: 0.20362070917336708 and parameters: {'alpha': 7388.462915980162, 'l1_ratio': 0.0009518902495645967}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:45,625] Trial 237 finished with value: 0.3885228932754115 and parameters: {'alpha': 32261.64736126847, 'l1_ratio': 0.0021816719315590834}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:45,687] Trial 238 finished with value: 0.38873699062097117 and parameters: {'alpha': 32506.528890780537, 'l1_ratio': 0.002318379945066614}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:46,065] Trial 239 finished with value: 0.3660341269275107 and parameters: {'alpha': 34271.19999906601, 'l1_ratio': 0.0031846246643253}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:46,212] Trial 240 finished with value: 0.22574606093041474 and parameters: {'alpha': 46390.10100557462, 'l1_ratio': 0.0036250702397836185}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:46,578] Trial 241 finished with value: 0.3792824836473537 and parameters: {'alpha': 60329.96400402703, 'l1_ratio': 0.0015137831899866361}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:46,700] Trial 242 finished with value: -0.04819942487239789 and parameters: {'alpha': 210762.60784144906, 'l1_ratio': 0.001417747247936427}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:47,029] Trial 243 finished with value: 0.11851686785571802 and parameters: {'alpha': 149793.64286445954, 'l1_ratio': 0.0012780323471570933}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:47,060] Trial 244 finished with value: 0.36596004389596337 and parameters: {'alpha': 73825.03027329688, 'l1_ratio': 0.0013674156694660237}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:47,439] Trial 245 finished with value: 0.38541739975647277 and parameters: {'alpha': 8906.431838290118, 'l1_ratio': 0.010077400857192553}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:47,481] Trial 246 finished with value: 0.16097296016867332 and parameters: {'alpha': 35003.75484477129, 'l1_ratio': 0.0053736891753085846}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:47,946] Trial 247 finished with value: -0.01478066822094252 and parameters: {'alpha': 34917.70877393871, 'l1_ratio': 0.012260445691949388}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:47,997] Trial 248 finished with value: 0.3763257791289647 and parameters: {'alpha': 9141.717405117271, 'l1_ratio': 0.011464995262680279}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:48,432] Trial 249 finished with value: 0.38621504106152355 and parameters: {'alpha': 9692.322040473211, 'l1_ratio': 0.008034571605543708}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:48,562] Trial 250 finished with value: 0.344778684713102 and parameters: {'alpha': 9798.102648987238, 'l1_ratio': 0.002347013979056153}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:49,035] Trial 251 finished with value: -0.0010605577384500038 and parameters: {'alpha': 82324.59012451879, 'l1_ratio': 0.00830371811108887}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:49,111] Trial 252 finished with value: -0.0010605577384500038 and parameters: {'alpha': 65900.13563511492, 'l1_ratio': 0.020073257441488985}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:49,407] Trial 253 finished with value: 0.355861394994174 and parameters: {'alpha': 1952.9017910536545, 'l1_ratio': 0.023942552543845495}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:49,894] Trial 255 finished with value: 0.34197805757274635 and parameters: {'alpha': 19594.352112491102, 'l1_ratio': 0.0008754879362451518}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:51,437] Trial 254 finished with value: -0.34746217922804384 and parameters: {'alpha': 1428.4363331321522, 'l1_ratio': 0.0009010865975193097}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:51,734] Trial 257 finished with value: -0.0010605577384500038 and parameters: {'alpha': 347805.0434227382, 'l1_ratio': 0.04197541026700453}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:52,410] Trial 159 finished with value: -2.286440412715395 and parameters: {'alpha': 3.0965787148501938, 'l1_ratio': 0.0007006995481327665}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.683e-02, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:56:54,460] Trial 164 finished with value: -2.2459959812924986 and parameters: {'alpha': 3.43726272144088, 'l1_ratio': 0.00039617332236674543}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:56:59,550] Trial 258 finished with value: -0.2053453657071758 and parameters: {'alpha': 5105.196403679338, 'l1_ratio': 1.4483488687631854e-06}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.164e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:01,584] Trial 155 finished with value: -2.499097176321239 and parameters: {'alpha': 2.9448004899629514, 'l1_ratio': 0.00020900174490359592}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:04,525] Trial 165 finished with value: -1.9160236423297774 and parameters: {'alpha': 4.945877804756753, 'l1_ratio': 4.576393027879329e-05}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:05,595] Trial 163 finished with value: -2.800691583690175 and parameters: {'alpha': 2.4398843361179368, 'l1_ratio': 5.05685141793119e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:05,931] Trial 264 finished with value: 0.3874614290903196 and parameters: {'alpha': 32473.37806908154, 'l1_ratio': 0.0020118999696044806}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:06,272] Trial 262 finished with value: 0.20409253318511497 and parameters: {'alpha': 34528.19425792258, 'l1_ratio': 6.470579410681337e-09}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:06,415] Trial 265 finished with value: -0.0010605577384500038 and parameters: {'alpha': 19403.651521909964, 'l1_ratio': 0.09621451308613342}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:06,628] Trial 266 finished with value: -0.0326297934295254 and parameters: {'alpha': 137034.56212052764, 'l1_ratio': 0.0020501534279234067}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:06,745] Trial 267 finished with value: -0.04133598910978631 and parameters: {'alpha': 149035.96691639954, 'l1_ratio': 0.002163565673706406}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:07,015] Trial 268 finished with value: 0.35066338031892 and parameters: {'alpha': 5527.586542979896, 'l1_ratio': 0.0064526498334469}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:07,108] Trial 269 finished with value: 0.35214853679869246 and parameters: {'alpha': 6764.909264584282, 'l1_ratio': 0.006165031417554039}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:07,356] Trial 270 finished with value: -0.0010605577384500038 and parameters: {'alpha': 950123.3512651891, 'l1_ratio': 0.004329062256368524}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:07,410] Trial 263 finished with value: 0.2577633567556522 and parameters: {'alpha': 48582.28825462282, 'l1_ratio': 2.44762611630542e-08}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:07,600] Trial 271 finished with value: 0.37448836036322136 and parameters: {'alpha': 15172.320491777467, 'l1_ratio': 0.003599002130512044}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.317e-03, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:08,581] Trial 273 finished with value: -6.3755815493328445 and parameters: {'alpha': 2.6639162167656196e-08, 'l1_ratio': 0.0037170461092662505}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:08,881] Trial 272 finished with value: -6.377400545556277 and parameters: {'alpha': 1.0695055119405738e-10, 'l1_ratio': 0.003217808871859951}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:09,019] Trial 276 finished with value: -0.0010605577384500038 and parameters: {'alpha': 15798942.603003178, 'l1_ratio': 0.0017741456655082596}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:12,716] Trial 275 finished with value: -0.5055205991387095 and parameters: {'alpha': 645.5157374137088, 'l1_ratio': 0.0017764187711340124}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:12,895] Trial 278 finished with value: -0.0010605577384500038 and parameters: {'alpha': 310833.2150143456, 'l1_ratio': 0.01494268316787406}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:13,063] Trial 279 finished with value: -0.0010605577384500038 and parameters: {'alpha': 79239.34675309059, 'l1_ratio': 0.009613246583399094}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:13,264] Trial 280 finished with value: 0.3576034459842808 and parameters: {'alpha': 15214.301416841594, 'l1_ratio': 0.002310487199277375}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:18,708] Trial 259 finished with value: -0.19325270272731943 and parameters: {'alpha': 5545.533086369831, 'l1_ratio': 1.3743139233229968e-09}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:18,876] Trial 282 finished with value: -0.0010605577384500038 and parameters: {'alpha': 7870671794.260424, 'l1_ratio': 0.7451252906950535}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:19,084] Trial 283 finished with value: 0.3627067438529363 and parameters: {'alpha': 24843.66007202584, 'l1_ratio': 0.0013812453722986014}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.891e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.430e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.114e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.101e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.079e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:40,551] Trial 256 finished with value: -4.100987952529528 and parameters: {'alpha': 0.16558192095299074, 'l1_ratio': 0.05306925663351592}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.365e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:40,863] Trial 173 finished with value: -2.8650016245128156 and parameters: {'alpha': 2.1077901158972883, 'l1_ratio': 0.00034132360718826677}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:41,139] Trial 286 finished with value: 0.3904685236846641 and parameters: {'alpha': 83739.32167655876, 'l1_ratio': 0.0006780638525684553}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:41,389] Trial 287 finished with value: -0.0010605577384500038 and parameters: {'alpha': 3620392.997805494, 'l1_ratio': 0.0006941283877493488}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:41,686] Trial 288 finished with value: -0.0010605577384500038 and parameters: {'alpha': 655075.3263958301, 'l1_ratio': 0.004938570787404903}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:41,952] Trial 289 finished with value: -0.0010203810292667519 and parameters: {'alpha': 81382.73772873194, 'l1_ratio': 0.007371139979689451}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:42,223] Trial 290 finished with value: -0.0010605577384500038 and parameters: {'alpha': 245560.55763809392, 'l1_ratio': 0.0026399615516209682}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:42,343] Trial 291 finished with value: 0.3831699078910157 and parameters: {'alpha': 56327.01454124702, 'l1_ratio': 0.0015483326288952897}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:42,477] Trial 285 finished with value: -0.3034378935221617 and parameters: {'alpha': 2242.084123985344, 'l1_ratio': 0.0007039049766994665}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:42,673] Trial 292 finished with value: 0.36889472259404965 and parameters: {'alpha': 72711.91902965796, 'l1_ratio': 0.001358670563110978}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:42,952] Trial 294 finished with value: -0.0010605577384500038 and parameters: {'alpha': 44619526.54650097, 'l1_ratio': 0.0010619738374255314}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:43,210] Trial 295 finished with value: -0.0013626400293860197 and parameters: {'alpha': 243946.5725275968, 'l1_ratio': 0.0022434401388383633}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.081e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:43,520] Trial 277 finished with value: 0.08430028757320522 and parameters: {'alpha': 652.9291346711408, 'l1_ratio': 1.1062331808538606e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:43,679] Trial 297 finished with value: 0.38861872724490293 and parameters: {'alpha': 40132.61777936307, 'l1_ratio': 0.0015975954973834379}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:43,952] Trial 298 finished with value: 0.38561504854450196 and parameters: {'alpha': 31437.21868420113, 'l1_ratio': 0.002776587853818542}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:44,128] Trial 299 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1234961.4790589674, 'l1_ratio': 0.0006894810191337478}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:44,335] Trial 300 finished with value: 0.04034784646931381 and parameters: {'alpha': 125557.00741850866, 'l1_ratio': 0.0018573760646959558}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.699e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.240e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.198e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.759e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:57:54,424] Trial 260 finished with value: -6.01040915188282 and parameters: {'alpha': 0.3873056636183257, 'l1_ratio': 0.0020137210156453713}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:54,842] Trial 302 finished with value: 0.31516146991067073 and parameters: {'alpha': 12847.674384370439, 'l1_ratio': 0.0010371831226719632}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:55,984] Trial 303 finished with value: 0.1904020900530455 and parameters: {'alpha': 31732.142750123254, 'l1_ratio': 2.7138662586077162e-06}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:56,361] Trial 304 finished with value: -0.0007970045579219395 and parameters: {'alpha': 111317.24798091226, 'l1_ratio': 0.005292930400382486}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:56,546] Trial 305 finished with value: -0.0010605577384500038 and parameters: {'alpha': 587583.1730145497, 'l1_ratio': 0.00961253921091326}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:57:56,894] Trial 306 finished with value: 0.37474518591159 and parameters: {'alpha': 30098.38251026849, 'l1_ratio': 0.0034009318273566275}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.165e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.682e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:58:08,812] Trial 261 finished with value: -7.970776558611518 and parameters: {'alpha': 0.06716132809144262, 'l1_ratio': 1.4863762721926872e-09}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:09,373] Trial 308 finished with value: 0.2881379069351448 and parameters: {'alpha': 9654.389179251128, 'l1_ratio': 0.0011793963476966023}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:10,020] Trial 307 finished with value: -0.013030628985144102 and parameters: {'alpha': 13011.75944065323, 'l1_ratio': 1.412500423049582e-10}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:10,081] Trial 309 finished with value: 0.27750521142620105 and parameters: {'alpha': 55387.37203588949, 'l1_ratio': 7.195614988731685e-06}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.227e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:58:10,606] Trial 274 finished with value: -8.043546583415134 and parameters: {'alpha': 0.08208523674647705, 'l1_ratio': 0.0018603473833141285}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:10,753] Trial 312 finished with value: 0.20942435690081504 and parameters: {'alpha': 240605.95988001296, 'l1_ratio': 0.0006306930301458665}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:58:14,093] Trial 281 finished with value: -7.375013253939475 and parameters: {'alpha': 0.19844654695310093, 'l1_ratio': 0.0012963077481271425}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:20,066] Trial 293 finished with value: -22.340092348098327 and parameters: {'alpha': 0.00014318068364668936, 'l1_ratio': 0.0010968257934666865}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:58:27,341] Trial 284 finished with value: -25.303981180367114 and parameters: {'alpha': 0.004724150403089681, 'l1_ratio': 0.0007328611192113297}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:30,990] Trial 313 finished with value: -8.230705894275287 and parameters: {'alpha': 5.096803306431946e-05, 'l1_ratio': 1.4984895075662467e-05}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.636e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:58:31,331] Trial 317 finished with value: -0.0010605577384500038 and parameters: {'alpha': 230935682.3144087, 'l1_ratio': 0.002730895370527371}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.414e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:58:32,732] Trial 316 finished with value: -0.23259689970028272 and parameters: {'alpha': 4188.54964553217, 'l1_ratio': 1.8970873363694227e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:32,886] Trial 319 finished with value: -0.0010605577384500038 and parameters: {'alpha': 7591810.6049971515, 'l1_ratio': 0.005518956719210317}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:33,065] Trial 320 finished with value: -0.0010605577384500038 and parameters: {'alpha': 34965.79573050122, 'l1_ratio': 0.017703592561667963}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:33,393] Trial 314 finished with value: -0.22190995256450408 and parameters: {'alpha': 4375.889968384954, 'l1_ratio': 7.217277068641847e-07}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:33,634] Trial 322 finished with value: -0.011933835866239936 and parameters: {'alpha': 107297.21805607254, 'l1_ratio': 0.004129036750605247}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:33,883] Trial 323 finished with value: 0.2762257304103604 and parameters: {'alpha': 15504.786280387061, 'l1_ratio': 0.010030565754818165}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:34,126] Trial 324 finished with value: -0.0010605577384500038 and parameters: {'alpha': 425954.2671561524, 'l1_ratio': 0.0026890389342580042}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:34,299] Trial 321 finished with value: 0.33759410587523786 and parameters: {'alpha': 113942.22975652767, 'l1_ratio': 1.2807154311477113e-07}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:34,483] Trial 325 finished with value: 0.3761371592255241 and parameters: {'alpha': 55750.02912721145, 'l1_ratio': 0.0017167800197663166}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:34,734] Trial 326 finished with value: 0.38919338945536225 and parameters: {'alpha': 39506.96181213637, 'l1_ratio': 0.0017142040389168324}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:34,947] Trial 327 finished with value: 0.22351219153487567 and parameters: {'alpha': 28977.573626213394, 'l1_ratio': 0.005889227642940979}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:35,183] Trial 328 finished with value: 0.04335384711247777 and parameters: {'alpha': 219489.32488322683, 'l1_ratio': 0.0009753911807948409}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:35,464] Trial 329 finished with value: -0.0010605577384500038 and parameters: {'alpha': 583597384.6545408, 'l1_ratio': 0.0006441274364456393}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:35,618] Trial 330 finished with value: -0.0010605577384500038 and parameters: {'alpha': 2232818.581363501, 'l1_ratio': 0.4206482554368249}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:36,168] Trial 331 finished with value: 0.30524868737990707 and parameters: {'alpha': 8631.172219860302, 'l1_ratio': 0.001477434440066019}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:36,335] Trial 332 finished with value: 0.3103384487633779 and parameters: {'alpha': 8140.701706024596, 'l1_ratio': 0.001621888782861993}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:36,674] Trial 333 finished with value: 0.31212901736861737 and parameters: {'alpha': 55180.34679674387, 'l1_ratio': 0.0024528677141362545}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:36,926] Trial 334 finished with value: 0.21584118296492927 and parameters: {'alpha': 59192.796213745, 'l1_ratio': 0.002871433656345299}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:37,120] Trial 335 finished with value: -0.011358494375293682 and parameters: {'alpha': 158470.3106102399, 'l1_ratio': 0.002813163910578369}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:37,331] Trial 336 finished with value: 0.36513391705557613 and parameters: {'alpha': 159670.52905405915, 'l1_ratio': 0.0005053103767219618}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e-03, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:58:38,773] Trial 337 finished with value: -0.29952632941317253 and parameters: {'alpha': 2191.3860284952757, 'l1_ratio': 0.0009036706501432351}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:38,921] Trial 338 finished with value: 0.15155187650436164 and parameters: {'alpha': 24144.428895108213, 'l1_ratio': 3.0234191563266266e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:38,960] Trial 339 finished with value: 0.2971917355457566 and parameters: {'alpha': 18840.235533042505, 'l1_ratio': 0.00782804665419697}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:39,203] Trial 340 finished with value: -0.0010605577384500038 and parameters: {'alpha': 451554.2913581688, 'l1_ratio': 0.0073800936396603845}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:39,281] Trial 341 finished with value: -0.0010605577384500038 and parameters: {'alpha': 584965.8684171892, 'l1_ratio': 0.001765871559300321}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:39,594] Trial 342 finished with value: -0.0010605577384500038 and parameters: {'alpha': 46800.13498978346, 'l1_ratio': 0.014010706408076718}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:39,668] Trial 343 finished with value: -0.0007508823834184719 and parameters: {'alpha': 39892.21105552246, 'l1_ratio': 0.01466710809428833}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:39,926] Trial 344 finished with value: -0.0010605577384500038 and parameters: {'alpha': 593967002.376147, 'l1_ratio': 0.00414842372987306}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:40,318] Trial 345 finished with value: 0.337672238277489 and parameters: {'alpha': 4587.878081967929, 'l1_ratio': 0.0045541855521809334}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:40,544] Trial 347 finished with value: -0.0010605577384500038 and parameters: {'alpha': 19472724.687002704, 'l1_ratio': 0.0005118346174669832}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:41,152] Trial 346 finished with value: -0.08147871572673264 and parameters: {'alpha': 5156.012747452881, 'l1_ratio': 0.0005282843816209121}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:41,661] Trial 349 finished with value: 0.3734987440536484 and parameters: {'alpha': 89457.78178550172, 'l1_ratio': 0.001018069261578558}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:41,698] Trial 348 finished with value: 0.30057832419013736 and parameters: {'alpha': 12349.364488710708, 'l1_ratio': 0.000967979158373095}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:42,071] Trial 350 finished with value: 0.3597694711620189 and parameters: {'alpha': 21287.863341635722, 'l1_ratio': 0.0017670193508684286}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:42,464] Trial 352 finished with value: -0.013802109427328105 and parameters: {'alpha': 155699.92583738643, 'l1_ratio': 0.002771275218451844}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:42,735] Trial 353 finished with value: 0.3523411149317821 and parameters: {'alpha': 1608.2812397194505, 'l1_ratio': 0.027824050802019558}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:42,885] Trial 354 finished with value: 0.38062831401006564 and parameters: {'alpha': 34938.15020321141, 'l1_ratio': 0.0014681835464717273}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:43,024] Trial 351 finished with value: -0.32850253893878484 and parameters: {'alpha': 1233.465542661059, 'l1_ratio': 0.002018393657090473}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:43,221] Trial 355 finished with value: 0.3473260388747805 and parameters: {'alpha': 10436.399128455869, 'l1_ratio': 0.0023506809544479833}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:43,321] Trial 356 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1123938.9385386833, 'l1_ratio': 0.0958247295533693}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:43,525] Trial 357 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1969437.6323901415, 'l1_ratio': 0.004360812331505145}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:43,652] Trial 358 finished with value: 0.35063995279398313 and parameters: {'alpha': 252872.54567693092, 'l1_ratio': 0.00025481361331549854}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:43,974] Trial 359 finished with value: 0.3499739449016694 and parameters: {'alpha': 318129.8023446485, 'l1_ratio': 5.2494988900942344e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:44,234] Trial 361 finished with value: -0.0010605577384500038 and parameters: {'alpha': 47506688.23064951, 'l1_ratio': 0.0012299323100967497}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:44,418] Trial 360 finished with value: 0.31862633377568855 and parameters: {'alpha': 87211.62724087252, 'l1_ratio': 4.54949516170217e-06}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:44,710] Trial 315 finished with value: -0.23398644327032214 and parameters: {'alpha': 3628.278138560619, 'l1_ratio': 5.949049067710244e-07}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:44,908] Trial 363 finished with value: 0.3337760469627412 and parameters: {'alpha': 21375.193332796232, 'l1_ratio': 0.0007214686243456592}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:45,023] Trial 364 finished with value: 0.019963138290010136 and parameters: {'alpha': 7611502.569055353, 'l1_ratio': 3.0654401898642456e-07}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:45,241] Trial 365 finished with value: -0.003772352940814757 and parameters: {'alpha': 76114.24389154745, 'l1_ratio': 0.006711227561267295}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:45,522] Trial 367 finished with value: 0.3526559177648407 and parameters: {'alpha': 9963.816338712524, 'l1_ratio': 0.0037928577259197897}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:45,524] Trial 366 finished with value: 0.3162221127559418 and parameters: {'alpha': 73139.39923395537, 'l1_ratio': 9.119566137668779e-05}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:45,847] Trial 368 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1197306052.5205612, 'l1_ratio': 0.0013061493376457921}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:45,859] Trial 369 finished with value: -0.0010605577384500038 and parameters: {'alpha': 31272.964343410767, 'l1_ratio': 0.9505899575835521}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:46,323] Trial 371 finished with value: 0.34008497254332565 and parameters: {'alpha': 7678.753260285553, 'l1_ratio': 0.00279027233633227}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:47,310] Trial 372 finished with value: -0.5535640781238206 and parameters: {'alpha': 199.6014038734649, 'l1_ratio': 0.008368228409394224}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:49,765] Trial 373 finished with value: -5.585929815255792 and parameters: {'alpha': 5.944774993687069e-07, 'l1_ratio': 0.0007414702411105751}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:49,884] Trial 374 finished with value: 0.37900367111439565 and parameters: {'alpha': 25422.54682818793, 'l1_ratio': 0.0021348209798288495}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:50,028] Trial 375 finished with value: 0.37706200795612455 and parameters: {'alpha': 153530.35776581115, 'l1_ratio': 0.0003583853362033274}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:50,140] Trial 376 finished with value: -0.0010605577384500038 and parameters: {'alpha': 685639.6704479076, 'l1_ratio': 0.004117404475329098}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:53,281] Trial 318 finished with value: -0.23448612613681627 and parameters: {'alpha': 3585.5301672671967, 'l1_ratio': 7.30693606126081e-07}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:53,604] Trial 378 finished with value: 0.38876309436368667 and parameters: {'alpha': 45301.719113674895, 'l1_ratio': 0.0013448372178737251}. Best is trial 31 with value: 0.3908832395967129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.768e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:58:57,738] Trial 296 finished with value: -48.77249753961546 and parameters: {'alpha': 0.0018333999227193962, 'l1_ratio': 0.001621909294433387}. Best is trial 31 with value: 0.3908832395967129.\n",
      "[I 2023-06-16 17:58:57,880] Trial 380 finished with value: 0.3912637017739599 and parameters: {'alpha': 69592.80870099114, 'l1_ratio': 0.000972891439395148}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:58:58,059] Trial 381 finished with value: 0.3629957078185064 and parameters: {'alpha': 299464.79116767016, 'l1_ratio': 9.863182238666693e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:58:58,206] Trial 382 finished with value: 0.3749351792094292 and parameters: {'alpha': 89232.4429479708, 'l1_ratio': 0.0004602338403963291}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:58:58,346] Trial 383 finished with value: -0.0010605577384500038 and parameters: {'alpha': 121813873.9876249, 'l1_ratio': 0.0009457046867540391}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:58:58,500] Trial 384 finished with value: 0.38029378704944455 and parameters: {'alpha': 64839.0186263174, 'l1_ratio': 0.0006705826172194084}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:58:58,648] Trial 385 finished with value: 0.11325039881654216 and parameters: {'alpha': 170407.29216148745, 'l1_ratio': 0.0011246148399309736}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:58:58,940] Trial 386 finished with value: 0.3086345813903631 and parameters: {'alpha': 22804.307960291542, 'l1_ratio': 0.0005005820922229113}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:00,151] Trial 387 finished with value: 0.25286962286660136 and parameters: {'alpha': 46888.53884457309, 'l1_ratio': 9.281860502338834e-08}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.538e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:02,242] Trial 301 finished with value: -50.26206606618207 and parameters: {'alpha': 0.001428564084978286, 'l1_ratio': 0.001013780662215337}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.725e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:03,191] Trial 389 finished with value: 0.07327538901918906 and parameters: {'alpha': 11485.799338274015, 'l1_ratio': 0.00025675645315589564}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:05,497] Trial 390 finished with value: -0.4934313864490952 and parameters: {'alpha': 605.1784117971146, 'l1_ratio': 0.0022396508764171794}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:05,742] Trial 391 finished with value: 0.1258617093818644 and parameters: {'alpha': 955315.4932277882, 'l1_ratio': 0.00012930267841376676}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:08,412] Trial 310 finished with value: -34.55337075395565 and parameters: {'alpha': 0.00027458251612305943, 'l1_ratio': 6.95701970145893e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.287e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.675e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:27,028] Trial 311 finished with value: -15.890115061993466 and parameters: {'alpha': 0.008031475730350407, 'l1_ratio': 0.0006590895382280301}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:27,347] Trial 394 finished with value: -0.0010605577384500038 and parameters: {'alpha': 3574860.604202507, 'l1_ratio': 0.012081984519902146}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:27,613] Trial 395 finished with value: -0.026071758595019905 and parameters: {'alpha': 265464.08270007925, 'l1_ratio': 0.001404094952033285}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:27,916] Trial 396 finished with value: -0.04669117601043423 and parameters: {'alpha': 59287.89788643982, 'l1_ratio': 0.005209301063029002}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.720e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.532e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.944e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.291e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:46,752] Trial 388 finished with value: 0.17194834394573122 and parameters: {'alpha': 500.76363488333556, 'l1_ratio': 3.034712592307513e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:49,771] Trial 379 finished with value: -3.8212757979665497 and parameters: {'alpha': 1.0489179563672875, 'l1_ratio': 0.0009956651993582627}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:50,206] Trial 399 finished with value: 0.35802109019840916 and parameters: {'alpha': 14210.48060045207, 'l1_ratio': 0.0029474738731522987}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:51,005] Trial 400 finished with value: 0.04021080687445455 and parameters: {'alpha': 2905.2514334188104, 'l1_ratio': 0.0018392837303818413}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:51,183] Trial 401 finished with value: -0.0010605577384500038 and parameters: {'alpha': 130454.4929535517, 'l1_ratio': 0.026023410190789603}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:51,460] Trial 402 finished with value: 0.2009788402383115 and parameters: {'alpha': 28527.351100019638, 'l1_ratio': 0.006222711932371775}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:51,639] Trial 403 finished with value: 0.006608051677226556 and parameters: {'alpha': 110054988.8124528, 'l1_ratio': 2.493283861360941e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:51,827] Trial 404 finished with value: -0.0010605577384500038 and parameters: {'alpha': 485660.66016812244, 'l1_ratio': 0.0035248087199177924}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:52,103] Trial 405 finished with value: -0.0010605577384500038 and parameters: {'alpha': 5000585789.714481, 'l1_ratio': 0.0015084516627018462}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:52,386] Trial 406 finished with value: 0.3102952565082843 and parameters: {'alpha': 5693.059646846673, 'l1_ratio': 0.002345630112991148}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:52,519] Trial 370 finished with value: -5.056631316623989 and parameters: {'alpha': 0.6267409465173831, 'l1_ratio': 1.0293746517792645e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:52,656] Trial 407 finished with value: 0.34038587288973415 and parameters: {'alpha': 51214.335159344606, 'l1_ratio': 0.00033381864370571725}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:52,819] Trial 408 finished with value: 0.3424386402093959 and parameters: {'alpha': 52868.71746111032, 'l1_ratio': 0.00034329688951719096}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:53,772] Trial 409 finished with value: 0.10617088853352707 and parameters: {'alpha': 14961.126408343976, 'l1_ratio': 0.0001622654854830951}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:54,422] Trial 411 finished with value: 0.2944674000976273 and parameters: {'alpha': 1340.1908292162277, 'l1_ratio': 0.00940726222929999}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:54,548] Trial 410 finished with value: 0.02188223875367849 and parameters: {'alpha': 13634.241358750127, 'l1_ratio': 5.2518317417486156e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:54,846] Trial 412 finished with value: 0.3706414532158156 and parameters: {'alpha': 113350.21666579947, 'l1_ratio': 0.0007802797329746706}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:54,963] Trial 413 finished with value: 0.3568229346994201 and parameters: {'alpha': 115210.23065992628, 'l1_ratio': 0.0008590254880135484}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:55,323] Trial 414 finished with value: 0.3429416635322493 and parameters: {'alpha': 7453.3415030085625, 'l1_ratio': 0.003155576926238266}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:55,691] Trial 416 finished with value: -0.0010605577384500038 and parameters: {'alpha': 9767944373.455719, 'l1_ratio': 0.15634560070485398}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:55,945] Trial 417 finished with value: -0.0010605577384500038 and parameters: {'alpha': 327464.5305125575, 'l1_ratio': 0.005261945758718794}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:56,195] Trial 418 finished with value: -0.0010605577384500038 and parameters: {'alpha': 30631.99846020285, 'l1_ratio': 0.33305208959112564}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 17:59:56,393] Trial 419 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1235939.995751995, 'l1_ratio': 0.015577940461226708}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 17:59:56,962] Trial 393 finished with value: -3.948189418635607 and parameters: {'alpha': 0.43286225180091886, 'l1_ratio': 0.012261751481522998}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.696e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:00:00,163] Trial 362 finished with value: -10.784017941215117 and parameters: {'alpha': 0.025989733149287868, 'l1_ratio': 9.8557615198564e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:01,540] Trial 415 finished with value: -0.24931180784395243 and parameters: {'alpha': 11.629215114313263, 'l1_ratio': 0.003455837554328901}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:01,850] Trial 423 finished with value: 0.3620594480726215 and parameters: {'alpha': 24395.16861205102, 'l1_ratio': 0.001342222727368619}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:02,341] Trial 424 finished with value: 0.24123463601495176 and parameters: {'alpha': 4075.55878447345, 'l1_ratio': 0.002406068207868146}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:02,572] Trial 425 finished with value: -0.031254654193242616 and parameters: {'alpha': 184320.45954203795, 'l1_ratio': 0.0015171350693883583}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:02,770] Trial 426 finished with value: 0.3671577492503924 and parameters: {'alpha': 50219.5668469596, 'l1_ratio': 0.0006698069991890815}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:02,869] Trial 420 finished with value: -0.25046499032896524 and parameters: {'alpha': 2900.496208879016, 'l1_ratio': 1.7663422344262468e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:03,052] Trial 428 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1577688328.1980617, 'l1_ratio': 0.006285984527663537}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e-02, tolerance: 1.895e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.246e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:00:03,153] Trial 377 finished with value: -13.81655913333449 and parameters: {'alpha': 0.011719122535705105, 'l1_ratio': 0.0013021282626597326}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:03,260] Trial 427 finished with value: 0.3393868406610609 and parameters: {'alpha': 10220.746993543911, 'l1_ratio': 0.001906900539221116}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:03,487] Trial 430 finished with value: -0.0010605577384500038 and parameters: {'alpha': 15818318.519425742, 'l1_ratio': 0.03264349103813628}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:03,627] Trial 431 finished with value: 0.3816626884890576 and parameters: {'alpha': 91555.21381804107, 'l1_ratio': 0.0005069909639703674}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:03,793] Trial 421 finished with value: -0.1618109015629847 and parameters: {'alpha': 19.505247328829014, 'l1_ratio': 0.0014580016675043836}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:03,976] Trial 433 finished with value: -0.0010605577384500038 and parameters: {'alpha': 459411.97466337495, 'l1_ratio': 0.021335111802476377}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:06,537] Trial 432 finished with value: 0.3263331143951294 and parameters: {'alpha': 97854.69393099683, 'l1_ratio': 2.216612585588463e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:06,688] Trial 434 finished with value: -0.0010605577384500038 and parameters: {'alpha': 492727.86383346835, 'l1_ratio': 0.004214904444839126}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:06,817] Trial 435 finished with value: 0.3869463842101577 and parameters: {'alpha': 19881.23344273389, 'l1_ratio': 0.0042298875763800625}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:07,008] Trial 436 finished with value: 0.3827908271654027 and parameters: {'alpha': 22637.02755596898, 'l1_ratio': 0.004147031540884328}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:07,072] Trial 437 finished with value: -0.0010605577384500038 and parameters: {'alpha': 22612.26969397724, 'l1_ratio': 0.5478360004461741}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:07,277] Trial 438 finished with value: 0.3094155052224754 and parameters: {'alpha': 16420.586006665257, 'l1_ratio': 0.008712605089169151}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:07,531] Trial 440 finished with value: -0.041631419940999836 and parameters: {'alpha': 7153.1095798193555, 'l1_ratio': 0.04544942197495472}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:07,582] Trial 439 finished with value: 0.37767302485021553 and parameters: {'alpha': 7177.686310962383, 'l1_ratio': 0.0086700351520167}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:07,863] Trial 442 finished with value: -0.0010605577384500038 and parameters: {'alpha': 286104810.71515685, 'l1_ratio': 0.0026524896086100413}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:08,329] Trial 444 finished with value: 0.12125757216777296 and parameters: {'alpha': 1314.280552158169, 'l1_ratio': 0.00527333257831905}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:08,365] Trial 443 finished with value: -0.033476492330456055 and parameters: {'alpha': 1878.8429598710961, 'l1_ratio': 0.0026142055161983866}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:08,588] Trial 445 finished with value: -0.0010605577384500038 and parameters: {'alpha': 41288727.347742684, 'l1_ratio': 0.0022147460319294683}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:08,650] Trial 446 finished with value: 0.380601982726808 and parameters: {'alpha': 45174.61740581951, 'l1_ratio': 0.0020542135354901328}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:10,833] Trial 429 finished with value: -0.034568609883756686 and parameters: {'alpha': 11917.193610691013, 'l1_ratio': 3.558058775058849e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:11,166] Trial 448 finished with value: -6.1781323515107225 and parameters: {'alpha': 2.808551015229261e-07, 'l1_ratio': 0.01860335382024059}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:11,972] Trial 422 finished with value: -0.7763383883520867 and parameters: {'alpha': 9.066717765792095, 'l1_ratio': 0.0016789328438532832}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:12,153] Trial 398 finished with value: -0.2022361340533627 and parameters: {'alpha': 1971.596401230084, 'l1_ratio': 1.490330286721173e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:13,270] Trial 451 finished with value: 0.23526128581525538 and parameters: {'alpha': 41409.949038063525, 'l1_ratio': 1.4310836469944784e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:13,513] Trial 449 finished with value: 0.24463644127461406 and parameters: {'alpha': 44302.80483668, 'l1_ratio': 1.0809148127761904e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:13,876] Trial 454 finished with value: -0.0010605577384500038 and parameters: {'alpha': 241923.73504928005, 'l1_ratio': 0.00592620368426672}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:14,167] Trial 455 finished with value: -0.0010605577384500038 and parameters: {'alpha': 3152449.8742977018, 'l1_ratio': 0.003426574236906875}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:14,380] Trial 453 finished with value: 0.35801638734189495 and parameters: {'alpha': 178493.88973962102, 'l1_ratio': 5.7953992181605745e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:15,377] Trial 452 finished with value: 0.23378077767106234 and parameters: {'alpha': 41249.48916056543, 'l1_ratio': 6.6417972681019104e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:16,143] Trial 458 finished with value: -0.03706486435467141 and parameters: {'alpha': 4037.474847204515, 'l1_ratio': 0.000963455100165846}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:00:18,635] Trial 392 finished with value: -10.735384366667894 and parameters: {'alpha': 0.026281318795746487, 'l1_ratio': 5.546052259694741e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:19,198] Trial 460 finished with value: 0.3484974440278738 and parameters: {'alpha': 16844.45089348207, 'l1_ratio': 0.007380130576432781}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:19,534] Trial 461 finished with value: 0.3802094593032089 and parameters: {'alpha': 8156.730036649916, 'l1_ratio': 0.0122813436360112}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.120e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:00:21,751] Trial 397 finished with value: -9.575811988920657 and parameters: {'alpha': 0.03668349434079864, 'l1_ratio': 0.003201513858064263}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:21,888] Trial 463 finished with value: 0.3670601186655892 and parameters: {'alpha': 95065.78257863743, 'l1_ratio': 0.0010045283376459387}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:23,886] Trial 464 finished with value: -4.806806845993062 and parameters: {'alpha': 3.6893778645258e-06, 'l1_ratio': 0.004434211688582417}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:24,021] Trial 465 finished with value: -0.0010605577384500038 and parameters: {'alpha': 23150.554486811547, 'l1_ratio': 0.16277372717584015}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:28,315] Trial 466 finished with value: -5.005889842187646 and parameters: {'alpha': 1.635229483905024e-05, 'l1_ratio': 0.0019438144688543777}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:28,481] Trial 467 finished with value: 0.3741492877538322 and parameters: {'alpha': 76131.5103166109, 'l1_ratio': 0.0012259611208110604}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:28,983] Trial 468 finished with value: -6.377442060754623 and parameters: {'alpha': 1.980840764015166e-09, 'l1_ratio': 1.534355946878369e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:31,444] Trial 459 finished with value: -6.464215996515261 and parameters: {'alpha': 3.486283907286729e-05, 'l1_ratio': 7.0751096600751235e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:32,092] Trial 470 finished with value: -0.03761853802858883 and parameters: {'alpha': 5490.388321854512, 'l1_ratio': 0.0005876760950139086}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:32,581] Trial 469 finished with value: 0.2881144207105898 and parameters: {'alpha': 214.62419094704512, 'l1_ratio': 0.0005390793631801368}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:32,748] Trial 471 finished with value: -6.376867149270265 and parameters: {'alpha': 7.971653615383125e-09, 'l1_ratio': 4.0613964640539565e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:34,030] Trial 473 finished with value: -0.4394415774788152 and parameters: {'alpha': 619.8363729856184, 'l1_ratio': 0.003079942805735053}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:34,211] Trial 474 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1249700.3963830618, 'l1_ratio': 0.005561946638447553}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+00, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.860e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+00, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.775e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:00:38,447] Trial 475 finished with value: 0.23144377541751662 and parameters: {'alpha': 2.356349780543624, 'l1_ratio': 0.05593974760514007}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:38,604] Trial 476 finished with value: -0.0010605577384500038 and parameters: {'alpha': 176483.48385145242, 'l1_ratio': 0.00990683780940866}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:39,445] Trial 477 finished with value: 0.14510767743716968 and parameters: {'alpha': 22290.382702656807, 'l1_ratio': 4.720293985970275e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:39,945] Trial 478 finished with value: 0.029426769902694622 and parameters: {'alpha': 7083610.963085889, 'l1_ratio': 2.1211158322757405e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:40,085] Trial 479 finished with value: 0.3899241731258676 and parameters: {'alpha': 59094.7711212346, 'l1_ratio': 0.0009535863079453738}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:00:40,586] Trial 480 finished with value: 0.3375102927705711 and parameters: {'alpha': 73018.54706894945, 'l1_ratio': 0.00021270743673350068}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e+00, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.428e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.469e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e+00, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:05,305] Trial 441 finished with value: -0.1759259953025021 and parameters: {'alpha': 1697.6411564172947, 'l1_ratio': 1.1707923681172426e-08}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:06,289] Trial 482 finished with value: 0.27852817185699186 and parameters: {'alpha': 10837.01264943894, 'l1_ratio': 0.0009760908000217128}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:06,464] Trial 457 finished with value: 0.3065938999539102 and parameters: {'alpha': 291.97871189804846, 'l1_ratio': 6.733769082756547e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:06,995] Trial 484 finished with value: -0.0010605577384500038 and parameters: {'alpha': 286980.73187088035, 'l1_ratio': 0.0022676524409153197}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:07,224] Trial 485 finished with value: -0.0010605577384500038 and parameters: {'alpha': 101285.04401591168, 'l1_ratio': 0.018496696497656784}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:08,681] Trial 483 finished with value: 0.28747224812876854 and parameters: {'alpha': 102.90058171219395, 'l1_ratio': 0.002225150562069094}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:09,472] Trial 487 finished with value: 0.18412870663140388 and parameters: {'alpha': 23906.21455863164, 'l1_ratio': 9.496287707446369e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:09,822] Trial 488 finished with value: 0.37745901682276645 and parameters: {'alpha': 48118.22104811968, 'l1_ratio': 0.0008934717661168458}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:10,140] Trial 489 finished with value: -0.0010605577384500038 and parameters: {'alpha': 597892.6572765209, 'l1_ratio': 0.0040983759635257345}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:10,454] Trial 490 finished with value: -0.0010605577384500038 and parameters: {'alpha': 100113120.65914027, 'l1_ratio': 0.00037657949512054833}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:11,100] Trial 491 finished with value: 0.11387729787649133 and parameters: {'alpha': 4172.610685678535, 'l1_ratio': 0.001430144075339233}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.946e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:11,580] Trial 492 finished with value: 0.34703785362389455 and parameters: {'alpha': 163153.89768735084, 'l1_ratio': 3.528341829818422e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:11,826] Trial 493 finished with value: 0.3866879050474894 and parameters: {'alpha': 12630.31391592796, 'l1_ratio': 0.0066438093404874434}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e-01, tolerance: 1.895e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.406e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:17,592] Trial 456 finished with value: -3.093794304905655 and parameters: {'alpha': 1.5548391265246975, 'l1_ratio': 0.000981066592672395}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:17,721] Trial 450 finished with value: -8.691617418363492 and parameters: {'alpha': 0.05601926439586636, 'l1_ratio': 0.0067491084658620965}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:17,964] Trial 495 finished with value: 0.3818529336269009 and parameters: {'alpha': 8990.017879593293, 'l1_ratio': 0.0074583610133594725}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:18,035] Trial 496 finished with value: 0.38156380977596144 and parameters: {'alpha': 7994.924967496701, 'l1_ratio': 0.008396803023265537}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:18,283] Trial 497 finished with value: 0.12720144428797733 and parameters: {'alpha': 14278.357284122721, 'l1_ratio': 0.013890105430160105}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:18,417] Trial 498 finished with value: 0.3856731088534315 and parameters: {'alpha': 2862.56818206108, 'l1_ratio': 0.028459528329653715}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:18,650] Trial 500 finished with value: 0.347588128447053 and parameters: {'alpha': 2542.552600840263, 'l1_ratio': 0.012731475194784977}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:18,843] Trial 501 finished with value: 0.3134113731827913 and parameters: {'alpha': 3907.0256921704095, 'l1_ratio': 0.03673382018330556}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+00, tolerance: 1.895e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:26,829] Trial 462 finished with value: 0.23948688919499994 and parameters: {'alpha': 395.2057768681413, 'l1_ratio': 1.4413433380617565e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:26,845] Trial 447 finished with value: 0.2907164079740137 and parameters: {'alpha': 318.04647201072885, 'l1_ratio': 7.238997626504893e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:27,081] Trial 503 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1397932395.5850751, 'l1_ratio': 0.015213154106754546}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:27,301] Trial 505 finished with value: 0.3434546114611044 and parameters: {'alpha': 1279.576076041926, 'l1_ratio': 0.023760457344598827}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:27,644] Trial 506 finished with value: -0.013375232862853767 and parameters: {'alpha': 17168.250455631, 'l1_ratio': 0.025398047900032986}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:31,140] Trial 507 finished with value: -5.0271162747482725 and parameters: {'alpha': 1.6962529148088807e-06, 'l1_ratio': 0.004944645938564963}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:31,304] Trial 508 finished with value: -0.04409245140630225 and parameters: {'alpha': 6525.241621786347, 'l1_ratio': 0.04430506457258119}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:31,782] Trial 509 finished with value: -6.377389040383408 and parameters: {'alpha': 2.1533926885821311e-10, 'l1_ratio': 7.463156474374009e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:31,978] Trial 510 finished with value: -0.0010605577384500038 and parameters: {'alpha': 27833.79357046513, 'l1_ratio': 0.08401825927719231}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.668e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.886e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:33,433] Trial 472 finished with value: -39.4243500757115 and parameters: {'alpha': 0.00035920115101896965, 'l1_ratio': 0.003420870315880045}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:33,665] Trial 511 finished with value: -6.4575275466560935 and parameters: {'alpha': 1.628667603131976e-07, 'l1_ratio': 0.0037680940257040652}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:33,857] Trial 513 finished with value: -0.0009097060362016999 and parameters: {'alpha': 17918.070929043417, 'l1_ratio': 0.033235388602483686}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:33,995] Trial 512 finished with value: 0.32767087481070767 and parameters: {'alpha': 3274.905214231743, 'l1_ratio': 0.005164501049503112}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:34,172] Trial 514 finished with value: 0.3476898041112938 and parameters: {'alpha': 3668.88924161139, 'l1_ratio': 0.010514079553874693}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:34,322] Trial 515 finished with value: 0.3726586845181222 and parameters: {'alpha': 847.2694702583095, 'l1_ratio': 0.07100613935550545}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:34,506] Trial 517 finished with value: -0.0010605577384500038 and parameters: {'alpha': 34969.27188638751, 'l1_ratio': 0.02660401896111468}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:34,753] Trial 518 finished with value: -0.0010605577384500038 and parameters: {'alpha': 9668.990755940951, 'l1_ratio': 0.06269821320050101}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:36,232] Trial 499 finished with value: -0.23698177097402987 and parameters: {'alpha': 3162.4478696254, 'l1_ratio': 8.454942977657159e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:37,127] Trial 516 finished with value: -0.11067718853461221 and parameters: {'alpha': 900.2279338578059, 'l1_ratio': 0.00016267789497221492}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:38,466] Trial 521 finished with value: 0.3137294103851825 and parameters: {'alpha': 80996.45874465573, 'l1_ratio': 3.6552892584792057e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:38,848] Trial 522 finished with value: -0.0010605577384500038 and parameters: {'alpha': 32509.648939548028, 'l1_ratio': 0.2857429307092115}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.028e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:40,936] Trial 481 finished with value: -32.370924596677234 and parameters: {'alpha': 0.0002461396881293703, 'l1_ratio': 2.9197789820716684e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:43,808] Trial 523 finished with value: 0.35693391352026727 and parameters: {'alpha': 46.67761029109444, 'l1_ratio': 0.002767209353829653}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:44,141] Trial 525 finished with value: -0.0010605577384500038 and parameters: {'alpha': 187609.0814169465, 'l1_ratio': 0.009296178092495014}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:44,502] Trial 526 finished with value: 0.3836811243672429 and parameters: {'alpha': 11857.90938900717, 'l1_ratio': 0.005795710071534415}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.714e-03, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:01:46,539] Trial 524 finished with value: -4.616581262944586 and parameters: {'alpha': 8.06959290904302e-06, 'l1_ratio': 0.007412681492862724}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:46,956] Trial 528 finished with value: 0.34516101401351784 and parameters: {'alpha': 71419.63883294692, 'l1_ratio': 0.00029429072161355103}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:47,422] Trial 529 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1691803.4408623471, 'l1_ratio': 0.01625543897311185}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:01:47,709] Trial 530 finished with value: 0.3854352921489593 and parameters: {'alpha': 30634.809335791157, 'l1_ratio': 0.0028653640970055317}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.044e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.168e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.899e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.713e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.727e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.774e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.338e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.113e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:14,340] Trial 502 finished with value: -3.9785182940168053 and parameters: {'alpha': 0.25961365038733586, 'l1_ratio': 0.026819209767866142}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:14,551] Trial 532 finished with value: -0.0010605577384500038 and parameters: {'alpha': 329819.5620066166, 'l1_ratio': 0.19350975848761415}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.078e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:20,160] Trial 486 finished with value: -3.468551911441933 and parameters: {'alpha': 1.311990532187099, 'l1_ratio': 0.0007741914522459689}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:20,542] Trial 534 finished with value: 0.3853564725653997 and parameters: {'alpha': 37998.513578599785, 'l1_ratio': 0.0022868413207789203}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.900e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:22,162] Trial 494 finished with value: -51.74835880780047 and parameters: {'alpha': 0.0011132072809827754, 'l1_ratio': 0.007217395977736852}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:22,907] Trial 536 finished with value: 0.344264516661934 and parameters: {'alpha': 129730.67912063657, 'l1_ratio': 4.863815441227793e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:23,272] Trial 537 finished with value: -0.0010605577384500038 and parameters: {'alpha': 17154510.593917236, 'l1_ratio': 0.9550151746833393}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:23,698] Trial 538 finished with value: 0.3764886888433961 and parameters: {'alpha': 45292.529326264455, 'l1_ratio': 0.0021527627560996585}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:28,941] Trial 504 finished with value: -44.72986456713179 and parameters: {'alpha': 0.0010438692326250904, 'l1_ratio': 0.051389789595342614}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:29,271] Trial 540 finished with value: 0.005527790696925883 and parameters: {'alpha': 393365005.95751643, 'l1_ratio': 7.09625820952043e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:29,560] Trial 541 finished with value: -0.0010605577384500038 and parameters: {'alpha': 104397.50728863617, 'l1_ratio': 0.11030053352943246}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:29,805] Trial 542 finished with value: -0.0010605577384500038 and parameters: {'alpha': 528236.2727511175, 'l1_ratio': 0.4561556596213377}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.355e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:32,057] Trial 520 finished with value: -5.3509196550435405 and parameters: {'alpha': 0.019342996034272985, 'l1_ratio': 0.28981342172177266}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:33,419] Trial 544 finished with value: 0.21422125313269413 and parameters: {'alpha': 36418.0223562413, 'l1_ratio': 1.2215144713338883e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:39,029] Trial 519 finished with value: -18.33363347337298 and parameters: {'alpha': 0.005351237645138984, 'l1_ratio': 0.00904286671231259}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:39,629] Trial 546 finished with value: 0.34196549306158536 and parameters: {'alpha': 12943.495804330367, 'l1_ratio': 0.0015751064413431473}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:40,116] Trial 547 finished with value: 0.3122000410434011 and parameters: {'alpha': 200897.74747166553, 'l1_ratio': 0.0005440190775322444}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e-02, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:40,426] Trial 548 finished with value: 0.33279410895938544 and parameters: {'alpha': 49689.5295675833, 'l1_ratio': 0.0025466993909085047}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e-03, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:48,115] Trial 543 finished with value: -1.3830234712819762 and parameters: {'alpha': 5.263533307881505, 'l1_ratio': 0.0015831934204277478}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:48,991] Trial 550 finished with value: 0.022675151575102137 and parameters: {'alpha': 5632.30786166568, 'l1_ratio': 0.0007158238721064007}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:49,206] Trial 551 finished with value: -0.0010605577384500038 and parameters: {'alpha': 56853608.40620427, 'l1_ratio': 0.003202870085493893}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:49,657] Trial 527 finished with value: -14.579824782070293 and parameters: {'alpha': 0.009632317595185541, 'l1_ratio': 0.00030253889400358143}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.588e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:50,184] Trial 552 finished with value: 0.12876131990082917 and parameters: {'alpha': 21982.85886654454, 'l1_ratio': 2.8505241559992348e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:50,511] Trial 554 finished with value: -0.0010605577384500038 and parameters: {'alpha': 837800.8261439215, 'l1_ratio': 0.001137062083773823}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:50,989] Trial 555 finished with value: 0.3130859443848873 and parameters: {'alpha': 80180.26610907173, 'l1_ratio': 2.2515909553636564e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:55,262] Trial 553 finished with value: 0.10611200032559227 and parameters: {'alpha': 21356.909171005613, 'l1_ratio': 1.4554100326977304e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:55,647] Trial 556 finished with value: 0.22550710475227734 and parameters: {'alpha': 139.80624880866077, 'l1_ratio': 0.001958879323107187}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:55,676] Trial 557 finished with value: -6.374356103902174 and parameters: {'alpha': 6.981492127063723e-08, 'l1_ratio': 1.03842122471721e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:02:56,893] Trial 559 finished with value: -6.375660598344574 and parameters: {'alpha': 2.822547321863829e-08, 'l1_ratio': 0.004514651662586002}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.128e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:02:57,824] Trial 531 finished with value: -15.288422570514998 and parameters: {'alpha': 0.008628517243768802, 'l1_ratio': 0.0006397200642841626}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:00,248] Trial 545 finished with value: -17.155055616677274 and parameters: {'alpha': 0.00010247322737712787, 'l1_ratio': 0.001626535814013453}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:00,395] Trial 558 finished with value: -0.1485825145208591 and parameters: {'alpha': 7277.13021037164, 'l1_ratio': 1.2855714473529949e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:00,581] Trial 563 finished with value: -0.002475163612169151 and parameters: {'alpha': 161204.49584668118, 'l1_ratio': 0.0032706442207222036}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:01,470] Trial 561 finished with value: -5.351409477137485 and parameters: {'alpha': 7.348672449791029e-07, 'l1_ratio': 0.003324498931535914}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:01,671] Trial 565 finished with value: 0.3824729610644145 and parameters: {'alpha': 46145.88148494555, 'l1_ratio': 0.0010485637891727087}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:01,908] Trial 566 finished with value: -0.0010605577384500038 and parameters: {'alpha': 317401.04308414966, 'l1_ratio': 0.0022395506510648326}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:02,154] Trial 567 finished with value: -0.0010605577384500038 and parameters: {'alpha': 7539.5731909760725, 'l1_ratio': 0.09655900170708527}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:03,188] Trial 562 finished with value: -0.13463344299045077 and parameters: {'alpha': 7837.562947589997, 'l1_ratio': 1.7967701869156208e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:03,250] Trial 568 finished with value: 0.10648866807588102 and parameters: {'alpha': 21214.39661643369, 'l1_ratio': 3.7488133274127886e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.158e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.281e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:03:06,336] Trial 569 finished with value: 0.15411671639313787 and parameters: {'alpha': 26632.049335006748, 'l1_ratio': 2.234119890623148e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:06,855] Trial 571 finished with value: -6.377752329832946 and parameters: {'alpha': 7.335000725117874e-10, 'l1_ratio': 0.04090855242674657}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:03:08,637] Trial 533 finished with value: -8.639500886123605 and parameters: {'alpha': 0.022389702522038972, 'l1_ratio': 0.0854014769369789}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:09,649] Trial 572 finished with value: 0.35411932008562624 and parameters: {'alpha': 8.974304407017447, 'l1_ratio': 0.01808735929792727}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:09,980] Trial 574 finished with value: 0.37730818045533987 and parameters: {'alpha': 98036.8422100918, 'l1_ratio': 0.0004410328550458888}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:10,231] Trial 573 finished with value: -0.36428299316963997 and parameters: {'alpha': 1462.5459592971342, 'l1_ratio': 0.0011989817660007418}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:10,420] Trial 575 finished with value: -0.0010605577384500038 and parameters: {'alpha': 4477601.239106265, 'l1_ratio': 0.005148683812933069}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:10,724] Trial 576 finished with value: -0.0010605577384500038 and parameters: {'alpha': 4238659.364233687, 'l1_ratio': 0.00020480352943980592}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:10,868] Trial 577 finished with value: 0.369900921223319 and parameters: {'alpha': 44569.974367832, 'l1_ratio': 0.0008244122457423017}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.071e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:03:11,096] Trial 539 finished with value: -17.327707009681696 and parameters: {'alpha': 0.0024066868785249528, 'l1_ratio': 0.09874139979670876}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:11,303] Trial 579 finished with value: -0.0010605577384500038 and parameters: {'alpha': 340002.95661210775, 'l1_ratio': 0.002211308273172459}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:11,964] Trial 581 finished with value: 0.28931297698319597 and parameters: {'alpha': 2365.824939909292, 'l1_ratio': 0.0051712984533784515}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:12,310] Trial 582 finished with value: -0.0010605577384500038 and parameters: {'alpha': 93042.99228620093, 'l1_ratio': 0.013395908634018613}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:12,332] Trial 578 finished with value: 0.2866745026603408 and parameters: {'alpha': 61315.05350369283, 'l1_ratio': 3.7060813575658996e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:13,800] Trial 583 finished with value: 0.06057854915258343 and parameters: {'alpha': 13352.079224238221, 'l1_ratio': 0.0001225335347472436}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:15,370] Trial 584 finished with value: 0.006272838523699901 and parameters: {'alpha': 14024.163878364592, 'l1_ratio': 2.772844091016086e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:15,643] Trial 586 finished with value: -0.0008248833181166981 and parameters: {'alpha': 177885.3164831511, 'l1_ratio': 0.0031841652472797046}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:15,983] Trial 587 finished with value: 0.32813700617669767 and parameters: {'alpha': 831285.8763512599, 'l1_ratio': 1.9702984901158307e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:16,210] Trial 580 finished with value: -4.645541408055542 and parameters: {'alpha': 9.098431122649328e-06, 'l1_ratio': 2.722147481445395e-10}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.746e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.911e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e+00, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.037e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.839e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:03:29,262] Trial 535 finished with value: -49.751203222221655 and parameters: {'alpha': 0.0012736781663304545, 'l1_ratio': 2.3844141198117863e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:29,767] Trial 590 finished with value: 0.38225203839651706 and parameters: {'alpha': 35120.81337507169, 'l1_ratio': 0.0015205901267097586}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.490e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:03:37,733] Trial 591 finished with value: -0.3183042839318394 and parameters: {'alpha': 20.584090592957807, 'l1_ratio': 0.0005509876320806781}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.858e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.247e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:03:47,130] Trial 549 finished with value: -1.3952125650285414 and parameters: {'alpha': 7.897489724572461, 'l1_ratio': 5.011046648605007e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:48,053] Trial 593 finished with value: -0.16240991208550504 and parameters: {'alpha': 2880.107919238979, 'l1_ratio': 0.0010279968202941028}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:03:52,442] Trial 570 finished with value: -0.1784051931355852 and parameters: {'alpha': 1720.4068605257949, 'l1_ratio': 4.099359235261142e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:03:52,842] Trial 595 finished with value: 0.30372791582363984 and parameters: {'alpha': 6004.190248846347, 'l1_ratio': 0.0021388122617286725}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.952e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.871e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.142e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.790e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:03:59,827] Trial 560 finished with value: -0.10972828945053832 and parameters: {'alpha': 35.446166512175694, 'l1_ratio': 2.8608601585160993e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:00,163] Trial 597 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1848182.1915980247, 'l1_ratio': 0.005020938538602156}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:00,544] Trial 598 finished with value: -0.0010605577384500038 and parameters: {'alpha': 170452.50924550163, 'l1_ratio': 0.01043339485040439}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:00,890] Trial 599 finished with value: 0.007199985274894886 and parameters: {'alpha': 193421285.426026, 'l1_ratio': 9.596039942121091e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:01,294] Trial 600 finished with value: 0.35616863842838015 and parameters: {'alpha': 20431.29729629465, 'l1_ratio': 0.001392792255376375}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:02,036] Trial 601 finished with value: 0.30777640490968083 and parameters: {'alpha': 67760.69496018275, 'l1_ratio': 5.8547841440612344e-05}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.865e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e-01, tolerance: 1.895e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.905e-02, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:09,324] Trial 588 finished with value: -6.803873399650838 and parameters: {'alpha': 0.28840277358398686, 'l1_ratio': 0.0013426717028322077}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:12,207] Trial 602 finished with value: -0.02993833144455671 and parameters: {'alpha': 12145.21162811462, 'l1_ratio': 1.544036537617879e-10}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:14,115] Trial 585 finished with value: -4.705745158741586 and parameters: {'alpha': 0.718310167793297, 'l1_ratio': 1.1375886788805289e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:14,401] Trial 605 finished with value: 0.34289511999740013 and parameters: {'alpha': 37336.41378559542, 'l1_ratio': 0.003308386779814481}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:14,671] Trial 606 finished with value: -0.0010605577384500038 and parameters: {'alpha': 9630581811.94564, 'l1_ratio': 0.0007885422500254703}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:14,963] Trial 607 finished with value: 0.008240343110919812 and parameters: {'alpha': 111742.64848967017, 'l1_ratio': 0.0023042274063329584}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:15,325] Trial 608 finished with value: -0.002041526551683881 and parameters: {'alpha': 34698963.847382866, 'l1_ratio': 1.2936496432311986e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:15,628] Trial 609 finished with value: -0.0010605577384500038 and parameters: {'alpha': 888393033.9650564, 'l1_ratio': 0.00040484655877082686}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.046e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:18,640] Trial 564 finished with value: -7.2827965082143855 and parameters: {'alpha': 0.10166338217492417, 'l1_ratio': 3.492255175651997e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:18,907] Trial 611 finished with value: -0.0010605577384500038 and parameters: {'alpha': 409227.9515821315, 'l1_ratio': 0.006559917151146424}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:19,094] Trial 603 finished with value: -5.65918558011136 and parameters: {'alpha': 2.5364675208037194e-05, 'l1_ratio': 0.003095694299683146}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:19,148] Trial 612 finished with value: -0.05035018878415184 and parameters: {'alpha': 8545.1887606665, 'l1_ratio': 0.035100630119833214}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:19,427] Trial 613 finished with value: 0.3788909601234725 and parameters: {'alpha': 5693.706253290541, 'l1_ratio': 0.017981980968993217}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.093e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:20,374] Trial 589 finished with value: -0.6255092734363117 and parameters: {'alpha': 17.451323705454453, 'l1_ratio': 1.3156316680134248e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:20,774] Trial 616 finished with value: -0.0010605577384500038 and parameters: {'alpha': 27213.865617783533, 'l1_ratio': 0.22891231943710613}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:22,596] Trial 617 finished with value: -0.4871071845655925 and parameters: {'alpha': 398.03826019756525, 'l1_ratio': 0.004267501126731502}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:23,271] Trial 618 finished with value: -6.377658081313444 and parameters: {'alpha': 1.1609641831941183e-09, 'l1_ratio': 0.0018252020305572496}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:23,436] Trial 619 finished with value: -0.0007613269763294683 and parameters: {'alpha': 65932.5478230925, 'l1_ratio': 0.008891273576949141}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.495e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.387e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.284e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.005e-01, tolerance: 1.895e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.733e-02, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:41,709] Trial 592 finished with value: -3.666273012296252 and parameters: {'alpha': 1.3251087780466753, 'l1_ratio': 6.600250561606049e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:42,017] Trial 621 finished with value: 0.1123447767797714 and parameters: {'alpha': 253381.62762937014, 'l1_ratio': 0.0007356827835178555}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+00, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:46,334] Trial 622 finished with value: -4.736094839551445 and parameters: {'alpha': 4.027727864528885e-06, 'l1_ratio': 6.332602518758104e-07}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.416e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:46,845] Trial 596 finished with value: -8.681618859743883 and parameters: {'alpha': 0.05121733650964862, 'l1_ratio': 0.004450039864041434}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:47,380] Trial 624 finished with value: 0.2179339867990113 and parameters: {'alpha': 20449.079184717066, 'l1_ratio': 0.00023483197231374275}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:47,985] Trial 625 finished with value: 0.32120295227073037 and parameters: {'alpha': 89097.03445931582, 'l1_ratio': 1.4525793780152107e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:48,412] Trial 626 finished with value: -0.02113556886385637 and parameters: {'alpha': 3820.4249009917417, 'l1_ratio': 0.0011003924463774942}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.159e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:48,761] Trial 627 finished with value: 0.3856968310926175 and parameters: {'alpha': 38005.48774819411, 'l1_ratio': 0.002269098370090015}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:50,341] Trial 623 finished with value: -4.981412239095385 and parameters: {'alpha': 1.0858967753101516e-06, 'l1_ratio': 0.12869950271771446}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:50,513] Trial 629 finished with value: 0.35593079531998323 and parameters: {'alpha': 13313.031281560925, 'l1_ratio': 0.0024978827373341957}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:52,494] Trial 630 finished with value: -0.4718251407176765 and parameters: {'alpha': 142.83698721230814, 'l1_ratio': 0.007098976097594322}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:52,733] Trial 631 finished with value: 0.08185891631578994 and parameters: {'alpha': 1130.6551096297062, 'l1_ratio': 0.18905307893269432}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:52,918] Trial 632 finished with value: 0.0002685218694552516 and parameters: {'alpha': 2644334050.295469, 'l1_ratio': 3.7625133470923404e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:53,086] Trial 633 finished with value: -0.0010605577384500038 and parameters: {'alpha': 866014.3774602787, 'l1_ratio': 0.0040002217052048615}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.317e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:04:56,506] Trial 594 finished with value: -7.004517680228437 and parameters: {'alpha': 0.2093462326083818, 'l1_ratio': 1.3860585633761113e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:56,886] Trial 635 finished with value: 0.38924954820272434 and parameters: {'alpha': 37808.87447744437, 'l1_ratio': 0.0019327276644285215}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:57,266] Trial 636 finished with value: -0.022204825672430872 and parameters: {'alpha': 30054.52785855647, 'l1_ratio': 0.013084381973969711}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:58,315] Trial 637 finished with value: 0.36060886162323513 and parameters: {'alpha': 193515.3096451677, 'l1_ratio': 3.072823691092738e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:58,890] Trial 638 finished with value: 0.3401860556851229 and parameters: {'alpha': 9659.994286093635, 'l1_ratio': 0.0021139799903272683}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:04:59,262] Trial 639 finished with value: -0.0010605577384500038 and parameters: {'alpha': 7692416.850797013, 'l1_ratio': 0.05347241615124366}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:00,389] Trial 640 finished with value: -6.376966971159752 and parameters: {'alpha': 5.650096281456844e-09, 'l1_ratio': 0.006393849069355635}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:00,659] Trial 641 finished with value: 0.2553191910932765 and parameters: {'alpha': 53441.80783070298, 'l1_ratio': 0.002943991773123762}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:00,923] Trial 642 finished with value: 0.3780618997719804 and parameters: {'alpha': 2967.3880861012562, 'l1_ratio': 0.02187615122944376}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:01,165] Trial 643 finished with value: 0.3540297292848086 and parameters: {'alpha': 17008.510470475074, 'l1_ratio': 0.0015583924934792922}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:07,854] Trial 610 finished with value: -7.482531049428136 and parameters: {'alpha': 0.1362574490201744, 'l1_ratio': 0.00781975100127503}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:08,024] Trial 644 finished with value: -4.974283471554158 and parameters: {'alpha': 1.5082142120728491e-05, 'l1_ratio': 0.003910305473584608}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:08,252] Trial 645 finished with value: -0.0010605577384500038 and parameters: {'alpha': 75027.17811736702, 'l1_ratio': 0.4028584530887794}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:08,374] Trial 646 finished with value: 0.3629973654187089 and parameters: {'alpha': 168607.58964316716, 'l1_ratio': 0.00047582805139216236}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.125e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:08,602] Trial 604 finished with value: -8.213744298127487 and parameters: {'alpha': 0.07547800244010457, 'l1_ratio': 0.002386064204228075}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:08,970] Trial 647 finished with value: 0.2640957954477175 and parameters: {'alpha': 5843.265866123046, 'l1_ratio': 0.0018051070152830214}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.488e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:09,329] Trial 649 finished with value: 0.15874070252868236 and parameters: {'alpha': 4963.757335018681, 'l1_ratio': 0.0013158355344254952}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:09,385] Trial 650 finished with value: -0.0010605577384500038 and parameters: {'alpha': 282452745.3291925, 'l1_ratio': 0.0011582953518780219}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:09,609] Trial 651 finished with value: 0.3624802542934541 and parameters: {'alpha': 35813.910927190904, 'l1_ratio': 0.0008282780132248191}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:09,949] Trial 653 finished with value: 0.3609344601438474 and parameters: {'alpha': 527559.8651617068, 'l1_ratio': 6.403141885753043e-10}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.245e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.566e-02, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:16,210] Trial 654 finished with value: 0.034565362204306026 and parameters: {'alpha': 15790.890236740443, 'l1_ratio': 7.220885924921282e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:16,413] Trial 655 finished with value: -0.0010605577384500038 and parameters: {'alpha': 3419874550.513931, 'l1_ratio': 6.506087174144479e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:17,300] Trial 656 finished with value: -6.374074176992734 and parameters: {'alpha': 6.103855192042594e-08, 'l1_ratio': 0.011325401315658984}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.781e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:17,671] Trial 614 finished with value: -3.5157931061512357 and parameters: {'alpha': 0.7965604937109405, 'l1_ratio': 0.004370717432532377}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:17,983] Trial 658 finished with value: 0.33147421176550623 and parameters: {'alpha': 108572.88297824933, 'l1_ratio': 3.676575665667991e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:18,177] Trial 657 finished with value: -0.4063145461043232 and parameters: {'alpha': 543.6095972416874, 'l1_ratio': 0.00466440000861085}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:18,504] Trial 660 finished with value: 0.3760485783868223 and parameters: {'alpha': 20242.81073444217, 'l1_ratio': 0.0026480559966831694}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:19,010] Trial 661 finished with value: 0.27669994922120406 and parameters: {'alpha': 44365.37456527566, 'l1_ratio': 8.620503746489588e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:19,287] Trial 662 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1898096.2371032166, 'l1_ratio': 0.031555850916684544}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:19,535] Trial 663 finished with value: -0.0010605577384500038 and parameters: {'alpha': 95470942.65909082, 'l1_ratio': 0.00034632246322542794}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:20,082] Trial 664 finished with value: 0.3664470449559747 and parameters: {'alpha': 246527.94756237062, 'l1_ratio': 2.1075693546764956e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:22,053] Trial 665 finished with value: -0.3305701847142551 and parameters: {'alpha': 1686.2593678930182, 'l1_ratio': 0.0006723186998955312}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:26,521] Trial 615 finished with value: 0.11961436929905944 and parameters: {'alpha': 595.5993842974809, 'l1_ratio': 3.659756745739143e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:27,201] Trial 667 finished with value: 0.02363096268494173 and parameters: {'alpha': 10658.444073540039, 'l1_ratio': 0.00018564871636354933}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:27,349] Trial 668 finished with value: -0.03430460229600726 and parameters: {'alpha': 113802.60513904049, 'l1_ratio': 0.003040101643194239}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:27,501] Trial 669 finished with value: 0.3701004591340455 and parameters: {'alpha': 26119.840879598163, 'l1_ratio': 0.0017191994147404824}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:27,724] Trial 666 finished with value: -0.10721608636005404 and parameters: {'alpha': 8754.121100699718, 'l1_ratio': 1.2406793860199083e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:28,022] Trial 670 finished with value: 0.26138744466105435 and parameters: {'alpha': 46050.916159096996, 'l1_ratio': 2.34546014421487e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:28,055] Trial 671 finished with value: -0.012361863838674029 and parameters: {'alpha': 16657968.938622387, 'l1_ratio': 2.0340681405308255e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:28,296] Trial 673 finished with value: -0.0010605577384500038 and parameters: {'alpha': 601339.3189398964, 'l1_ratio': 0.016682108858631518}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:28,798] Trial 674 finished with value: 0.33050148154117576 and parameters: {'alpha': 2822.4986450439733, 'l1_ratio': 0.006399863260584585}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:29,131] Trial 675 finished with value: 0.3764962441638036 and parameters: {'alpha': 83099.70540543957, 'l1_ratio': 0.001077233620194337}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:30,089] Trial 676 finished with value: -6.377166960043011 and parameters: {'alpha': 2.9380723579596396e-09, 'l1_ratio': 0.002954358795418079}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:32,912] Trial 677 finished with value: 0.10682360585033306 and parameters: {'alpha': 21422.837102433274, 'l1_ratio': 2.346152167830171e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:33,272] Trial 678 finished with value: 0.18887365198628667 and parameters: {'alpha': 159.37395985856256, 'l1_ratio': 0.054964211484861934}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:33,460] Trial 679 finished with value: 0.3631999505767235 and parameters: {'alpha': 300758.8241423901, 'l1_ratio': 9.494993092223491e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:33,729] Trial 672 finished with value: 0.21659988815360462 and parameters: {'alpha': 51.76307249777102, 'l1_ratio': 0.007703663905645612}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:34,007] Trial 680 finished with value: -6.376346696807017 and parameters: {'alpha': 8.060949817293942e-09, 'l1_ratio': 0.14368490636334055}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:34,327] Trial 682 finished with value: 0.23621001308292291 and parameters: {'alpha': 5807.537227658081, 'l1_ratio': 0.001573204617346014}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.453e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:34,543] Trial 620 finished with value: -8.151408831518728 and parameters: {'alpha': 0.06177171205623545, 'l1_ratio': 8.930381661071057e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:34,617] Trial 652 finished with value: -15.049399107482172 and parameters: {'alpha': 9.346663776106648e-05, 'l1_ratio': 8.971204418769143e-10}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.213e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:34,961] Trial 684 finished with value: 0.3598447797352931 and parameters: {'alpha': 46759.98399960543, 'l1_ratio': 0.0005707513291899661}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+00, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:36,199] Trial 685 finished with value: 0.24682464806978108 and parameters: {'alpha': 44921.46670738055, 'l1_ratio': 2.763999008840689e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:37,409] Trial 683 finished with value: -4.946830879378721 and parameters: {'alpha': 2.61588032589428e-06, 'l1_ratio': 0.0005294046222915712}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.555e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:38,701] Trial 681 finished with value: -0.16715789463864636 and parameters: {'alpha': 6536.550473030766, 'l1_ratio': 3.3841880045447902e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:39,057] Trial 689 finished with value: 0.34002564125968743 and parameters: {'alpha': 131598.98244358462, 'l1_ratio': 0.00011858800581372298}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:40,055] Trial 688 finished with value: -4.504583200079261 and parameters: {'alpha': 6.587338212935835e-06, 'l1_ratio': 0.004752357161036784}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:40,347] Trial 691 finished with value: 0.35202702927174506 and parameters: {'alpha': 14287.766457219393, 'l1_ratio': 0.0018707065070740867}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.110e-03, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:41,581] Trial 692 finished with value: -0.3534714076529421 and parameters: {'alpha': 1561.1140372586176, 'l1_ratio': 0.0009565457706720743}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:42,240] Trial 687 finished with value: -4.646896795456025 and parameters: {'alpha': 8.110972119492672e-06, 'l1_ratio': 0.011577339303405258}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:43,442] Trial 690 finished with value: -4.59132850540241 and parameters: {'alpha': 7.866439686132266e-06, 'l1_ratio': 0.005184990827683987}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:43,599] Trial 695 finished with value: -0.0010605577384500038 and parameters: {'alpha': 315997.537258037, 'l1_ratio': 0.0031637048745216216}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:43,970] Trial 694 finished with value: 0.3632358696111082 and parameters: {'alpha': 47.83986937322027, 'l1_ratio': 0.0032899903632221646}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:45,259] Trial 696 finished with value: 0.13078602310511067 and parameters: {'alpha': 23848.346158276516, 'l1_ratio': 1.9669120773573343e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:45,582] Trial 698 finished with value: -0.0010605577384500038 and parameters: {'alpha': 93739.2087953467, 'l1_ratio': 0.6866358542852175}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:53,066] Trial 686 finished with value: -1.3965515913916828 and parameters: {'alpha': 3.0288450382972174, 'l1_ratio': 0.0048327049107273245}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:53,341] Trial 700 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1260784.4686620522, 'l1_ratio': 0.0020325432386574015}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:53,850] Trial 701 finished with value: 0.3386323795011429 and parameters: {'alpha': 13561.501649415153, 'l1_ratio': 0.0012916385430026063}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:54,994] Trial 702 finished with value: -6.370936481809964 and parameters: {'alpha': 1.8949292794479268e-08, 'l1_ratio': 0.5170488846166872}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:55,469] Trial 703 finished with value: -6.377308018275457 and parameters: {'alpha': 3.720497541691101e-10, 'l1_ratio': 1.311315188192075e-05}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.706e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:57,156] Trial 634 finished with value: -7.12952406956268 and parameters: {'alpha': 0.11957363295696409, 'l1_ratio': 5.9068259430669696e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:57,443] Trial 705 finished with value: -0.0010605577384500038 and parameters: {'alpha': 57404.31036884908, 'l1_ratio': 0.010906750973591858}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.812e-03, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:05:57,656] Trial 706 finished with value: -0.0010605577384500038 and parameters: {'alpha': 3428.202407105647, 'l1_ratio': 0.9731301949521906}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:05:57,782] Trial 707 finished with value: -0.0010605577384500038 and parameters: {'alpha': 148208.4781768898, 'l1_ratio': 0.022372405626506487}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:00,161] Trial 708 finished with value: 0.18483309557703728 and parameters: {'alpha': 31087.559458221163, 'l1_ratio': 4.1782501788005114e-08}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.060e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:06:03,633] Trial 628 finished with value: 0.3142389279748148 and parameters: {'alpha': 101.28387533336948, 'l1_ratio': 3.3198209373527016e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:04,092] Trial 710 finished with value: 0.2912902363994648 and parameters: {'alpha': 13108.423262904673, 'l1_ratio': 0.0008501928358550891}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:04,474] Trial 711 finished with value: 0.2945513497746695 and parameters: {'alpha': 5815.2420305579035, 'l1_ratio': 0.002102239254803219}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:04,698] Trial 712 finished with value: 0.026784699551855733 and parameters: {'alpha': 522591.7003891551, 'l1_ratio': 0.000392411182096326}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:04,918] Trial 713 finished with value: -0.0010605577384500038 and parameters: {'alpha': 88154.94606795305, 'l1_ratio': 0.008010992423669672}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:05,209] Trial 704 finished with value: -0.23826746694930437 and parameters: {'alpha': 3382.3158284611036, 'l1_ratio': 4.13811389221081e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e-03, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:06:05,523] Trial 715 finished with value: -0.0010605577384500038 and parameters: {'alpha': 804500311.2316724, 'l1_ratio': 0.0013148662043909114}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:05,831] Trial 714 finished with value: -6.377396361331781 and parameters: {'alpha': 1.0953585011934002e-10, 'l1_ratio': 0.06405058483476032}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:05,940] Trial 716 finished with value: -0.0010605577384500038 and parameters: {'alpha': 40214.652651649514, 'l1_ratio': 0.06680373439105892}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:06,113] Trial 718 finished with value: -0.0010605577384500038 and parameters: {'alpha': 2757524.1238913145, 'l1_ratio': 0.00024301336807348587}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:06,855] Trial 717 finished with value: -6.377734370510967 and parameters: {'alpha': 8.12546206668586e-10, 'l1_ratio': 1.3959849318805437e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:07,373] Trial 719 finished with value: -0.4358553042966272 and parameters: {'alpha': 756.4037964695372, 'l1_ratio': 0.002684274682945984}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:07,435] Trial 720 finished with value: 0.3569620525552184 and parameters: {'alpha': 177405.7073780661, 'l1_ratio': 8.925710420821774e-07}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.824e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:06:08,774] Trial 648 finished with value: 0.29430661774683453 and parameters: {'alpha': 90.90228555205924, 'l1_ratio': 1.5393325392768096e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:09,020] Trial 723 finished with value: 0.3368667231503821 and parameters: {'alpha': 22433.835893874733, 'l1_ratio': 0.005774874319244363}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.198e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:06:23,855] Trial 659 finished with value: -32.40704874397935 and parameters: {'alpha': 0.0034557484564317923, 'l1_ratio': 0.0031943630197136547}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:24,024] Trial 725 finished with value: -0.0010605577384500038 and parameters: {'alpha': 47006071.7958533, 'l1_ratio': 0.0008139511825315689}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:24,183] Trial 726 finished with value: -0.03885364891893698 and parameters: {'alpha': 9261.695982519752, 'l1_ratio': 0.036021940843712116}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:24,500] Trial 709 finished with value: -17.185465062349948 and parameters: {'alpha': 0.00010690864084730231, 'l1_ratio': 0.0002619483861271918}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:24,986] Trial 728 finished with value: 0.31038223846719093 and parameters: {'alpha': 72607.0997863443, 'l1_ratio': 4.838649450891707e-05}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:06:28,994] Trial 722 finished with value: -8.186405807726523 and parameters: {'alpha': 4.439915719807409e-05, 'l1_ratio': 0.006652666763094303}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:06:32,093] Trial 693 finished with value: -27.507693556800383 and parameters: {'alpha': 0.0033885299957311793, 'l1_ratio': 0.010327082105714343}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:32,516] Trial 731 finished with value: 0.004680134777292011 and parameters: {'alpha': 467399422.41198194, 'l1_ratio': 7.362886497073787e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:32,892] Trial 732 finished with value: 0.3693973653117101 and parameters: {'alpha': 25593.083788065716, 'l1_ratio': 0.001741720564788624}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:33,042] Trial 733 finished with value: -0.0010605577384500038 and parameters: {'alpha': 208605.20108698725, 'l1_ratio': 0.01684663221125514}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.735e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.246e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:06:50,998] Trial 697 finished with value: -48.75937636747312 and parameters: {'alpha': 0.0009284926357975053, 'l1_ratio': 0.00208073609487668}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.509e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.487e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.681e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:06:59,142] Trial 699 finished with value: -3.0858006528214137 and parameters: {'alpha': 2.014312348575906, 'l1_ratio': 5.9915966824932125e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:06:59,732] Trial 735 finished with value: -0.28937493448224516 and parameters: {'alpha': 18.090600301051694, 'l1_ratio': 0.001120568878191162}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:01,186] Trial 736 finished with value: -0.36705476142739796 and parameters: {'alpha': 1439.7332332772896, 'l1_ratio': 0.001080135341887486}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.245e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:01,736] Trial 738 finished with value: 0.25497498089562104 and parameters: {'alpha': 13260.219758090328, 'l1_ratio': 0.0006306674191672215}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:01,931] Trial 721 finished with value: -38.0741440427671 and parameters: {'alpha': 0.00018601380426163508, 'l1_ratio': 0.035570993092334406}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:02,385] Trial 739 finished with value: 0.3263863071224283 and parameters: {'alpha': 76423.14428174851, 'l1_ratio': 0.00013591022592153478}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:03,684] Trial 740 finished with value: 0.2487280877411703 and parameters: {'alpha': 45563.41818193746, 'l1_ratio': 2.1092589760766933e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:04,072] Trial 742 finished with value: 0.3463691086637667 and parameters: {'alpha': 6371.0943200627125, 'l1_ratio': 0.0045683099957086895}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:04,415] Trial 743 finished with value: -0.0010605577384500038 and parameters: {'alpha': 820740.5652982669, 'l1_ratio': 0.003034965565904922}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:04,781] Trial 744 finished with value: 0.36861964257515556 and parameters: {'alpha': 289378.8957600921, 'l1_ratio': 2.3557122246592916e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:05,098] Trial 745 finished with value: 0.35705476675444964 and parameters: {'alpha': 17466.529533964524, 'l1_ratio': 0.0017947401725877008}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.898e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:05,707] Trial 746 finished with value: 0.24327776492300077 and parameters: {'alpha': 2465.550642532762, 'l1_ratio': 0.004138419844600054}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.637e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.695e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:15,202] Trial 734 finished with value: -27.35188523122657 and parameters: {'alpha': 0.0001928537053556123, 'l1_ratio': 2.0467760003499055e-08}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.612e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:23,798] Trial 729 finished with value: -12.00535958884469 and parameters: {'alpha': 0.019717755446267308, 'l1_ratio': 0.0017613637599167896}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:25,342] Trial 749 finished with value: -6.351712469423592 and parameters: {'alpha': 2.056776921186883e-07, 'l1_ratio': 0.02117993234046488}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:25,814] Trial 750 finished with value: -0.0010605577384500038 and parameters: {'alpha': 32143.323103719194, 'l1_ratio': 0.1317616245962366}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:26,676] Trial 751 finished with value: 0.3261123896574048 and parameters: {'alpha': 96006.38744121378, 'l1_ratio': 7.70436326223901e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:26,885] Trial 752 finished with value: -0.0010605577384500038 and parameters: {'alpha': 9602539.014099486, 'l1_ratio': 0.0004778204773849251}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.902e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:27,435] Trial 724 finished with value: -2.91340287303545 and parameters: {'alpha': 2.2843672612394874, 'l1_ratio': 6.934390690321832e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:27,717] Trial 754 finished with value: -0.0010605577384500038 and parameters: {'alpha': 4199062259.2103696, 'l1_ratio': 0.0026833955319509263}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:28,605] Trial 755 finished with value: -6.465510173957438 and parameters: {'alpha': 1.612733671905601e-07, 'l1_ratio': 0.010528918020556628}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.752e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.981e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:32,921] Trial 727 finished with value: -1.0759731522283411 and parameters: {'alpha': 10.724752958738524, 'l1_ratio': 1.7324544387019314e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:33,367] Trial 757 finished with value: 0.22907628252660847 and parameters: {'alpha': 9008.70683345133, 'l1_ratio': 0.0008711693540330008}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:34,002] Trial 756 finished with value: 0.03669641945798593 and parameters: {'alpha': 346.3322571769438, 'l1_ratio': 0.0008099777109851686}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:34,135] Trial 759 finished with value: -0.0010605577384500038 and parameters: {'alpha': 154091.65040350944, 'l1_ratio': 0.006045796507255515}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:35,081] Trial 760 finished with value: 0.20955801093712648 and parameters: {'alpha': 35551.8271533633, 'l1_ratio': 4.6957285914259417e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:35,556] Trial 761 finished with value: 0.14064518317627275 and parameters: {'alpha': 4616.096657469212, 'l1_ratio': 0.001362907500421367}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+00, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:37,823] Trial 762 finished with value: -0.0010605577384500038 and parameters: {'alpha': 447779.81528447627, 'l1_ratio': 0.0036164812750890197}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:38,245] Trial 730 finished with value: -24.0236308855437 and parameters: {'alpha': 0.004823614114814914, 'l1_ratio': 0.0015729043917665413}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.804e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:38,470] Trial 764 finished with value: -0.0010605577384500038 and parameters: {'alpha': 13550.913779720766, 'l1_ratio': 0.2489002597405316}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:38,498] Trial 737 finished with value: -0.11937684304356815 and parameters: {'alpha': 1306.8888119047647, 'l1_ratio': 1.5939461016278995e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:38,975] Trial 765 finished with value: 0.25785594470304335 and parameters: {'alpha': 64341.07939799463, 'l1_ratio': 0.002410209614691976}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:39,441] Trial 767 finished with value: -0.034322995193036464 and parameters: {'alpha': 24300.634023343046, 'l1_ratio': 0.014319665857927055}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:39,739] Trial 768 finished with value: 0.3755108927677638 and parameters: {'alpha': 141531.5368557839, 'l1_ratio': 0.00032996489601187865}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:40,868] Trial 758 finished with value: -0.10030161884355467 and parameters: {'alpha': 317.205778300497, 'l1_ratio': 0.0013656440578467622}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:41,236] Trial 770 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1858535.344079911, 'l1_ratio': 0.007175180099102776}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:41,431] Trial 771 finished with value: 0.34652599150016666 and parameters: {'alpha': 7018.131101351922, 'l1_ratio': 0.003958716954525582}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:41,991] Trial 772 finished with value: -6.377210683799779 and parameters: {'alpha': 4.718770866915614e-09, 'l1_ratio': 0.002859534368487353}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:42,358] Trial 773 finished with value: 0.2652036584961229 and parameters: {'alpha': 41826.39168923278, 'l1_ratio': 7.281816929146562e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:42,551] Trial 774 finished with value: -0.0010605577384500038 and parameters: {'alpha': 103098457.96294756, 'l1_ratio': 0.0005434471447973328}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:42,714] Trial 775 finished with value: -0.0010605577384500038 and parameters: {'alpha': 300677.31640937924, 'l1_ratio': 0.005075352050846577}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:45,630] Trial 769 finished with value: -0.17195989458990166 and parameters: {'alpha': 6384.284029759877, 'l1_ratio': 6.278446149045294e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+00, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:52,725] Trial 741 finished with value: -39.5728996494445 and parameters: {'alpha': 0.0003902735353496276, 'l1_ratio': 4.5974092978608413e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:53,158] Trial 778 finished with value: 0.35605098391725193 and parameters: {'alpha': 15308.23169252556, 'l1_ratio': 0.0020767441366129694}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:53,594] Trial 779 finished with value: 0.34964872291192844 and parameters: {'alpha': 97101.59077448773, 'l1_ratio': 0.0011081966478286521}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:54,741] Trial 747 finished with value: -6.977136317480416 and parameters: {'alpha': 0.26089550090039526, 'l1_ratio': 0.002267858849766067}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:54,864] Trial 781 finished with value: -0.0010605577384500038 and parameters: {'alpha': 5606752.362942856, 'l1_ratio': 0.010693596197771637}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:55,439] Trial 782 finished with value: 0.21524802653432204 and parameters: {'alpha': 36046.9523633482, 'l1_ratio': 6.128211161437454e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:07:55,568] Trial 783 finished with value: 0.15155934282714842 and parameters: {'alpha': 708054.730374677, 'l1_ratio': 0.00018165438162179737}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.218e-02, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:07:59,093] Trial 784 finished with value: -5.064044311730996 and parameters: {'alpha': 6.053635020836988e-07, 'l1_ratio': 0.6051627204866271}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.259e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:08:07,174] Trial 748 finished with value: 0.32256363456967313 and parameters: {'alpha': 267.76574691261743, 'l1_ratio': 1.2920343864850378e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:08,122] Trial 786 finished with value: -6.374825300912436 and parameters: {'alpha': 3.563162152751406e-08, 'l1_ratio': 0.000688223319499767}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:09,342] Trial 787 finished with value: -6.377544050608911 and parameters: {'alpha': 1.5775745606592406e-09, 'l1_ratio': 0.006449632466066473}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:10,491] Trial 788 finished with value: -6.377385803061429 and parameters: {'alpha': 2.4036853567398935e-10, 'l1_ratio': 0.0038664528867446805}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:10,941] Trial 789 finished with value: -0.024556109506437718 and parameters: {'alpha': 18781.976626872576, 'l1_ratio': 0.020433593910817154}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:11,617] Trial 790 finished with value: -0.1188541454277879 and parameters: {'alpha': 2767.9994674335985, 'l1_ratio': 0.001285906845545761}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:17,118] Trial 791 finished with value: 0.19793969428155167 and parameters: {'alpha': 26.524949007247635, 'l1_ratio': 0.002510842680807017}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.020e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e+00, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:08:18,711] Trial 792 finished with value: 0.2947184199624053 and parameters: {'alpha': 66125.52429865657, 'l1_ratio': 2.3109020338740432e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:19,563] Trial 793 finished with value: 0.36622311867458274 and parameters: {'alpha': 243540.8885009456, 'l1_ratio': 3.512033923770953e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:19,996] Trial 794 finished with value: 0.2350075643702769 and parameters: {'alpha': 14800.879678829157, 'l1_ratio': 0.0004421189970533387}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:23,169] Trial 795 finished with value: -4.850779682516535 and parameters: {'alpha': 3.554665406017523e-06, 'l1_ratio': 0.007854572399688413}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.747e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:08:23,581] Trial 796 finished with value: 0.340568658343509 and parameters: {'alpha': 920.0755059406214, 'l1_ratio': 0.029582707315559766}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:23,903] Trial 797 finished with value: 0.07404445549496556 and parameters: {'alpha': 55071.35751003978, 'l1_ratio': 0.0037922083921840205}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:24,595] Trial 798 finished with value: 0.13917581795749326 and parameters: {'alpha': 3852.3531370292058, 'l1_ratio': 0.001681157284973562}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:28,355] Trial 785 finished with value: -16.274068653950266 and parameters: {'alpha': 6.313608527955538e-05, 'l1_ratio': 0.024851316604466378}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:28,795] Trial 800 finished with value: 0.33092392731522596 and parameters: {'alpha': 128919.09602747683, 'l1_ratio': 0.0008722136398387802}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:29,136] Trial 801 finished with value: -0.0010605577384500038 and parameters: {'alpha': 24117137.55905064, 'l1_ratio': 0.012948264310596097}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.527e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.246e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:08:41,949] Trial 766 finished with value: -13.584997217256081 and parameters: {'alpha': 0.013679402241950526, 'l1_ratio': 0.0024761586388179707}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:08:42,401] Trial 753 finished with value: 0.25073249952472965 and parameters: {'alpha': 378.2275384589198, 'l1_ratio': 2.3024614325608493e-09}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.351e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:08:44,007] Trial 777 finished with value: -7.038273234484219 and parameters: {'alpha': 0.253149773052641, 'l1_ratio': 0.002198618006630202}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:44,443] Trial 805 finished with value: 0.36964224834762416 and parameters: {'alpha': 9975.515913444255, 'l1_ratio': 0.005288527257380772}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:44,498] Trial 804 finished with value: -6.036493276280838 and parameters: {'alpha': 3.4427601875010254e-07, 'l1_ratio': 9.203296294993047e-08}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:08:44,814] Trial 807 finished with value: 0.3643905038786334 and parameters: {'alpha': 29485.16142167944, 'l1_ratio': 0.0012683316272743262}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:44,884] Trial 763 finished with value: -6.954659306529162 and parameters: {'alpha': 0.2614496271225296, 'l1_ratio': 7.936775261844151e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:45,294] Trial 806 finished with value: 0.2543882384680895 and parameters: {'alpha': 33268.594257801655, 'l1_ratio': 0.0001310659336925718}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:45,369] Trial 809 finished with value: 0.356291087634362 and parameters: {'alpha': 129894.42515425506, 'l1_ratio': 0.0007407454287019575}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:45,823] Trial 810 finished with value: 0.3852121951440221 and parameters: {'alpha': 105196.19747660887, 'l1_ratio': 0.0006902893347809516}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:45,946] Trial 808 finished with value: 0.33871385716138086 and parameters: {'alpha': 116097.2851635988, 'l1_ratio': 5.695628374920611e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:46,097] Trial 812 finished with value: -0.0010605577384500038 and parameters: {'alpha': 401115.4636187554, 'l1_ratio': 0.0035924687181923044}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:46,216] Trial 813 finished with value: -0.00015570934990805085 and parameters: {'alpha': 3877319407.1842127, 'l1_ratio': 1.174329418496851e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:46,351] Trial 814 finished with value: 0.00042151545205774504 and parameters: {'alpha': 2341620559.840382, 'l1_ratio': 8.074433383655826e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:48,974] Trial 811 finished with value: -0.3284007662547506 and parameters: {'alpha': 2313.997577927707, 'l1_ratio': 0.00031680840448086104}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.210e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.845e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:08:52,458] Trial 776 finished with value: -7.011711346629762 and parameters: {'alpha': 0.1829315292405248, 'l1_ratio': 5.400215921968742e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:52,699] Trial 803 finished with value: -0.08443733764903454 and parameters: {'alpha': 9671.299028384015, 'l1_ratio': 7.621738780997368e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:52,860] Trial 816 finished with value: -0.24617853038085358 and parameters: {'alpha': 2279.7613632480493, 'l1_ratio': 3.177619144595978e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:52,871] Trial 818 finished with value: -0.0010605577384500038 and parameters: {'alpha': 8885.249549636232, 'l1_ratio': 0.12159544365415621}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:53,206] Trial 819 finished with value: -0.0010605577384500038 and parameters: {'alpha': 24116.13642390324, 'l1_ratio': 0.18813636542580295}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:53,567] Trial 822 finished with value: -0.01168038023754033 and parameters: {'alpha': 53316.4806333272, 'l1_ratio': 0.008353239650476432}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:55,677] Trial 815 finished with value: -5.055929170405026 and parameters: {'alpha': 1.7890573653075363e-05, 'l1_ratio': 0.00029855399948865136}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:56,101] Trial 824 finished with value: -0.0010605577384500038 and parameters: {'alpha': 392195012.0809416, 'l1_ratio': 0.001492955708008958}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:56,370] Trial 825 finished with value: -0.0010605577384500038 and parameters: {'alpha': 773610.892785509, 'l1_ratio': 0.004944952607269672}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:56,392] Trial 821 finished with value: 0.36272415025919724 and parameters: {'alpha': 6.606783004390005, 'l1_ratio': 0.04412353008387253}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:56,536] Trial 817 finished with value: -0.026915395137569798 and parameters: {'alpha': 12296.955508891822, 'l1_ratio': 4.549477110083918e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:56,827] Trial 826 finished with value: -0.0010605577384500038 and parameters: {'alpha': 2073565.0393777788, 'l1_ratio': 0.07986227051129381}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:56,964] Trial 828 finished with value: -0.0010605577384500038 and parameters: {'alpha': 2661196.9433550453, 'l1_ratio': 0.003075722529505064}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:57,264] Trial 829 finished with value: -0.0010605577384500038 and parameters: {'alpha': 292245.9087868231, 'l1_ratio': 0.003003804551223366}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:57,372] Trial 830 finished with value: -0.0014366308938499699 and parameters: {'alpha': 312490.8342540182, 'l1_ratio': 0.0017446397699237347}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:57,681] Trial 831 finished with value: 0.3837171790145271 and parameters: {'alpha': 44519.92961838156, 'l1_ratio': 0.0011346422978764654}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:57,709] Trial 820 finished with value: -5.14781314546107 and parameters: {'alpha': 1.2977020288596152e-06, 'l1_ratio': 0.007122084255947294}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:57,786] Trial 832 finished with value: -0.0010605577384500038 and parameters: {'alpha': 49016.148545053176, 'l1_ratio': 0.01428248626803201}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:58,126] Trial 833 finished with value: 0.37490007790772706 and parameters: {'alpha': 4688.956931706163, 'l1_ratio': 0.012888655129448541}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:08:58,175] Trial 834 finished with value: 0.3842336884047411 and parameters: {'alpha': 6373.727228061688, 'l1_ratio': 0.014626679236687855}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:09:00,706] Trial 827 finished with value: 0.08860469761446743 and parameters: {'alpha': 19783.7540335415, 'l1_ratio': 2.2138846475751547e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:00,872] Trial 838 finished with value: 0.04175042935618881 and parameters: {'alpha': 920.9409911842899, 'l1_ratio': 0.26488484575894755}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:01,249] Trial 839 finished with value: -0.0010605577384500038 and parameters: {'alpha': 178034207.4029982, 'l1_ratio': 0.0018797354472115222}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:03,123] Trial 837 finished with value: 0.07828316670354311 and parameters: {'alpha': 18931.707556864112, 'l1_ratio': 2.3465174378813718e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:03,488] Trial 841 finished with value: 0.3889910629331639 and parameters: {'alpha': 105159.62616151574, 'l1_ratio': 0.000565547163407624}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:03,804] Trial 842 finished with value: 0.3439877804188713 and parameters: {'alpha': 192021.7359625861, 'l1_ratio': 0.0004692601903957218}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:03,962] Trial 843 finished with value: -0.0010605577384500038 and parameters: {'alpha': 9410866.86253591, 'l1_ratio': 0.0005023115304233405}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:04,482] Trial 844 finished with value: -6.377309989749969 and parameters: {'alpha': 3.537935002920197e-10, 'l1_ratio': 4.113439887237776e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:04,683] Trial 840 finished with value: 0.13359766857885044 and parameters: {'alpha': 24163.94014826676, 'l1_ratio': 1.2057570856573535e-07}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.541e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:09:08,681] Trial 780 finished with value: -7.014545847853967 and parameters: {'alpha': 0.17336038943002732, 'l1_ratio': 1.980143040713331e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:08,890] Trial 847 finished with value: -0.0010605577384500038 and parameters: {'alpha': 46506154.34788727, 'l1_ratio': 0.0001945400758970184}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.928e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.876e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:09:22,970] Trial 799 finished with value: -44.500198200682426 and parameters: {'alpha': 0.0006599023743396247, 'l1_ratio': 1.963329906504371e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:23,141] Trial 849 finished with value: -0.0010605577384500038 and parameters: {'alpha': 978334.8075281854, 'l1_ratio': 0.0009173641028681177}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.881e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.771e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:09:30,636] Trial 802 finished with value: -13.48857226005678 and parameters: {'alpha': 0.01215788332951178, 'l1_ratio': 4.4688126359732964e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:31,046] Trial 851 finished with value: 0.3835334521492379 and parameters: {'alpha': 119876.98491666894, 'l1_ratio': 0.0005838883517970862}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:31,240] Trial 852 finished with value: 0.35568896822551144 and parameters: {'alpha': 74015.36355603194, 'l1_ratio': 0.0003485175606386807}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:33,020] Trial 853 finished with value: 0.37629428068386445 and parameters: {'alpha': 98.28448310769707, 'l1_ratio': 0.0009945936022822605}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:37,283] Trial 845 finished with value: -2.040800719821177 and parameters: {'alpha': 3.7506423917938543, 'l1_ratio': 0.0007731485206505667}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:37,715] Trial 855 finished with value: 0.36647216069470434 and parameters: {'alpha': 439093.2749678235, 'l1_ratio': 1.2161593917864945e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:37,881] Trial 856 finished with value: 0.33598670788462365 and parameters: {'alpha': 88250.38519821395, 'l1_ratio': 0.0013314948522622338}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.376e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.251e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.234e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.564e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.706e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:09:48,065] Trial 823 finished with value: -31.35177711100819 and parameters: {'alpha': 0.0016791959195606226, 'l1_ratio': 0.048824743092149445}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:48,581] Trial 858 finished with value: 0.3322755103618064 and parameters: {'alpha': 3934.8950544458507, 'l1_ratio': 0.004656122343702198}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:09:49,701] Trial 859 finished with value: -0.0011196486591476724 and parameters: {'alpha': 9861.711134698548, 'l1_ratio': 0.00017805193616468912}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.744e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.087e-02, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:04,231] Trial 835 finished with value: -3.7898373813328816 and parameters: {'alpha': 1.1365754142009643, 'l1_ratio': 0.0005256838974850618}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.075e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:04,658] Trial 848 finished with value: -3.472995627807699 and parameters: {'alpha': 1.3090554152983704, 'l1_ratio': 0.0007723999345247029}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:05,055] Trial 862 finished with value: 0.34606226082156355 and parameters: {'alpha': 154373.53433230516, 'l1_ratio': 2.6700874425351865e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:05,570] Trial 861 finished with value: 0.27036536236565234 and parameters: {'alpha': 53233.16404078097, 'l1_ratio': 1.7118477454378808e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:05,827] Trial 864 finished with value: 0.0796919342583166 and parameters: {'alpha': 23869.954554096617, 'l1_ratio': 0.008887630894643225}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:07,207] Trial 865 finished with value: 0.3639732397139172 and parameters: {'alpha': 219103.24774689606, 'l1_ratio': 2.3034067327149549e-10}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:07,424] Trial 836 finished with value: -3.5936531212015854 and parameters: {'alpha': 1.3990804697463939, 'l1_ratio': 4.8156542802645216e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:07,787] Trial 867 finished with value: 0.169516207699088 and parameters: {'alpha': 984319.3257500406, 'l1_ratio': 9.211681109456637e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:08,338] Trial 866 finished with value: -0.11640454612114233 and parameters: {'alpha': 2351.873635869786, 'l1_ratio': 0.0016294080591541628}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:09,394] Trial 868 finished with value: -0.39211876712210914 and parameters: {'alpha': 1155.9004407772563, 'l1_ratio': 0.0014191855752107641}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:11,176] Trial 870 finished with value: -0.03188051324928809 and parameters: {'alpha': 11922.93472415954, 'l1_ratio': 1.6753568741191648e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:11,506] Trial 871 finished with value: -0.0010605577384500038 and parameters: {'alpha': 17839980.482669752, 'l1_ratio': 0.003833804603480471}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:13,571] Trial 846 finished with value: -4.069925325170112 and parameters: {'alpha': 1.0205238762346471, 'l1_ratio': 1.6858571674409497e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.625e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:16,400] Trial 873 finished with value: -6.0216624205350175 and parameters: {'alpha': 3.516579147054755e-07, 'l1_ratio': 0.0025523865742085603}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:17,389] Trial 874 finished with value: 0.29837535979133506 and parameters: {'alpha': 68603.11992118815, 'l1_ratio': 3.76819326355956e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:17,539] Trial 875 finished with value: 0.22097104259932288 and parameters: {'alpha': 27978.850742854374, 'l1_ratio': 0.006131364947052276}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:23,930] Trial 872 finished with value: -5.777028989283949 and parameters: {'alpha': 2.6624372849826776e-05, 'l1_ratio': 0.0029468236270328066}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:24,570] Trial 877 finished with value: 0.03611988391363019 and parameters: {'alpha': 19.615934077101677, 'l1_ratio': 0.3256064146161369}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.018e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:31,209] Trial 850 finished with value: -8.567431987986309 and parameters: {'alpha': 0.05194116424547647, 'l1_ratio': 3.963602897438303e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:31,923] Trial 879 finished with value: -0.10579131587828587 and parameters: {'alpha': 5621.918580980188, 'l1_ratio': 0.0003754244543563023}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:32,071] Trial 880 finished with value: -0.03687480707700815 and parameters: {'alpha': 365598.33076725923, 'l1_ratio': 0.0009065464210899269}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.845e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:34,806] Trial 881 finished with value: -5.206884366545934 and parameters: {'alpha': 1.1558798410498551e-06, 'l1_ratio': 0.0019031579577064907}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:35,735] Trial 882 finished with value: -6.3730720307806035 and parameters: {'alpha': 1.0779051121049912e-07, 'l1_ratio': 0.0204465165759945}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:35,960] Trial 883 finished with value: -0.04146188980338328 and parameters: {'alpha': 56234.67814798143, 'l1_ratio': 0.005086400061047178}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:36,598] Trial 884 finished with value: 0.342845530416373 and parameters: {'alpha': 16927.30543757975, 'l1_ratio': 0.0011240641290692196}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.159e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:38,565] Trial 857 finished with value: -5.168010524526988 and parameters: {'alpha': 0.6025955998053206, 'l1_ratio': 1.3193991774486015e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:39,959] Trial 886 finished with value: -6.3773139405501 and parameters: {'alpha': 2.2076969760697902e-09, 'l1_ratio': 0.030845694429563756}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:40,316] Trial 887 finished with value: -0.0010605577384500038 and parameters: {'alpha': 123802.3065223748, 'l1_ratio': 0.4183622112260346}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:40,496] Trial 888 finished with value: 0.37452681401922344 and parameters: {'alpha': 6474.953411617837, 'l1_ratio': 0.00913012326557032}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.515e-03, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:40,765] Trial 889 finished with value: -0.0010605577384500038 and parameters: {'alpha': 2101321195.4441729, 'l1_ratio': 0.00023050037820510712}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:40,944] Trial 890 finished with value: 0.3307128255716736 and parameters: {'alpha': 33397.6157604136, 'l1_ratio': 0.003910542350798582}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:41,182] Trial 854 finished with value: -1.7165935183441827 and parameters: {'alpha': 5.870439651448298, 'l1_ratio': 3.4763595971528095e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:42,046] Trial 892 finished with value: -6.375843718019625 and parameters: {'alpha': 2.38047132292943e-08, 'l1_ratio': 3.681634486888657e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:43,958] Trial 891 finished with value: 0.3277936274486528 and parameters: {'alpha': 72.12662621315808, 'l1_ratio': 0.0026623921336756083}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:51,088] Trial 878 finished with value: -0.19149925280121474 and parameters: {'alpha': 5611.512589155819, 'l1_ratio': 4.783588213314501e-09}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.842e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:10:56,763] Trial 860 finished with value: -11.409182762842619 and parameters: {'alpha': 0.02221053580675746, 'l1_ratio': 0.0005709344269460733}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:57,114] Trial 896 finished with value: -0.04271626813233276 and parameters: {'alpha': 189640.5358247541, 'l1_ratio': 0.001672652891069516}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:57,499] Trial 897 finished with value: -0.01845424597596775 and parameters: {'alpha': 63011.97735499715, 'l1_ratio': 0.006496219635991537}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:57,860] Trial 898 finished with value: -0.0010605577384500038 and parameters: {'alpha': 4689288.519122934, 'l1_ratio': 0.7020790573144265}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:10:59,636] Trial 895 finished with value: 0.15011892723381193 and parameters: {'alpha': 44.06003524981892, 'l1_ratio': 0.0005680710538988673}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:00,527] Trial 900 finished with value: 0.0800961430845671 and parameters: {'alpha': 16740.879414775896, 'l1_ratio': 5.617282807759912e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:00,765] Trial 901 finished with value: 0.2960305888426556 and parameters: {'alpha': 974067.4024744915, 'l1_ratio': 1.0960296548989209e-05}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.079e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.334e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.277e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.301e-01, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:20,928] Trial 863 finished with value: -23.444177862236888 and parameters: {'alpha': 0.004914827396080172, 'l1_ratio': 0.0017034748944737212}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:28,017] Trial 869 finished with value: -1.2064320213734456 and parameters: {'alpha': 9.394863471076082, 'l1_ratio': 9.035606225837857e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:28,498] Trial 904 finished with value: -6.376956082159654 and parameters: {'alpha': 1.1638421358173756e-08, 'l1_ratio': 0.0012455916580301361}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:29,235] Trial 905 finished with value: -0.44002467853761384 and parameters: {'alpha': 632.1265236381869, 'l1_ratio': 0.0034787316899884024}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.196e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:29,645] Trial 885 finished with value: -39.65677548739121 and parameters: {'alpha': 0.0003290718298615878, 'l1_ratio': 0.00955708368263384}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:30,550] Trial 906 finished with value: 0.24711869899499073 and parameters: {'alpha': 44860.642984456914, 'l1_ratio': 1.1274742559323134e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:31,023] Trial 876 finished with value: -30.538493148569316 and parameters: {'alpha': 0.0039875211979000244, 'l1_ratio': 0.00029491000203625827}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:31,961] Trial 909 finished with value: -0.32920253414197537 and parameters: {'alpha': 1865.1404395550728, 'l1_ratio': 0.0009811036124558578}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:32,365] Trial 910 finished with value: -0.0010605577384500038 and parameters: {'alpha': 440937.13284088025, 'l1_ratio': 0.002417730284547678}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:33,647] Trial 911 finished with value: 0.05649390557144385 and parameters: {'alpha': 13081.377427041987, 'l1_ratio': 0.00012563232722594364}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:34,116] Trial 912 finished with value: -0.0010605577384500038 and parameters: {'alpha': 78700684.42216755, 'l1_ratio': 0.004594956719323457}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:35,090] Trial 913 finished with value: -6.377237098325663 and parameters: {'alpha': 2.6503754091420087e-09, 'l1_ratio': 0.0022424920273172305}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:35,421] Trial 914 finished with value: -0.0010605577384500038 and parameters: {'alpha': 144431.5671776107, 'l1_ratio': 0.02364320636135563}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+00, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:36,077] Trial 915 finished with value: 0.35744201345946125 and parameters: {'alpha': 33038.283113959624, 'l1_ratio': 0.0007871100516439768}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:49,139] Trial 903 finished with value: -14.990934603979035 and parameters: {'alpha': 9.011394950275697e-05, 'l1_ratio': 0.0011062617225226132}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:50,491] Trial 899 finished with value: -29.939545183293962 and parameters: {'alpha': 0.0002091552607904778, 'l1_ratio': 0.0010009235828604328}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:50,744] Trial 918 finished with value: -0.0047890693085415785 and parameters: {'alpha': 86501.98647211544, 'l1_ratio': 0.005764301773704134}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:51,006] Trial 919 finished with value: -0.0010605577384500038 and parameters: {'alpha': 11496.833942412144, 'l1_ratio': 0.09590338048921014}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:51,269] Trial 907 finished with value: -12.846131001478053 and parameters: {'alpha': 7.817011832379962e-05, 'l1_ratio': 0.000858913030659146}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:52,055] Trial 921 finished with value: 0.27737557158798476 and parameters: {'alpha': 3722.0824908411146, 'l1_ratio': 0.00309000262269153}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:53,006] Trial 917 finished with value: -0.020238161518880138 and parameters: {'alpha': 12636.803013966413, 'l1_ratio': 6.545303999925464e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:53,008] Trial 922 finished with value: -6.3777394352650845 and parameters: {'alpha': 7.637859172049414e-10, 'l1_ratio': 0.0004382003623118231}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:53,636] Trial 924 finished with value: 0.3651159740080811 and parameters: {'alpha': 233316.3192984987, 'l1_ratio': 4.132551717303217e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:56,135] Trial 923 finished with value: -4.887766394292062 and parameters: {'alpha': 2.7505937654596913e-06, 'l1_ratio': 0.01602261796808957}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:11:56,688] Trial 894 finished with value: -14.339266071217729 and parameters: {'alpha': 0.010075852090742172, 'l1_ratio': 1.2124998889468692e-09}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:56,951] Trial 925 finished with value: 0.1760138966498895 and parameters: {'alpha': 29696.048303965585, 'l1_ratio': 2.7033210475565595e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:57,077] Trial 927 finished with value: -0.0010605577384500038 and parameters: {'alpha': 31085.151707171863, 'l1_ratio': 0.048561764601659965}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:57,642] Trial 926 finished with value: 0.21663615894419538 and parameters: {'alpha': 34509.14239675974, 'l1_ratio': 2.1045115113712436e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:57,646] Trial 929 finished with value: 0.17269398170479353 and parameters: {'alpha': 93784.39843313489, 'l1_ratio': 0.0019174262324922464}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:58,230] Trial 931 finished with value: 0.335101411368618 and parameters: {'alpha': 2712.424230516438, 'l1_ratio': 0.007820616612107176}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:11:58,584] Trial 932 finished with value: -0.0010605577384500038 and parameters: {'alpha': 314632.0000122184, 'l1_ratio': 0.06830929536792675}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+00, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.568e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:02,820] Trial 902 finished with value: -46.835946716984104 and parameters: {'alpha': 0.0007865287912290363, 'l1_ratio': 0.0012055144074393288}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:03,342] Trial 893 finished with value: 0.22926693163373893 and parameters: {'alpha': 73.12905742872296, 'l1_ratio': 6.218469472549421e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:07,135] Trial 920 finished with value: -0.23437135795603325 and parameters: {'alpha': 3583.4686721334742, 'l1_ratio': 4.8586677807116e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:07,411] Trial 936 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1428540.2215120068, 'l1_ratio': 0.004202463296146884}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:08,202] Trial 937 finished with value: -6.375262154347148 and parameters: {'alpha': 3.2004216864426116e-08, 'l1_ratio': 2.133305217581941e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:08,650] Trial 933 finished with value: -0.15640969518924866 and parameters: {'alpha': 6904.270993296462, 'l1_ratio': 1.0380596589653508e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:08,759] Trial 934 finished with value: -0.04069454896239555 and parameters: {'alpha': 139.71903841761298, 'l1_ratio': 0.0038155570185793917}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:09,068] Trial 940 finished with value: -0.0010605577384500038 and parameters: {'alpha': 89166.4016825834, 'l1_ratio': 0.01145742428283167}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:09,365] Trial 941 finished with value: 0.3565986779908008 and parameters: {'alpha': 15525.989546033434, 'l1_ratio': 0.0020792694077842976}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:14,195] Trial 939 finished with value: 0.12046653458571832 and parameters: {'alpha': 159.32040899702469, 'l1_ratio': 0.002246159547513315}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:14,359] Trial 943 finished with value: -0.0010605577384500038 and parameters: {'alpha': 534805.4543243676, 'l1_ratio': 0.1831102719174236}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:14,953] Trial 944 finished with value: 0.16681107240509552 and parameters: {'alpha': 1213.4845068759223, 'l1_ratio': 0.006307893440562739}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.606e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:17,096] Trial 945 finished with value: -5.463253032644226 and parameters: {'alpha': 6.605252683786521e-07, 'l1_ratio': 2.3464771119525397e-09}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e-02, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:20,028] Trial 930 finished with value: -0.1696104950269077 and parameters: {'alpha': 6416.143699518818, 'l1_ratio': 5.898622564524341e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:20,797] Trial 947 finished with value: 0.3000890220138099 and parameters: {'alpha': 69080.94287279794, 'l1_ratio': 3.2614219375043697e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:21,294] Trial 948 finished with value: 0.27327699910662767 and parameters: {'alpha': 20601.697299618863, 'l1_ratio': 0.0003909379867115608}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:21,570] Trial 949 finished with value: 0.03507004617472561 and parameters: {'alpha': 165288.33896970536, 'l1_ratio': 0.00140617277411315}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:22,536] Trial 950 finished with value: -6.3744131350434055 and parameters: {'alpha': 1.1858861063616437e-07, 'l1_ratio': 1.012471670195516e-08}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.682e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+00, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.114e-03, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+00, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.324e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:35,626] Trial 908 finished with value: -50.66276522048361 and parameters: {'alpha': 0.0012222232402081528, 'l1_ratio': 0.0025550186371939235}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:35,919] Trial 952 finished with value: 0.3684050040874696 and parameters: {'alpha': 56105.98385654916, 'l1_ratio': 0.0006419293295025654}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:37,987] Trial 953 finished with value: -0.06690594180795133 and parameters: {'alpha': 10302.182564317096, 'l1_ratio': 3.546455879359003e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:38,226] Trial 954 finished with value: -0.0010605577384500038 and parameters: {'alpha': 194743.4050513567, 'l1_ratio': 0.03276644147668978}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:38,379] Trial 955 finished with value: -0.0010605577384500038 and parameters: {'alpha': 216703038.9919859, 'l1_ratio': 0.0035804605413810482}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:38,878] Trial 956 finished with value: -6.37635645670523 and parameters: {'alpha': 1.782055474016915e-08, 'l1_ratio': 9.215666948989396e-05}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:39,328] Trial 957 finished with value: 0.23847462407425332 and parameters: {'alpha': 28501.141355024964, 'l1_ratio': 0.00015277643707115341}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.540e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:39,566] Trial 958 finished with value: -0.0010605577384500038 and parameters: {'alpha': 12154574.329734258, 'l1_ratio': 0.018747290442641278}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:40,340] Trial 959 finished with value: -6.377499955408792 and parameters: {'alpha': 3.659004223092172e-09, 'l1_ratio': 0.0002742613791029146}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:40,612] Trial 960 finished with value: -0.0010605577384500038 and parameters: {'alpha': 3863500.657938497, 'l1_ratio': 0.00877033627800658}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.608e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:42,415] Trial 961 finished with value: -0.44655540417473766 and parameters: {'alpha': 810.4552111691636, 'l1_ratio': 0.0015886115408402944}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:43,195] Trial 962 finished with value: 0.29911585456043843 and parameters: {'alpha': 67998.52325210335, 'l1_ratio': 5.082896797160382e-06}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e-02, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:43,612] Trial 963 finished with value: -0.0010605577384500038 and parameters: {'alpha': 727910.5341296906, 'l1_ratio': 0.00540348489186453}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:44,322] Trial 916 finished with value: 0.35203804913915393 and parameters: {'alpha': 211.36719478746565, 'l1_ratio': 5.486764651974658e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:44,900] Trial 965 finished with value: 0.3064569143978141 and parameters: {'alpha': 15331.938864234553, 'l1_ratio': 0.0007901120995824707}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:45,191] Trial 966 finished with value: -0.02423989243897488 and parameters: {'alpha': 132158.55126236612, 'l1_ratio': 0.002896495580221575}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:45,572] Trial 967 finished with value: 0.13991217395815403 and parameters: {'alpha': 3904.7142609699767, 'l1_ratio': 0.0016580840335140487}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:45,944] Trial 968 finished with value: 0.34443480268978804 and parameters: {'alpha': 33689.29602378708, 'l1_ratio': 0.00052479814122155}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:46,624] Trial 969 finished with value: -6.376744033320048 and parameters: {'alpha': 8.328329131611868e-09, 'l1_ratio': 0.011979692921961558}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:47,089] Trial 970 finished with value: 0.28232071698266575 and parameters: {'alpha': 8800.75954830352, 'l1_ratio': 0.001263635795293546}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:47,342] Trial 971 finished with value: -0.0010605577384500038 and parameters: {'alpha': 258596.96638175452, 'l1_ratio': 0.004930470851635843}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:49,993] Trial 964 finished with value: 0.04965265411125297 and parameters: {'alpha': 16802.705618631004, 'l1_ratio': 2.1680047408979183e-08}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.927e-03, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:50,861] Trial 972 finished with value: -4.92408576604559 and parameters: {'alpha': 2.8396731452381382e-06, 'l1_ratio': 0.0026961315523435876}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:51,099] Trial 973 finished with value: -6.424851301634664 and parameters: {'alpha': 1.2075339994653405e-07, 'l1_ratio': 0.002743567973176054}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:51,238] Trial 974 finished with value: -0.0010605577384500038 and parameters: {'alpha': 62574.66659037394, 'l1_ratio': 0.08776164652381152}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+00, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:54,084] Trial 975 finished with value: 0.2883635135531735 and parameters: {'alpha': 62334.32948632364, 'l1_ratio': 2.9890440514772642e-09}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.140e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:12:58,569] Trial 935 finished with value: -9.777670674142291 and parameters: {'alpha': 0.033704699762009724, 'l1_ratio': 0.00422100174096747}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:12:59,827] Trial 978 finished with value: -0.28325727184415395 and parameters: {'alpha': 2471.955077334955, 'l1_ratio': 0.0007506619823540703}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:00,158] Trial 979 finished with value: -0.0010605577384500038 and parameters: {'alpha': 24552.07610699845, 'l1_ratio': 0.3381080065950833}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:00,850] Trial 980 finished with value: 0.36656995209666215 and parameters: {'alpha': 437288.3213258245, 'l1_ratio': 2.611078856985001e-10}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.486e-02, tolerance: 1.895e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e-01, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:02,410] Trial 928 finished with value: -9.246681517600162 and parameters: {'alpha': 0.04081713909818583, 'l1_ratio': 1.0293238287667609e-07}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:02,697] Trial 982 finished with value: 0.005043392892111124 and parameters: {'alpha': 439871984.20027, 'l1_ratio': 1.0577948919812965e-09}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e-02, tolerance: 1.854e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:08,243] Trial 942 finished with value: -38.91093698806498 and parameters: {'alpha': 0.0025697241397990454, 'l1_ratio': 0.006620086012033557}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:08,540] Trial 984 finished with value: -0.0010605577384500038 and parameters: {'alpha': 1735124.8994086348, 'l1_ratio': 0.0015952627414913885}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:09,389] Trial 985 finished with value: -0.0628038211004505 and parameters: {'alpha': 7415.924600974228, 'l1_ratio': 0.00024795215459976687}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:09,543] Trial 986 finished with value: -0.0010605577384500038 and parameters: {'alpha': 42631.39481304772, 'l1_ratio': 0.019905349164381282}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:09,781] Trial 987 finished with value: 0.31561065485372125 and parameters: {'alpha': 104626.04003662229, 'l1_ratio': 0.0011948644810672677}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:10,214] Trial 988 finished with value: 0.19430409556160458 and parameters: {'alpha': 1085.0035454567549, 'l1_ratio': 0.007980738367424715}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:10,471] Trial 989 finished with value: 0.34977266107119404 and parameters: {'alpha': 157515.18491087735, 'l1_ratio': 6.032598534702437e-06}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:14,395] Trial 990 finished with value: -5.214948144162375 and parameters: {'alpha': 1.1351337676440317e-06, 'l1_ratio': 0.002052611704850636}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:14,970] Trial 991 finished with value: 0.23365431499786357 and parameters: {'alpha': 13088.328275131975, 'l1_ratio': 0.0005331578944951906}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:15,251] Trial 992 finished with value: -0.00016225778205743632 and parameters: {'alpha': 1565027515.0527627, 'l1_ratio': 9.965414391477903e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:15,525] Trial 993 finished with value: -0.0010605577384500038 and parameters: {'alpha': 136016360.75959456, 'l1_ratio': 0.0038925816908860337}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+00, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:20,450] Trial 938 finished with value: 0.33122760167518533 and parameters: {'alpha': 253.23338887630294, 'l1_ratio': 3.1959270539624953e-10}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:21,323] Trial 995 finished with value: 0.056227334958422616 and parameters: {'alpha': 4606.9290702365815, 'l1_ratio': 0.0010729023578895424}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:22,629] Trial 946 finished with value: -4.882101448705407 and parameters: {'alpha': 0.6594393565723491, 'l1_ratio': 0.0002509058664244195}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:23,040] Trial 997 finished with value: -0.0010605577384500038 and parameters: {'alpha': 26880.712120466185, 'l1_ratio': 0.4886999627376041}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e-01, tolerance: 1.854e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:24,436] Trial 996 finished with value: -5.925717008372087 and parameters: {'alpha': 4.088661473956734e-07, 'l1_ratio': 0.002078173778111725}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:24,841] Trial 999 finished with value: -0.0010605577384500038 and parameters: {'alpha': 408935.80215150915, 'l1_ratio': 0.011053745142060045}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:25,665] Trial 998 finished with value: -5.973403195385696 and parameters: {'alpha': 3.7999356663340464e-07, 'l1_ratio': 1.631855812974364e-05}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.641e-02, tolerance: 1.606e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:29,638] Trial 994 finished with value: -6.419617907504 and parameters: {'alpha': 3.4025649631919785e-05, 'l1_ratio': 0.0009070954564265574}. Best is trial 380 with value: 0.3912637017739599.\n",
      "[I 2023-06-16 18:13:31,512] Trial 977 finished with value: -0.21309265734085128 and parameters: {'alpha': 2158.9431597051316, 'l1_ratio': 1.0915921295298821e-07}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.219e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:32,051] Trial 951 finished with value: -8.642957785217094 and parameters: {'alpha': 0.05111277175057156, 'l1_ratio': 0.0006358050510032768}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.508e-03, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.577e-02, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:41,966] Trial 976 finished with value: -8.63128009845572 and parameters: {'alpha': 0.05937991603331984, 'l1_ratio': 0.00649832798535536}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.215e-01, tolerance: 1.606e-03\n",
      "\n",
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.827e-03, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:13:49,878] Trial 983 finished with value: -42.51884277542003 and parameters: {'alpha': 0.00043941409204865554, 'l1_ratio': 0.008373334697137337}. Best is trial 380 with value: 0.3912637017739599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/mambaforge/envs/qsar/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.656e-01, tolerance: 1.895e-03\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-06-16 18:14:01,590] Trial 981 finished with value: -1.7601677907582167 and parameters: {'alpha': 5.7123619655723115, 'l1_ratio': 1.0324709343627239e-08}. Best is trial 380 with value: 0.3912637017739599.\n",
      "0.3912637017739599 {'alpha': 69592.80870099114, 'l1_ratio': 0.000972891439395148}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-10, 1e10, log=True)\n",
    "\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 1e-10, 1, log=True)\n",
    "\n",
    "\n",
    "    clf = ElasticNet(max_iter=100000, alpha=alpha, l1_ratio=l1_ratio, random_state=0)\n",
    "\n",
    "    # n_ft = trial.suggest_int('n_ft', 1, 10, log=True)\n",
    "    # clf = RFE(Ridge(max_iter=100000, alpha=alpha, solver=solver), n_features_to_select=n_ft)\n",
    "\n",
    "    estimator = utils.Utils(neutral_train)\n",
    "    return estimator.cross_value_score(clf)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1, show_progress_bar=True)\n",
    "trial = study.best_trial\n",
    "print(trial.value, trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T22:14:01.711253149Z",
     "start_time": "2023-06-16T21:52:39.186109482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      "\tR2\t\t\t\t:\t 0.45644200981624605 \n",
      "\tCV train\t\t:\t 0.31343131113600475 \n",
      "\tCustom CV train\t:\t 0.3912637017739599 \n",
      "\tQ2\t\t\t\t:\t 0.07087603099376494\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          0.04185889286312716,
          -4.556141085210168,
          0.13304626685445076,
          -0.5363355045738799,
          -6.377504418091352,
          -0.0010605577384500038,
          0.005525064164305686,
          -0.0010605577384500038,
          0.001811440483309057,
          -6.8001739412434E-4,
          -47.7799506531394,
          -0.0010605577384500038,
          -7.05237384750848,
          -4.943861883637893,
          -28.867062176205362,
          -6.37670327168661,
          0.34733821447233987,
          0.29833901251330636,
          -0.3869641883759509,
          -0.1672768597513836,
          -0.1531371814969191,
          0.3680755838201387,
          -3.6359617206807724,
          -0.28003087700164947,
          -2.9647179020028624,
          -2.2941343178001117,
          -6.388418192872282,
          -13.313498850449138,
          -2.230797338756729,
          -4.582994963374512,
          -0.0010605577384500038,
          0.3908832395967129,
          0.3658143794300082,
          0.3467178921411273,
          0.288763879989727,
          0.3670076115350656,
          0.23199617155396005,
          -0.0010605577384500038,
          0.3577379763114123,
          0.09692673582930245,
          -0.0010605577384500038,
          -0.038389114641729706,
          0.34831932617976885,
          0.3260085302030584,
          -0.0010605577384500038,
          -0.018974292403799553,
          0.18231821384449187,
          0.29523684643277764,
          0.35431601950369895,
          0.37776970439194246,
          0.2678834315470247,
          0.042471059771781894,
          -0.05508669816306636,
          0.36888696671365306,
          0.2723437589816825,
          -0.1950144908199293,
          0.05740574481616367,
          -0.3991678134603547,
          -0.7227819766399415,
          -0.823907685501794,
          -0.5036072850319684,
          -0.8090393640596804,
          -0.11518836904202583,
          -0.3010265279789981,
          -0.5062409973920476,
          0.3535323697115595,
          -0.99343224327207,
          -0.1045350422466929,
          -0.4183101585050731,
          -0.285128456474994,
          0.3822407393134572,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.026658589695754742,
          -0.044208983106783006,
          -0.8198661235186157,
          -0.029189222159157868,
          0.381572671507201,
          0.3477962754609981,
          -0.004969353986447341,
          -0.026651632353653382,
          -1.2335355099534155,
          0.34080204859169383,
          -0.7391836454695707,
          0.02298819950806985,
          -2.3058018169045007,
          -0.14481321917325152,
          0.13068527848200315,
          0.3512225022663323,
          0.35203064441057375,
          0.3559810191725759,
          0.3625855944780787,
          -0.07217422904168869,
          -0.44443810725625693,
          0.018694914887517993,
          0.3221944029746541,
          0.33947738340922007,
          0.21260537226309803,
          0.3652722220298327,
          0.3550035178043038,
          -0.039517366702175614,
          -0.0010605577384500038,
          0.37474724379759744,
          0.3704373992139353,
          0.13932838641657563,
          0.2511817875374465,
          0.3287736007031428,
          -0.0010605577384500038,
          0.3481441077308524,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.3783518492640771,
          0.31374261085568006,
          0.21228341014974084,
          -0.17519887927090583,
          0.2804745490020909,
          -0.5048988154050876,
          -0.47163044432495105,
          0.35839077804444514,
          -0.14350445948779378,
          -0.4378101463755378,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.30394175946616264,
          -0.0010605577384500038,
          -0.3246354726256288,
          0.35283101687987733,
          -0.05615957710785413,
          0.36794108153143656,
          0.08207235493431331,
          0.3118903859670107,
          0.2602572442895932,
          -0.0010605577384500038,
          0.33851578256638154,
          -0.0010605577384500038,
          0.3456439384026126,
          0.2730060598405529,
          -0.1522378663928308,
          0.005556555584037004,
          -0.03873383997661065,
          0.351995099499227,
          0.36928367884628077,
          0.33513466861540503,
          -0.0010605577384500038,
          0.3667724152208821,
          0.355532710407048,
          0.30362271118233525,
          -0.037107573725934984,
          0.3247610205631729,
          0.34588065171969645,
          0.04885648884575574,
          0.18134677358960452,
          0.25913671558486734,
          0.3657321705592671,
          -0.37534005564278944,
          -2.499097176321239,
          -0.030994540740407046,
          0.2598310953290473,
          0.3538209999098738,
          -2.286440412715395,
          -1.8252612699741215,
          0.3501653432404178,
          -0.017202416998919594,
          -2.800691583690175,
          -2.2459959812924986,
          -1.9160236423297774,
          0.3582790556449174,
          -1.7402102500550192,
          0.30124982096136704,
          0.20301131004074024,
          0.14065276314498584,
          -0.0010605577384500038,
          -0.2894078697840549,
          -2.8650016245128156,
          -0.3492173021531805,
          0.3500412591431381,
          0.3048540745735115,
          0.3818461932174751,
          0.3896284409618738,
          0.3710697701596491,
          -0.017820243431351652,
          0.37175356318769315,
          0.3705285577316572,
          0.37682822015114387,
          0.34532822898144727,
          0.37480191800126444,
          0.3806475105830532,
          0.3682978154453476,
          0.3310346434098887,
          0.3522416920623915,
          0.33216505887911424,
          0.3873802162918917,
          0.36902685081009734,
          0.3575179303671192,
          0.38411576903085326,
          0.38649809322316253,
          0.3426701338285076,
          0.3364528002325194,
          0.384515265816337,
          0.3701833700500035,
          0.36037734448554243,
          0.10609570623436833,
          0.3516965079984788,
          -0.020503514590604177,
          0.3634856967175586,
          0.07243716670703293,
          0.29821080032460895,
          -0.0010605577384500038,
          0.3487129579288139,
          0.3849679867732455,
          -0.04718108966268427,
          0.005770129346022945,
          0.36315281115044307,
          0.3072308141589738,
          -0.0010605577384500038,
          0.3394960987014462,
          0.38785195139828804,
          0.016420847223247992,
          0.38022693881944525,
          0.14278732456041587,
          0.3834241019800115,
          -0.04840609472088445,
          0.3665814618311129,
          0.38291946232542223,
          -0.04284621608113456,
          -0.0010605577384500038,
          0.36742075593809886,
          0.384787601956976,
          0.35427686913525186,
          -0.025717535838595967,
          -0.0012824841160302691,
          0.3889306567982564,
          0.3770858538601182,
          -0.1661683313187793,
          -0.06431999676784868,
          0.20362070917336708,
          -0.0010605577384500038,
          0.3885228932754115,
          0.38873699062097117,
          0.3660341269275107,
          0.22574606093041474,
          0.3792824836473537,
          -0.04819942487239789,
          0.11851686785571802,
          0.36596004389596337,
          0.38541739975647277,
          0.16097296016867332,
          -0.01478066822094252,
          0.3763257791289647,
          0.38621504106152355,
          0.344778684713102,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.355861394994174,
          -0.34746217922804384,
          0.34197805757274635,
          -4.100987952529528,
          -0.0010605577384500038,
          -0.2053453657071758,
          -0.19325270272731943,
          -6.01040915188282,
          -7.970776558611518,
          0.20409253318511497,
          0.2577633567556522,
          0.3874614290903196,
          -0.0010605577384500038,
          -0.0326297934295254,
          -0.04133598910978631,
          0.35066338031892,
          0.35214853679869246,
          -0.0010605577384500038,
          0.37448836036322136,
          -6.377400545556277,
          -6.3755815493328445,
          -8.043546583415134,
          -0.5055205991387095,
          -0.0010605577384500038,
          0.08430028757320522,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.3576034459842808,
          -7.375013253939475,
          -0.0010605577384500038,
          0.3627067438529363,
          -25.303981180367114,
          -0.3034378935221617,
          0.3904685236846641,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.0010203810292667519,
          -0.0010605577384500038,
          0.3831699078910157,
          0.36889472259404965,
          -22.340092348098327,
          -0.0010605577384500038,
          -0.0013626400293860197,
          -48.77249753961546,
          0.38861872724490293,
          0.38561504854450196,
          -0.0010605577384500038,
          0.04034784646931381,
          -50.26206606618207,
          0.31516146991067073,
          0.1904020900530455,
          -7.970045579219395E-4,
          -0.0010605577384500038,
          0.37474518591159,
          -0.013030628985144102,
          0.2881379069351448,
          0.27750521142620105,
          -34.55337075395565,
          -15.890115061993466,
          0.20942435690081504,
          -8.230705894275287,
          -0.22190995256450408,
          -0.23398644327032214,
          -0.23259689970028272,
          -0.0010605577384500038,
          -0.23448612613681627,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.33759410587523786,
          -0.011933835866239936,
          0.2762257304103604,
          -0.0010605577384500038,
          0.3761371592255241,
          0.38919338945536225,
          0.22351219153487567,
          0.04335384711247777,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.30524868737990707,
          0.3103384487633779,
          0.31212901736861737,
          0.21584118296492927,
          -0.011358494375293682,
          0.36513391705557613,
          -0.29952632941317253,
          0.15155187650436164,
          0.2971917355457566,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -7.508823834184719E-4,
          -0.0010605577384500038,
          0.337672238277489,
          -0.08147871572673264,
          -0.0010605577384500038,
          0.30057832419013736,
          0.3734987440536484,
          0.3597694711620189,
          -0.32850253893878484,
          -0.013802109427328105,
          0.3523411149317821,
          0.38062831401006564,
          0.3473260388747805,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.35063995279398313,
          0.3499739449016694,
          0.31862633377568855,
          -0.0010605577384500038,
          -10.784017941215117,
          0.3337760469627412,
          0.019963138290010136,
          -0.003772352940814757,
          0.3162221127559418,
          0.3526559177648407,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -5.056631316623989,
          0.34008497254332565,
          -0.5535640781238206,
          -5.585929815255792,
          0.37900367111439565,
          0.37706200795612455,
          -0.0010605577384500038,
          -13.81655913333449,
          0.38876309436368667,
          -3.8212757979665497,
          0.3912637017739599,
          0.3629957078185064,
          0.3749351792094292,
          -0.0010605577384500038,
          0.38029378704944455,
          0.11325039881654216,
          0.3086345813903631,
          0.25286962286660136,
          0.17194834394573122,
          0.07327538901918906,
          -0.4934313864490952,
          0.1258617093818644,
          -10.735384366667894,
          -3.948189418635607,
          -0.0010605577384500038,
          -0.026071758595019905,
          -0.04669117601043423,
          -9.575811988920657,
          -0.2022361340533627,
          0.35802109019840916,
          0.04021080687445455,
          -0.0010605577384500038,
          0.2009788402383115,
          0.006608051677226556,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.3102952565082843,
          0.34038587288973415,
          0.3424386402093959,
          0.10617088853352707,
          0.02188223875367849,
          0.2944674000976273,
          0.3706414532158156,
          0.3568229346994201,
          0.3429416635322493,
          -0.24931180784395243,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.25046499032896524,
          -0.1618109015629847,
          -0.7763383883520867,
          0.3620594480726215,
          0.24123463601495176,
          -0.031254654193242616,
          0.3671577492503924,
          0.3393868406610609,
          -0.0010605577384500038,
          -0.034568609883756686,
          -0.0010605577384500038,
          0.3816626884890576,
          0.3263331143951294,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.3869463842101577,
          0.3827908271654027,
          -0.0010605577384500038,
          0.3094155052224754,
          0.37767302485021553,
          -0.041631419940999836,
          -0.1759259953025021,
          -0.0010605577384500038,
          -0.033476492330456055,
          0.12125757216777296,
          -0.0010605577384500038,
          0.380601982726808,
          0.2907164079740137,
          -6.1781323515107225,
          0.24463644127461406,
          -8.691617418363492,
          0.23526128581525538,
          0.23378077767106234,
          0.35801638734189495,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -3.093794304905655,
          0.3065938999539102,
          -0.03706486435467141,
          -6.464215996515261,
          0.3484974440278738,
          0.3802094593032089,
          0.23948688919499994,
          0.3670601186655892,
          -4.806806845993062,
          -0.0010605577384500038,
          -5.005889842187646,
          0.3741492877538322,
          -6.377442060754623,
          0.2881144207105898,
          -0.03761853802858883,
          -6.376867149270265,
          -39.4243500757115,
          -0.4394415774788152,
          -0.0010605577384500038,
          0.23144377541751662,
          -0.0010605577384500038,
          0.14510767743716968,
          0.029426769902694622,
          0.3899241731258676,
          0.3375102927705711,
          -32.370924596677234,
          0.27852817185699186,
          0.28747224812876854,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -3.468551911441933,
          0.18412870663140388,
          0.37745901682276645,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.11387729787649133,
          0.34703785362389455,
          0.3866879050474894,
          -51.74835880780047,
          0.3818529336269009,
          0.38156380977596144,
          0.12720144428797733,
          0.3856731088534315,
          -0.23698177097402987,
          0.347588128447053,
          0.3134113731827913,
          -3.9785182940168053,
          -0.0010605577384500038,
          -44.72986456713179,
          0.3434546114611044,
          -0.013375232862853767,
          -5.0271162747482725,
          -0.04409245140630225,
          -6.377389040383408,
          -0.0010605577384500038,
          -6.4575275466560935,
          0.32767087481070767,
          -9.097060362016999E-4,
          0.3476898041112938,
          0.3726586845181222,
          -0.11067718853461221,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -18.33363347337298,
          -5.3509196550435405,
          0.3137294103851825,
          -0.0010605577384500038,
          0.35693391352026727,
          -4.616581262944586,
          -0.0010605577384500038,
          0.3836811243672429,
          -14.579824782070293,
          0.34516101401351784,
          -0.0010605577384500038,
          0.3854352921489593,
          -15.288422570514998,
          -0.0010605577384500038,
          -8.639500886123605,
          0.3853564725653997,
          -49.751203222221655,
          0.344264516661934,
          -0.0010605577384500038,
          0.3764886888433961,
          -17.327707009681696,
          0.005527790696925883,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -1.3830234712819762,
          0.21422125313269413,
          -17.155055616677274,
          0.34196549306158536,
          0.3122000410434011,
          0.33279410895938544,
          -1.3952125650285414,
          0.022675151575102137,
          -0.0010605577384500038,
          0.12876131990082917,
          0.10611200032559227,
          -0.0010605577384500038,
          0.3130859443848873,
          0.22550710475227734,
          -6.374356103902174,
          -0.1485825145208591,
          -6.375660598344574,
          -0.10972828945053832,
          -5.351409477137485,
          -0.13463344299045077,
          -0.002475163612169151,
          -7.2827965082143855,
          0.3824729610644145,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.10648866807588102,
          0.15411671639313787,
          -0.1784051931355852,
          -6.377752329832946,
          0.35411932008562624,
          -0.36428299316963997,
          0.37730818045533987,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.369900921223319,
          0.2866745026603408,
          -0.0010605577384500038,
          -4.645541408055542,
          0.28931297698319597,
          -0.0010605577384500038,
          0.06057854915258343,
          0.006272838523699901,
          -4.705745158741586,
          -8.248833181166981E-4,
          0.32813700617669767,
          -6.803873399650838,
          -0.6255092734363117,
          0.38225203839651706,
          -0.3183042839318394,
          -3.666273012296252,
          -0.16240991208550504,
          -7.004517680228437,
          0.30372791582363984,
          -8.681618859743883,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.007199985274894886,
          0.35616863842838015,
          0.30777640490968083,
          -0.02993833144455671,
          -5.65918558011136,
          -8.213744298127487,
          0.34289511999740013,
          -0.0010605577384500038,
          0.008240343110919812,
          -0.002041526551683881,
          -0.0010605577384500038,
          -7.482531049428136,
          -0.0010605577384500038,
          -0.05035018878415184,
          0.3788909601234725,
          -3.5157931061512357,
          0.11961436929905944,
          -0.0010605577384500038,
          -0.4871071845655925,
          -6.377658081313444,
          -7.613269763294683E-4,
          -8.151408831518728,
          0.1123447767797714,
          -4.736094839551445,
          -4.981412239095385,
          0.2179339867990113,
          0.32120295227073037,
          -0.02113556886385637,
          0.3856968310926175,
          0.3142389279748148,
          0.35593079531998323,
          -0.4718251407176765,
          0.08185891631578994,
          2.685218694552516E-4,
          -0.0010605577384500038,
          -7.12952406956268,
          0.38924954820272434,
          -0.022204825672430872,
          0.36060886162323513,
          0.3401860556851229,
          -0.0010605577384500038,
          -6.376966971159752,
          0.2553191910932765,
          0.3780618997719804,
          0.3540297292848086,
          -4.974283471554158,
          -0.0010605577384500038,
          0.3629973654187089,
          0.2640957954477175,
          0.29430661774683453,
          0.15874070252868236,
          -0.0010605577384500038,
          0.3624802542934541,
          -15.049399107482172,
          0.3609344601438474,
          0.034565362204306026,
          -0.0010605577384500038,
          -6.374074176992734,
          -0.4063145461043232,
          0.33147421176550623,
          -32.40704874397935,
          0.3760485783868223,
          0.27669994922120406,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.3664470449559747,
          -0.3305701847142551,
          -0.10721608636005404,
          0.02363096268494173,
          -0.03430460229600726,
          0.3701004591340455,
          0.26138744466105435,
          -0.012361863838674029,
          0.21659988815360462,
          -0.0010605577384500038,
          0.33050148154117576,
          0.3764962441638036,
          -6.377166960043011,
          0.10682360585033306,
          0.18887365198628667,
          0.3631999505767235,
          -6.376346696807017,
          -0.16715789463864636,
          0.23621001308292291,
          -4.946830879378721,
          0.3598447797352931,
          0.24682464806978108,
          -1.3965515913916828,
          -4.646896795456025,
          -4.504583200079261,
          0.34002564125968743,
          -4.59132850540241,
          0.35202702927174506,
          -0.3534714076529421,
          -27.507693556800383,
          0.3632358696111082,
          -0.0010605577384500038,
          0.13078602310511067,
          -48.75937636747312,
          -0.0010605577384500038,
          -3.0858006528214137,
          -0.0010605577384500038,
          0.3386323795011429,
          -6.370936481809964,
          -6.377308018275457,
          -0.23826746694930437,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.18483309557703728,
          -17.185465062349948,
          0.2912902363994648,
          0.2945513497746695,
          0.026784699551855733,
          -0.0010605577384500038,
          -6.377396361331781,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -6.377734370510967,
          -0.0010605577384500038,
          -0.4358553042966272,
          0.3569620525552184,
          -38.0741440427671,
          -8.186405807726523,
          0.3368667231503821,
          -2.91340287303545,
          -0.0010605577384500038,
          -0.03885364891893698,
          -1.0759731522283411,
          0.31038223846719093,
          -12.00535958884469,
          -24.0236308855437,
          0.004680134777292011,
          0.3693973653117101,
          -0.0010605577384500038,
          -27.35188523122657,
          -0.28937493448224516,
          -0.36705476142739796,
          -0.11937684304356815,
          0.25497498089562104,
          0.3263863071224283,
          0.2487280877411703,
          -39.5728996494445,
          0.3463691086637667,
          -0.0010605577384500038,
          0.36861964257515556,
          0.35705476675444964,
          0.24327776492300077,
          -6.977136317480416,
          0.32256363456967313,
          -6.351712469423592,
          -0.0010605577384500038,
          0.3261123896574048,
          -0.0010605577384500038,
          0.25073249952472965,
          -0.0010605577384500038,
          -6.465510173957438,
          0.03669641945798593,
          0.22907628252660847,
          -0.10030161884355467,
          -0.0010605577384500038,
          0.20955801093712648,
          0.14064518317627275,
          -0.0010605577384500038,
          -6.954659306529162,
          -0.0010605577384500038,
          0.25785594470304335,
          -13.584997217256081,
          -0.034322995193036464,
          0.3755108927677638,
          -0.17195989458990166,
          -0.0010605577384500038,
          0.34652599150016666,
          -6.377210683799779,
          0.2652036584961229,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -7.011711346629762,
          -7.038273234484219,
          0.35605098391725193,
          0.34964872291192844,
          -7.014545847853967,
          -0.0010605577384500038,
          0.21524802653432204,
          0.15155934282714842,
          -5.064044311730996,
          -16.274068653950266,
          -6.374825300912436,
          -6.377544050608911,
          -6.377385803061429,
          -0.024556109506437718,
          -0.1188541454277879,
          0.19793969428155167,
          0.2947184199624053,
          0.36622311867458274,
          0.2350075643702769,
          -4.850779682516535,
          0.340568658343509,
          0.07404445549496556,
          0.13917581795749326,
          -44.500198200682426,
          0.33092392731522596,
          -0.0010605577384500038,
          -13.48857226005678,
          -0.08443733764903454,
          -6.036493276280838,
          0.36964224834762416,
          0.2543882384680895,
          0.3643905038786334,
          0.33871385716138086,
          0.356291087634362,
          0.3852121951440221,
          -0.3284007662547506,
          -0.0010605577384500038,
          -1.5570934990805085E-4,
          4.2151545205774504E-4,
          -5.055929170405026,
          -0.24617853038085358,
          -0.026915395137569798,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -5.14781314546107,
          0.36272415025919724,
          -0.01168038023754033,
          -31.35177711100819,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.0010605577384500038,
          0.08860469761446743,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -0.0014366308938499699,
          0.3837171790145271,
          -0.0010605577384500038,
          0.37490007790772706,
          0.3842336884047411,
          -3.7898373813328816,
          -3.5936531212015854,
          0.07828316670354311,
          0.04175042935618881,
          -0.0010605577384500038,
          0.13359766857885044,
          0.3889910629331639,
          0.3439877804188713,
          -0.0010605577384500038,
          -6.377309989749969,
          -2.040800719821177,
          -4.069925325170112,
          -0.0010605577384500038,
          -3.472995627807699,
          -0.0010605577384500038,
          -8.567431987986309,
          0.3835334521492379,
          0.35568896822551144,
          0.37629428068386445,
          -1.7165935183441827,
          0.36647216069470434,
          0.33598670788462365,
          -5.168010524526988,
          0.3322755103618064,
          -0.0011196486591476724,
          -11.409182762842619,
          0.27036536236565234,
          0.34606226082156355,
          -23.444177862236888,
          0.0796919342583166,
          0.3639732397139172,
          -0.11640454612114233,
          0.169516207699088,
          -0.39211876712210914,
          -1.2064320213734456,
          -0.03188051324928809,
          -0.0010605577384500038,
          -5.777028989283949,
          -6.0216624205350175,
          0.29837535979133506,
          0.22097104259932288,
          -30.538493148569316,
          0.03611988391363019,
          -0.19149925280121474,
          -0.10579131587828587,
          -0.03687480707700815,
          -5.206884366545934,
          -6.3730720307806035,
          -0.04146188980338328,
          0.342845530416373,
          -39.65677548739121,
          -6.3773139405501,
          -0.0010605577384500038,
          0.37452681401922344,
          -0.0010605577384500038,
          0.3307128255716736,
          0.3277936274486528,
          -6.375843718019625,
          0.22926693163373893,
          -14.339266071217729,
          0.15011892723381193,
          -0.04271626813233276,
          -0.01845424597596775,
          -0.0010605577384500038,
          -29.939545183293962,
          0.0800961430845671,
          0.2960305888426556,
          -46.835946716984104,
          -14.990934603979035,
          -6.376956082159654,
          -0.44002467853761384,
          0.24711869899499073,
          -12.846131001478053,
          -50.66276522048361,
          -0.32920253414197537,
          -0.0010605577384500038,
          0.05649390557144385,
          -0.0010605577384500038,
          -6.377237098325663,
          -0.0010605577384500038,
          0.35744201345946125,
          0.35203804913915393,
          -0.020238161518880138,
          -0.0047890693085415785,
          -0.0010605577384500038,
          -0.23437135795603325,
          0.27737557158798476,
          -6.3777394352650845,
          -4.887766394292062,
          0.3651159740080811,
          0.1760138966498895,
          0.21663615894419538,
          -0.0010605577384500038,
          -9.246681517600162,
          0.17269398170479353,
          -0.1696104950269077,
          0.335101411368618,
          -0.0010605577384500038,
          -0.15640969518924866,
          -0.04069454896239555,
          -9.777670674142291,
          -0.0010605577384500038,
          -6.375262154347148,
          0.33122760167518533,
          0.12046653458571832,
          -0.0010605577384500038,
          0.3565986779908008,
          -38.91093698806498,
          -0.0010605577384500038,
          0.16681107240509552,
          -5.463253032644226,
          -4.882101448705407,
          0.3000890220138099,
          0.27327699910662767,
          0.03507004617472561,
          -6.3744131350434055,
          -8.642957785217094,
          0.3684050040874696,
          -0.06690594180795133,
          -0.0010605577384500038,
          -0.0010605577384500038,
          -6.37635645670523,
          0.23847462407425332,
          -0.0010605577384500038,
          -6.377499955408792,
          -0.0010605577384500038,
          -0.44655540417473766,
          0.29911585456043843,
          -0.0010605577384500038,
          0.04965265411125297,
          0.3064569143978141,
          -0.02423989243897488,
          0.13991217395815403,
          0.34443480268978804,
          -6.376744033320048,
          0.28232071698266575,
          -0.0010605577384500038,
          -4.92408576604559,
          -6.424851301634664,
          -0.0010605577384500038,
          0.2883635135531735,
          -8.63128009845572,
          -0.21309265734085128,
          -0.28325727184415395,
          -0.0010605577384500038,
          0.36656995209666215,
          -1.7601677907582167,
          0.005043392892111124,
          -42.51884277542003,
          -0.0010605577384500038,
          -0.0628038211004505,
          -0.0010605577384500038,
          0.31561065485372125,
          0.19430409556160458,
          0.34977266107119404,
          -5.214948144162375,
          0.23365431499786357,
          -1.6225778205743632E-4,
          -0.0010605577384500038,
          -6.419617907504,
          0.056227334958422616,
          -5.925717008372087,
          -0.0010605577384500038,
          -5.973403195385696,
          -0.0010605577384500038
         ],
         "type": "scatter"
        },
        {
         "name": "Best Value",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          0.04185889286312716,
          0.04185889286312716,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.13304626685445076,
          0.34733821447233987,
          0.34733821447233987,
          0.34733821447233987,
          0.34733821447233987,
          0.34733821447233987,
          0.3680755838201387,
          0.3680755838201387,
          0.3680755838201387,
          0.3680755838201387,
          0.3680755838201387,
          0.3680755838201387,
          0.3680755838201387,
          0.3680755838201387,
          0.3680755838201387,
          0.3680755838201387,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3908832395967129,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599,
          0.3912637017739599
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        },
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"24c1fcd8-eded-492c-907e-63f2f8f63e25\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"24c1fcd8-eded-492c-907e-63f2f8f63e25\")) {                    Plotly.newPlot(                        \"24c1fcd8-eded-492c-907e-63f2f8f63e25\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999],\"y\":[0.04185889286312716,-4.556141085210168,0.13304626685445076,-0.5363355045738799,-6.377504418091352,-0.0010605577384500038,0.005525064164305686,-0.0010605577384500038,0.001811440483309057,-0.00068001739412434,-47.7799506531394,-0.0010605577384500038,-7.05237384750848,-4.943861883637893,-28.867062176205362,-6.37670327168661,0.34733821447233987,0.29833901251330636,-0.3869641883759509,-0.1672768597513836,-0.1531371814969191,0.3680755838201387,-3.6359617206807724,-0.28003087700164947,-2.9647179020028624,-2.2941343178001117,-6.388418192872282,-13.313498850449138,-2.230797338756729,-4.582994963374512,-0.0010605577384500038,0.3908832395967129,0.3658143794300082,0.3467178921411273,0.288763879989727,0.3670076115350656,0.23199617155396005,-0.0010605577384500038,0.3577379763114123,0.09692673582930245,-0.0010605577384500038,-0.038389114641729706,0.34831932617976885,0.3260085302030584,-0.0010605577384500038,-0.018974292403799553,0.18231821384449187,0.29523684643277764,0.35431601950369895,0.37776970439194246,0.2678834315470247,0.042471059771781894,-0.05508669816306636,0.36888696671365306,0.2723437589816825,-0.1950144908199293,0.05740574481616367,-0.3991678134603547,-0.7227819766399415,-0.823907685501794,-0.5036072850319684,-0.8090393640596804,-0.11518836904202583,-0.3010265279789981,-0.5062409973920476,0.3535323697115595,-0.99343224327207,-0.1045350422466929,-0.4183101585050731,-0.285128456474994,0.3822407393134572,-0.0010605577384500038,-0.0010605577384500038,-0.026658589695754742,-0.044208983106783006,-0.8198661235186157,-0.029189222159157868,0.381572671507201,0.3477962754609981,-0.004969353986447341,-0.026651632353653382,-1.2335355099534155,0.34080204859169383,-0.7391836454695707,0.02298819950806985,-2.3058018169045007,-0.14481321917325152,0.13068527848200315,0.3512225022663323,0.35203064441057375,0.3559810191725759,0.3625855944780787,-0.07217422904168869,-0.44443810725625693,0.018694914887517993,0.3221944029746541,0.33947738340922007,0.21260537226309803,0.3652722220298327,0.3550035178043038,-0.039517366702175614,-0.0010605577384500038,0.37474724379759744,0.3704373992139353,0.13932838641657563,0.2511817875374465,0.3287736007031428,-0.0010605577384500038,0.3481441077308524,-0.0010605577384500038,-0.0010605577384500038,0.3783518492640771,0.31374261085568006,0.21228341014974084,-0.17519887927090583,0.2804745490020909,-0.5048988154050876,-0.47163044432495105,0.35839077804444514,-0.14350445948779378,-0.4378101463755378,-0.0010605577384500038,-0.0010605577384500038,-0.30394175946616264,-0.0010605577384500038,-0.3246354726256288,0.35283101687987733,-0.05615957710785413,0.36794108153143656,0.08207235493431331,0.3118903859670107,0.2602572442895932,-0.0010605577384500038,0.33851578256638154,-0.0010605577384500038,0.3456439384026126,0.2730060598405529,-0.1522378663928308,0.005556555584037004,-0.03873383997661065,0.351995099499227,0.36928367884628077,0.33513466861540503,-0.0010605577384500038,0.3667724152208821,0.355532710407048,0.30362271118233525,-0.037107573725934984,0.3247610205631729,0.34588065171969645,0.04885648884575574,0.18134677358960452,0.25913671558486734,0.3657321705592671,-0.37534005564278944,-2.499097176321239,-0.030994540740407046,0.2598310953290473,0.3538209999098738,-2.286440412715395,-1.8252612699741215,0.3501653432404178,-0.017202416998919594,-2.800691583690175,-2.2459959812924986,-1.9160236423297774,0.3582790556449174,-1.7402102500550192,0.30124982096136704,0.20301131004074024,0.14065276314498584,-0.0010605577384500038,-0.2894078697840549,-2.8650016245128156,-0.3492173021531805,0.3500412591431381,0.3048540745735115,0.3818461932174751,0.3896284409618738,0.3710697701596491,-0.017820243431351652,0.37175356318769315,0.3705285577316572,0.37682822015114387,0.34532822898144727,0.37480191800126444,0.3806475105830532,0.3682978154453476,0.3310346434098887,0.3522416920623915,0.33216505887911424,0.3873802162918917,0.36902685081009734,0.3575179303671192,0.38411576903085326,0.38649809322316253,0.3426701338285076,0.3364528002325194,0.384515265816337,0.3701833700500035,0.36037734448554243,0.10609570623436833,0.3516965079984788,-0.020503514590604177,0.3634856967175586,0.07243716670703293,0.29821080032460895,-0.0010605577384500038,0.3487129579288139,0.3849679867732455,-0.04718108966268427,0.005770129346022945,0.36315281115044307,0.3072308141589738,-0.0010605577384500038,0.3394960987014462,0.38785195139828804,0.016420847223247992,0.38022693881944525,0.14278732456041587,0.3834241019800115,-0.04840609472088445,0.3665814618311129,0.38291946232542223,-0.04284621608113456,-0.0010605577384500038,0.36742075593809886,0.384787601956976,0.35427686913525186,-0.025717535838595967,-0.0012824841160302691,0.3889306567982564,0.3770858538601182,-0.1661683313187793,-0.06431999676784868,0.20362070917336708,-0.0010605577384500038,0.3885228932754115,0.38873699062097117,0.3660341269275107,0.22574606093041474,0.3792824836473537,-0.04819942487239789,0.11851686785571802,0.36596004389596337,0.38541739975647277,0.16097296016867332,-0.01478066822094252,0.3763257791289647,0.38621504106152355,0.344778684713102,-0.0010605577384500038,-0.0010605577384500038,0.355861394994174,-0.34746217922804384,0.34197805757274635,-4.100987952529528,-0.0010605577384500038,-0.2053453657071758,-0.19325270272731943,-6.01040915188282,-7.970776558611518,0.20409253318511497,0.2577633567556522,0.3874614290903196,-0.0010605577384500038,-0.0326297934295254,-0.04133598910978631,0.35066338031892,0.35214853679869246,-0.0010605577384500038,0.37448836036322136,-6.377400545556277,-6.3755815493328445,-8.043546583415134,-0.5055205991387095,-0.0010605577384500038,0.08430028757320522,-0.0010605577384500038,-0.0010605577384500038,0.3576034459842808,-7.375013253939475,-0.0010605577384500038,0.3627067438529363,-25.303981180367114,-0.3034378935221617,0.3904685236846641,-0.0010605577384500038,-0.0010605577384500038,-0.0010203810292667519,-0.0010605577384500038,0.3831699078910157,0.36889472259404965,-22.340092348098327,-0.0010605577384500038,-0.0013626400293860197,-48.77249753961546,0.38861872724490293,0.38561504854450196,-0.0010605577384500038,0.04034784646931381,-50.26206606618207,0.31516146991067073,0.1904020900530455,-0.0007970045579219395,-0.0010605577384500038,0.37474518591159,-0.013030628985144102,0.2881379069351448,0.27750521142620105,-34.55337075395565,-15.890115061993466,0.20942435690081504,-8.230705894275287,-0.22190995256450408,-0.23398644327032214,-0.23259689970028272,-0.0010605577384500038,-0.23448612613681627,-0.0010605577384500038,-0.0010605577384500038,0.33759410587523786,-0.011933835866239936,0.2762257304103604,-0.0010605577384500038,0.3761371592255241,0.38919338945536225,0.22351219153487567,0.04335384711247777,-0.0010605577384500038,-0.0010605577384500038,0.30524868737990707,0.3103384487633779,0.31212901736861737,0.21584118296492927,-0.011358494375293682,0.36513391705557613,-0.29952632941317253,0.15155187650436164,0.2971917355457566,-0.0010605577384500038,-0.0010605577384500038,-0.0010605577384500038,-0.0007508823834184719,-0.0010605577384500038,0.337672238277489,-0.08147871572673264,-0.0010605577384500038,0.30057832419013736,0.3734987440536484,0.3597694711620189,-0.32850253893878484,-0.013802109427328105,0.3523411149317821,0.38062831401006564,0.3473260388747805,-0.0010605577384500038,-0.0010605577384500038,0.35063995279398313,0.3499739449016694,0.31862633377568855,-0.0010605577384500038,-10.784017941215117,0.3337760469627412,0.019963138290010136,-0.003772352940814757,0.3162221127559418,0.3526559177648407,-0.0010605577384500038,-0.0010605577384500038,-5.056631316623989,0.34008497254332565,-0.5535640781238206,-5.585929815255792,0.37900367111439565,0.37706200795612455,-0.0010605577384500038,-13.81655913333449,0.38876309436368667,-3.8212757979665497,0.3912637017739599,0.3629957078185064,0.3749351792094292,-0.0010605577384500038,0.38029378704944455,0.11325039881654216,0.3086345813903631,0.25286962286660136,0.17194834394573122,0.07327538901918906,-0.4934313864490952,0.1258617093818644,-10.735384366667894,-3.948189418635607,-0.0010605577384500038,-0.026071758595019905,-0.04669117601043423,-9.575811988920657,-0.2022361340533627,0.35802109019840916,0.04021080687445455,-0.0010605577384500038,0.2009788402383115,0.006608051677226556,-0.0010605577384500038,-0.0010605577384500038,0.3102952565082843,0.34038587288973415,0.3424386402093959,0.10617088853352707,0.02188223875367849,0.2944674000976273,0.3706414532158156,0.3568229346994201,0.3429416635322493,-0.24931180784395243,-0.0010605577384500038,-0.0010605577384500038,-0.0010605577384500038,-0.0010605577384500038,-0.25046499032896524,-0.1618109015629847,-0.7763383883520867,0.3620594480726215,0.24123463601495176,-0.031254654193242616,0.3671577492503924,0.3393868406610609,-0.0010605577384500038,-0.034568609883756686,-0.0010605577384500038,0.3816626884890576,0.3263331143951294,-0.0010605577384500038,-0.0010605577384500038,0.3869463842101577,0.3827908271654027,-0.0010605577384500038,0.3094155052224754,0.37767302485021553,-0.041631419940999836,-0.1759259953025021,-0.0010605577384500038,-0.033476492330456055,0.12125757216777296,-0.0010605577384500038,0.380601982726808,0.2907164079740137,-6.1781323515107225,0.24463644127461406,-8.691617418363492,0.23526128581525538,0.23378077767106234,0.35801638734189495,-0.0010605577384500038,-0.0010605577384500038,-3.093794304905655,0.3065938999539102,-0.03706486435467141,-6.464215996515261,0.3484974440278738,0.3802094593032089,0.23948688919499994,0.3670601186655892,-4.806806845993062,-0.0010605577384500038,-5.005889842187646,0.3741492877538322,-6.377442060754623,0.2881144207105898,-0.03761853802858883,-6.376867149270265,-39.4243500757115,-0.4394415774788152,-0.0010605577384500038,0.23144377541751662,-0.0010605577384500038,0.14510767743716968,0.029426769902694622,0.3899241731258676,0.3375102927705711,-32.370924596677234,0.27852817185699186,0.28747224812876854,-0.0010605577384500038,-0.0010605577384500038,-3.468551911441933,0.18412870663140388,0.37745901682276645,-0.0010605577384500038,-0.0010605577384500038,0.11387729787649133,0.34703785362389455,0.3866879050474894,-51.74835880780047,0.3818529336269009,0.38156380977596144,0.12720144428797733,0.3856731088534315,-0.23698177097402987,0.347588128447053,0.3134113731827913,-3.9785182940168053,-0.0010605577384500038,-44.72986456713179,0.3434546114611044,-0.013375232862853767,-5.0271162747482725,-0.04409245140630225,-6.377389040383408,-0.0010605577384500038,-6.4575275466560935,0.32767087481070767,-0.0009097060362016999,0.3476898041112938,0.3726586845181222,-0.11067718853461221,-0.0010605577384500038,-0.0010605577384500038,-18.33363347337298,-5.3509196550435405,0.3137294103851825,-0.0010605577384500038,0.35693391352026727,-4.616581262944586,-0.0010605577384500038,0.3836811243672429,-14.579824782070293,0.34516101401351784,-0.0010605577384500038,0.3854352921489593,-15.288422570514998,-0.0010605577384500038,-8.639500886123605,0.3853564725653997,-49.751203222221655,0.344264516661934,-0.0010605577384500038,0.3764886888433961,-17.327707009681696,0.005527790696925883,-0.0010605577384500038,-0.0010605577384500038,-1.3830234712819762,0.21422125313269413,-17.155055616677274,0.34196549306158536,0.3122000410434011,0.33279410895938544,-1.3952125650285414,0.022675151575102137,-0.0010605577384500038,0.12876131990082917,0.10611200032559227,-0.0010605577384500038,0.3130859443848873,0.22550710475227734,-6.374356103902174,-0.1485825145208591,-6.375660598344574,-0.10972828945053832,-5.351409477137485,-0.13463344299045077,-0.002475163612169151,-7.2827965082143855,0.3824729610644145,-0.0010605577384500038,-0.0010605577384500038,0.10648866807588102,0.15411671639313787,-0.1784051931355852,-6.377752329832946,0.35411932008562624,-0.36428299316963997,0.37730818045533987,-0.0010605577384500038,-0.0010605577384500038,0.369900921223319,0.2866745026603408,-0.0010605577384500038,-4.645541408055542,0.28931297698319597,-0.0010605577384500038,0.06057854915258343,0.006272838523699901,-4.705745158741586,-0.0008248833181166981,0.32813700617669767,-6.803873399650838,-0.6255092734363117,0.38225203839651706,-0.3183042839318394,-3.666273012296252,-0.16240991208550504,-7.004517680228437,0.30372791582363984,-8.681618859743883,-0.0010605577384500038,-0.0010605577384500038,0.007199985274894886,0.35616863842838015,0.30777640490968083,-0.02993833144455671,-5.65918558011136,-8.213744298127487,0.34289511999740013,-0.0010605577384500038,0.008240343110919812,-0.002041526551683881,-0.0010605577384500038,-7.482531049428136,-0.0010605577384500038,-0.05035018878415184,0.3788909601234725,-3.5157931061512357,0.11961436929905944,-0.0010605577384500038,-0.4871071845655925,-6.377658081313444,-0.0007613269763294683,-8.151408831518728,0.1123447767797714,-4.736094839551445,-4.981412239095385,0.2179339867990113,0.32120295227073037,-0.02113556886385637,0.3856968310926175,0.3142389279748148,0.35593079531998323,-0.4718251407176765,0.08185891631578994,0.0002685218694552516,-0.0010605577384500038,-7.12952406956268,0.38924954820272434,-0.022204825672430872,0.36060886162323513,0.3401860556851229,-0.0010605577384500038,-6.376966971159752,0.2553191910932765,0.3780618997719804,0.3540297292848086,-4.974283471554158,-0.0010605577384500038,0.3629973654187089,0.2640957954477175,0.29430661774683453,0.15874070252868236,-0.0010605577384500038,0.3624802542934541,-15.049399107482172,0.3609344601438474,0.034565362204306026,-0.0010605577384500038,-6.374074176992734,-0.4063145461043232,0.33147421176550623,-32.40704874397935,0.3760485783868223,0.27669994922120406,-0.0010605577384500038,-0.0010605577384500038,0.3664470449559747,-0.3305701847142551,-0.10721608636005404,0.02363096268494173,-0.03430460229600726,0.3701004591340455,0.26138744466105435,-0.012361863838674029,0.21659988815360462,-0.0010605577384500038,0.33050148154117576,0.3764962441638036,-6.377166960043011,0.10682360585033306,0.18887365198628667,0.3631999505767235,-6.376346696807017,-0.16715789463864636,0.23621001308292291,-4.946830879378721,0.3598447797352931,0.24682464806978108,-1.3965515913916828,-4.646896795456025,-4.504583200079261,0.34002564125968743,-4.59132850540241,0.35202702927174506,-0.3534714076529421,-27.507693556800383,0.3632358696111082,-0.0010605577384500038,0.13078602310511067,-48.75937636747312,-0.0010605577384500038,-3.0858006528214137,-0.0010605577384500038,0.3386323795011429,-6.370936481809964,-6.377308018275457,-0.23826746694930437,-0.0010605577384500038,-0.0010605577384500038,-0.0010605577384500038,0.18483309557703728,-17.185465062349948,0.2912902363994648,0.2945513497746695,0.026784699551855733,-0.0010605577384500038,-6.377396361331781,-0.0010605577384500038,-0.0010605577384500038,-6.377734370510967,-0.0010605577384500038,-0.4358553042966272,0.3569620525552184,-38.0741440427671,-8.186405807726523,0.3368667231503821,-2.91340287303545,-0.0010605577384500038,-0.03885364891893698,-1.0759731522283411,0.31038223846719093,-12.00535958884469,-24.0236308855437,0.004680134777292011,0.3693973653117101,-0.0010605577384500038,-27.35188523122657,-0.28937493448224516,-0.36705476142739796,-0.11937684304356815,0.25497498089562104,0.3263863071224283,0.2487280877411703,-39.5728996494445,0.3463691086637667,-0.0010605577384500038,0.36861964257515556,0.35705476675444964,0.24327776492300077,-6.977136317480416,0.32256363456967313,-6.351712469423592,-0.0010605577384500038,0.3261123896574048,-0.0010605577384500038,0.25073249952472965,-0.0010605577384500038,-6.465510173957438,0.03669641945798593,0.22907628252660847,-0.10030161884355467,-0.0010605577384500038,0.20955801093712648,0.14064518317627275,-0.0010605577384500038,-6.954659306529162,-0.0010605577384500038,0.25785594470304335,-13.584997217256081,-0.034322995193036464,0.3755108927677638,-0.17195989458990166,-0.0010605577384500038,0.34652599150016666,-6.377210683799779,0.2652036584961229,-0.0010605577384500038,-0.0010605577384500038,-7.011711346629762,-7.038273234484219,0.35605098391725193,0.34964872291192844,-7.014545847853967,-0.0010605577384500038,0.21524802653432204,0.15155934282714842,-5.064044311730996,-16.274068653950266,-6.374825300912436,-6.377544050608911,-6.377385803061429,-0.024556109506437718,-0.1188541454277879,0.19793969428155167,0.2947184199624053,0.36622311867458274,0.2350075643702769,-4.850779682516535,0.340568658343509,0.07404445549496556,0.13917581795749326,-44.500198200682426,0.33092392731522596,-0.0010605577384500038,-13.48857226005678,-0.08443733764903454,-6.036493276280838,0.36964224834762416,0.2543882384680895,0.3643905038786334,0.33871385716138086,0.356291087634362,0.3852121951440221,-0.3284007662547506,-0.0010605577384500038,-0.00015570934990805085,0.00042151545205774504,-5.055929170405026,-0.24617853038085358,-0.026915395137569798,-0.0010605577384500038,-0.0010605577384500038,-5.14781314546107,0.36272415025919724,-0.01168038023754033,-31.35177711100819,-0.0010605577384500038,-0.0010605577384500038,-0.0010605577384500038,0.08860469761446743,-0.0010605577384500038,-0.0010605577384500038,-0.0014366308938499699,0.3837171790145271,-0.0010605577384500038,0.37490007790772706,0.3842336884047411,-3.7898373813328816,-3.5936531212015854,0.07828316670354311,0.04175042935618881,-0.0010605577384500038,0.13359766857885044,0.3889910629331639,0.3439877804188713,-0.0010605577384500038,-6.377309989749969,-2.040800719821177,-4.069925325170112,-0.0010605577384500038,-3.472995627807699,-0.0010605577384500038,-8.567431987986309,0.3835334521492379,0.35568896822551144,0.37629428068386445,-1.7165935183441827,0.36647216069470434,0.33598670788462365,-5.168010524526988,0.3322755103618064,-0.0011196486591476724,-11.409182762842619,0.27036536236565234,0.34606226082156355,-23.444177862236888,0.0796919342583166,0.3639732397139172,-0.11640454612114233,0.169516207699088,-0.39211876712210914,-1.2064320213734456,-0.03188051324928809,-0.0010605577384500038,-5.777028989283949,-6.0216624205350175,0.29837535979133506,0.22097104259932288,-30.538493148569316,0.03611988391363019,-0.19149925280121474,-0.10579131587828587,-0.03687480707700815,-5.206884366545934,-6.3730720307806035,-0.04146188980338328,0.342845530416373,-39.65677548739121,-6.3773139405501,-0.0010605577384500038,0.37452681401922344,-0.0010605577384500038,0.3307128255716736,0.3277936274486528,-6.375843718019625,0.22926693163373893,-14.339266071217729,0.15011892723381193,-0.04271626813233276,-0.01845424597596775,-0.0010605577384500038,-29.939545183293962,0.0800961430845671,0.2960305888426556,-46.835946716984104,-14.990934603979035,-6.376956082159654,-0.44002467853761384,0.24711869899499073,-12.846131001478053,-50.66276522048361,-0.32920253414197537,-0.0010605577384500038,0.05649390557144385,-0.0010605577384500038,-6.377237098325663,-0.0010605577384500038,0.35744201345946125,0.35203804913915393,-0.020238161518880138,-0.0047890693085415785,-0.0010605577384500038,-0.23437135795603325,0.27737557158798476,-6.3777394352650845,-4.887766394292062,0.3651159740080811,0.1760138966498895,0.21663615894419538,-0.0010605577384500038,-9.246681517600162,0.17269398170479353,-0.1696104950269077,0.335101411368618,-0.0010605577384500038,-0.15640969518924866,-0.04069454896239555,-9.777670674142291,-0.0010605577384500038,-6.375262154347148,0.33122760167518533,0.12046653458571832,-0.0010605577384500038,0.3565986779908008,-38.91093698806498,-0.0010605577384500038,0.16681107240509552,-5.463253032644226,-4.882101448705407,0.3000890220138099,0.27327699910662767,0.03507004617472561,-6.3744131350434055,-8.642957785217094,0.3684050040874696,-0.06690594180795133,-0.0010605577384500038,-0.0010605577384500038,-6.37635645670523,0.23847462407425332,-0.0010605577384500038,-6.377499955408792,-0.0010605577384500038,-0.44655540417473766,0.29911585456043843,-0.0010605577384500038,0.04965265411125297,0.3064569143978141,-0.02423989243897488,0.13991217395815403,0.34443480268978804,-6.376744033320048,0.28232071698266575,-0.0010605577384500038,-4.92408576604559,-6.424851301634664,-0.0010605577384500038,0.2883635135531735,-8.63128009845572,-0.21309265734085128,-0.28325727184415395,-0.0010605577384500038,0.36656995209666215,-1.7601677907582167,0.005043392892111124,-42.51884277542003,-0.0010605577384500038,-0.0628038211004505,-0.0010605577384500038,0.31561065485372125,0.19430409556160458,0.34977266107119404,-5.214948144162375,0.23365431499786357,-0.00016225778205743632,-0.0010605577384500038,-6.419617907504,0.056227334958422616,-5.925717008372087,-0.0010605577384500038,-5.973403195385696,-0.0010605577384500038],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999],\"y\":[0.04185889286312716,0.04185889286312716,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.13304626685445076,0.34733821447233987,0.34733821447233987,0.34733821447233987,0.34733821447233987,0.34733821447233987,0.3680755838201387,0.3680755838201387,0.3680755838201387,0.3680755838201387,0.3680755838201387,0.3680755838201387,0.3680755838201387,0.3680755838201387,0.3680755838201387,0.3680755838201387,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3908832395967129,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599,0.3912637017739599],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('24c1fcd8-eded-492c-907e-63f2f8f63e25');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penpen/Documents/Cours/Stage/QSAR/code/wrapper/utils.py:228: UserWarning:\n",
      "\n",
      "color is redundantly defined by the 'color' keyword argument and the fmt string \"--k\" (-> color='k'). The keyword argument will take precedence.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_utils.display_score(ElasticNet(**study.best_params, random_state=0, max_iter=100000), X_neutral_train, y_neutral_train, X_neutral_test, y_neutral_test)\n",
    "display(plot_optimization_history(study))\n",
    "\n",
    "rr = ElasticNet(**study.best_params, random_state=0, max_iter=100000).fit(X_neutral_train, y_neutral_train)\n",
    "y_neutral_train_pred = rr.predict(X_neutral_train)\n",
    "y_neutral_test_pred = rr.predict(X_neutral_test)\n",
    "\n",
    "test_utils.display_graph(rr, X_neutral_train, X_neutral_test, y_neutral_train, y_neutral_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T22:15:12.151464832Z",
     "start_time": "2023-06-16T22:15:11.080819889Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
